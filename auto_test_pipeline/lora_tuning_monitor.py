#!/usr/bin/env python3
"""
LoRA èª¿å„ªç›£æ§å„€è¡¨æ¿
å³æ™‚ç›£æ§ LoRA èª¿å„ªéç¨‹ï¼Œé¡¯ç¤ºæ€§èƒ½æŒ‡æ¨™è®ŠåŒ–è¶¨å‹¢

åŠŸèƒ½ï¼š
1. å³æ™‚ç›£æ§è¨“ç·´é€²åº¦
2. é¡¯ç¤ºæ€§èƒ½æŒ‡æ¨™è¶¨å‹¢
3. è‡ªå‹•é è­¦å’Œå»ºè­°
4. ç”Ÿæˆèª¿å„ªæ­·å²å ±å‘Š
5. æ”¯æ´å¤šè¼ªæ¬¡æ¯”è¼ƒ
"""

import json
import os
import time
import datetime
import matplotlib.pyplot as plt
import numpy as np
from typing import Dict, List, Any, Optional
import argparse
from dataclasses import dataclass
import threading
import queue

plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ¨™æ•¸æ“šé¡"""
    timestamp: str
    iteration: int
    total_loss: float
    visual_similarity: float
    fashion_clip_similarity: float
    color_similarity: float
    overall_score: float
    training_efficiency: float
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'timestamp': self.timestamp,
            'iteration': self.iteration,
            'total_loss': self.total_loss,
            'visual_similarity': self.visual_similarity,
            'fashion_clip_similarity': self.fashion_clip_similarity,
            'color_similarity': self.color_similarity,
            'overall_score': self.overall_score,
            'training_efficiency': self.training_efficiency
        }

class LoRATuningMonitor:
    """LoRA èª¿å„ªç›£æ§å™¨"""
    
    def __init__(self, monitor_dir: str = "test_results"):
        self.monitor_dir = monitor_dir
        self.metrics_history: List[PerformanceMetrics] = []
        self.alert_thresholds = {
            'total_loss_max': 0.8,
            'visual_similarity_min': 0.2,
            'fashion_clip_similarity_min': 0.3,
            'overall_score_min': 0.4
        }
        self.is_monitoring = False
        self.monitor_thread = None
        self.update_queue = queue.Queue()
        
    def load_latest_report(self) -> Optional[Dict[str, Any]]:
        """è¼‰å…¥æœ€æ–°çš„åˆ†æå ±å‘Š"""
        try:
            if not os.path.exists(self.monitor_dir):
                return None
            
            json_files = [f for f in os.listdir(self.monitor_dir) 
                         if f.startswith("training_report_") and f.endswith(".json")]
            
            if not json_files:
                return None
            
            # æŒ‰æ™‚é–“æ’åºï¼Œå–æœ€æ–°çš„
            json_files.sort(reverse=True)
            latest_file = os.path.join(self.monitor_dir, json_files[0])
            
            with open(latest_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ è¼‰å…¥å ±å‘Šå¤±æ•—ï¼š{e}")
            return None
    
    def extract_metrics(self, report: Dict[str, Any]) -> Optional[PerformanceMetrics]:
        """å¾å ±å‘Šä¸­æå–æ€§èƒ½æŒ‡æ¨™"""
        try:
            # å¾ benchmark_analysis æå–
            benchmark = report.get("benchmark_analysis", {})
            avg_metrics = benchmark.get("average_metrics", {})
            
            # å¾ lora_tuning æå–
            lora_tuning = report.get("lora_tuning", {})
            
            # å¾ tuning_targets æå–è¿­ä»£æ¬¡æ•¸
            iteration = len(self.metrics_history) + 1
            
            metrics = PerformanceMetrics(
                timestamp=report.get("analysis_time", datetime.datetime.now().isoformat()),
                iteration=iteration,
                total_loss=avg_metrics.get("avg_total_loss", 1.0),
                visual_similarity=avg_metrics.get("avg_visual_similarity", 0.0),
                fashion_clip_similarity=avg_metrics.get("avg_fashion_clip_similarity", 0.0),
                color_similarity=avg_metrics.get("avg_color_similarity", 0.0),
                overall_score=lora_tuning.get("overall_tuning_score", 0.0),
                training_efficiency=lora_tuning.get("training_efficiency", {}).get("score", 0.0)
            )
            
            return metrics
        except Exception as e:
            print(f"âŒ æå–æŒ‡æ¨™å¤±æ•—ï¼š{e}")
            return None
    
    def check_alerts(self, metrics: PerformanceMetrics) -> List[str]:
        """æª¢æŸ¥é è­¦æ¢ä»¶"""
        alerts = []
        
        if metrics.total_loss > self.alert_thresholds['total_loss_max']:
            alerts.append(f"ğŸš¨ ç¸½æå¤±éé«˜ï¼š{metrics.total_loss:.3f} > {self.alert_thresholds['total_loss_max']}")
        
        if metrics.visual_similarity < self.alert_thresholds['visual_similarity_min']:
            alerts.append(f"âš ï¸ è¦–è¦ºç›¸ä¼¼åº¦éä½ï¼š{metrics.visual_similarity:.3f} < {self.alert_thresholds['visual_similarity_min']}")
        
        if metrics.fashion_clip_similarity < self.alert_thresholds['fashion_clip_similarity_min']:
            alerts.append(f"âš ï¸ FashionCLIP ç›¸ä¼¼åº¦éä½ï¼š{metrics.fashion_clip_similarity:.3f} < {self.alert_thresholds['fashion_clip_similarity_min']}")
        
        if metrics.overall_score < self.alert_thresholds['overall_score_min']:
            alerts.append(f"âŒ æ•´é«”åˆ†æ•¸éä½ï¼š{metrics.overall_score:.3f} < {self.alert_thresholds['overall_score_min']}")
        
        return alerts
    
    def generate_recommendations(self, metrics: PerformanceMetrics) -> List[str]:
        """ç”Ÿæˆèª¿å„ªå»ºè­°"""
        recommendations = []
        
        # åŸºæ–¼ç•¶å‰æŒ‡æ¨™ç”Ÿæˆå»ºè­°
        if metrics.total_loss > 0.7:
            recommendations.append("ğŸ”§ å»ºè­°å¤§å¹…é™ä½å­¸ç¿’ç‡ï¼ˆ0.0002-0.0003ï¼‰")
            recommendations.append("ğŸ“Š å»ºè­°å¢åŠ è¨“ç·´æ­¥æ•¸ï¼ˆ200-300æ­¥ï¼‰")
        elif metrics.total_loss > 0.5:
            recommendations.append("ğŸ”§ å»ºè­°é©åº¦é™ä½å­¸ç¿’ç‡ï¼ˆ0.0003-0.0005ï¼‰")
        
        if metrics.visual_similarity < 0.3:
            recommendations.append("ğŸ‘ï¸ å»ºè­°æé«˜è¦–è¦ºæå¤±æ¬Šé‡ï¼ˆ0.3-0.4ï¼‰")
            recommendations.append("ğŸ“¸ å»ºè­°æé«˜è¨“ç·´è§£æåº¦ï¼ˆ768x768ï¼‰")
        
        if metrics.fashion_clip_similarity < 0.4:
            recommendations.append("ğŸ¨ å»ºè­°æé«˜ FashionCLIP æ¬Šé‡ï¼ˆ0.7-0.8ï¼‰")
            recommendations.append("ğŸ“ å»ºè­°å„ªåŒ–è¨“ç·´æ•¸æ“šæ¨™ç±¤")
        
        if metrics.training_efficiency < 0.5:
            recommendations.append("ğŸš€ å»ºè­°ä½¿ç”¨æ›´é«˜æ•ˆçš„è¨“ç·´ç­–ç•¥")
            recommendations.append("ğŸ’¾ å»ºè­°å•Ÿç”¨å¿«å–æ©Ÿåˆ¶")
        
        # åŸºæ–¼è¶¨å‹¢ç”Ÿæˆå»ºè­°
        if len(self.metrics_history) >= 2:
            prev_metrics = self.metrics_history[-1]
            
            # æª¢æŸ¥æ˜¯å¦æœ‰æ”¹å–„
            if metrics.total_loss > prev_metrics.total_loss:
                recommendations.append("ğŸ“ˆ æå¤±å¢åŠ ï¼šå»ºè­°æª¢æŸ¥å­¸ç¿’ç‡è¨­å®š")
            
            if metrics.overall_score < prev_metrics.overall_score:
                recommendations.append("ğŸ“‰ æ•´é«”åˆ†æ•¸ä¸‹é™ï¼šå»ºè­°å›åˆ°ä¸Šä¸€è¼ªåƒæ•¸")
        
        return recommendations
    
    def update_metrics(self, metrics: PerformanceMetrics):
        """æ›´æ–°æŒ‡æ¨™æ­·å²"""
        self.metrics_history.append(metrics)
        
        # æª¢æŸ¥é è­¦
        alerts = self.check_alerts(metrics)
        if alerts:
            print(f"\nâš ï¸ ç¬¬ {metrics.iteration} è¼ªé è­¦ï¼š")
            for alert in alerts:
                print(f"   {alert}")
        
        # ç”Ÿæˆå»ºè­°
        recommendations = self.generate_recommendations(metrics)
        if recommendations:
            print(f"\nğŸ’¡ ç¬¬ {metrics.iteration} è¼ªå»ºè­°ï¼š")
            for rec in recommendations:
                print(f"   {rec}")
        
        print(f"\nğŸ“Š ç¬¬ {metrics.iteration} è¼ªæ€§èƒ½ï¼š")
        print(f"   ç¸½æå¤±ï¼š{metrics.total_loss:.3f}")
        print(f"   è¦–è¦ºç›¸ä¼¼åº¦ï¼š{metrics.visual_similarity:.3f}")
        print(f"   FashionCLIP ç›¸ä¼¼åº¦ï¼š{metrics.fashion_clip_similarity:.3f}")
        print(f"   æ•´é«”åˆ†æ•¸ï¼š{metrics.overall_score:.3f}")
    
    def generate_dashboard(self, save_path: str = "tuning_dashboard.png"):
        """ç”Ÿæˆç›£æ§å„€è¡¨æ¿"""
        if not self.metrics_history:
            print("âŒ æ²’æœ‰å¯è¦–åŒ–çš„æ•¸æ“š")
            return
        
        # æº–å‚™æ•¸æ“š
        iterations = [m.iteration for m in self.metrics_history]
        total_losses = [m.total_loss for m in self.metrics_history]
        visual_sims = [m.visual_similarity for m in self.metrics_history]
        fashion_sims = [m.fashion_clip_similarity for m in self.metrics_history]
        overall_scores = [m.overall_score for m in self.metrics_history]
        
        # å‰µå»ºåœ–è¡¨
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('LoRA èª¿å„ªç›£æ§å„€è¡¨æ¿', fontsize=16, fontweight='bold')
        
        # 1. ç¸½æå¤±è¶¨å‹¢
        ax1.plot(iterations, total_losses, 'r-o', linewidth=2, markersize=6)
        ax1.axhline(y=0.5, color='orange', linestyle='--', alpha=0.7, label='è‰¯å¥½é–¾å€¼')
        ax1.axhline(y=0.3, color='green', linestyle='--', alpha=0.7, label='å„ªç§€é–¾å€¼')
        ax1.set_title('ç¸½æå¤±è¶¨å‹¢')
        ax1.set_xlabel('è¿­ä»£æ¬¡æ•¸')
        ax1.set_ylabel('ç¸½æå¤±')
        ax1.grid(True, alpha=0.3)
        ax1.legend()
        
        # 2. è¦–è¦ºç›¸ä¼¼åº¦è¶¨å‹¢
        ax2.plot(iterations, visual_sims, 'b-o', linewidth=2, markersize=6)
        ax2.axhline(y=0.3, color='orange', linestyle='--', alpha=0.7, label='ä¸€èˆ¬é–¾å€¼')
        ax2.axhline(y=0.5, color='green', linestyle='--', alpha=0.7, label='è‰¯å¥½é–¾å€¼')
        ax2.set_title('è¦–è¦ºç›¸ä¼¼åº¦è¶¨å‹¢')
        ax2.set_xlabel('è¿­ä»£æ¬¡æ•¸')
        ax2.set_ylabel('è¦–è¦ºç›¸ä¼¼åº¦')
        ax2.grid(True, alpha=0.3)
        ax2.legend()
        
        # 3. FashionCLIP ç›¸ä¼¼åº¦è¶¨å‹¢
        ax3.plot(iterations, fashion_sims, 'g-o', linewidth=2, markersize=6)
        ax3.axhline(y=0.3, color='orange', linestyle='--', alpha=0.7, label='ä¸€èˆ¬é–¾å€¼')
        ax3.axhline(y=0.5, color='green', linestyle='--', alpha=0.7, label='è‰¯å¥½é–¾å€¼')
        ax3.set_title('FashionCLIP ç›¸ä¼¼åº¦è¶¨å‹¢')
        ax3.set_xlabel('è¿­ä»£æ¬¡æ•¸')
        ax3.set_ylabel('FashionCLIP ç›¸ä¼¼åº¦')
        ax3.grid(True, alpha=0.3)
        ax3.legend()
        
        # 4. æ•´é«”åˆ†æ•¸è¶¨å‹¢
        ax4.plot(iterations, overall_scores, 'purple', marker='o', linewidth=2, markersize=6)
        ax4.axhline(y=0.5, color='orange', linestyle='--', alpha=0.7, label='ä¸€èˆ¬é–¾å€¼')
        ax4.axhline(y=0.7, color='green', linestyle='--', alpha=0.7, label='è‰¯å¥½é–¾å€¼')
        ax4.set_title('æ•´é«”åˆ†æ•¸è¶¨å‹¢')
        ax4.set_xlabel('è¿­ä»£æ¬¡æ•¸')
        ax4.set_ylabel('æ•´é«”åˆ†æ•¸')
        ax4.grid(True, alpha=0.3)
        ax4.legend()
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"ğŸ“Š å„€è¡¨æ¿å·²ä¿å­˜ï¼š{save_path}")
        return save_path
    
    def generate_comparison_report(self) -> str:
        """ç”Ÿæˆæ¯”è¼ƒå ±å‘Š"""
        if not self.metrics_history:
            return "æ²’æœ‰å¯æ¯”è¼ƒçš„æ•¸æ“š"
        
        report = f"""
# LoRA èª¿å„ªç›£æ§å ±å‘Š
ç”Ÿæˆæ™‚é–“ï¼š{datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## èª¿å„ªæ­·å²ç¸½è¦½
ç¸½è¿­ä»£æ¬¡æ•¸ï¼š{len(self.metrics_history)}

## æ€§èƒ½æŒ‡æ¨™æ¯”è¼ƒ
"""
        
        # æ‰¾å‡ºæœ€ä½³å’Œæœ€å·®çš„è¿­ä»£
        best_overall = max(self.metrics_history, key=lambda x: x.overall_score)
        worst_overall = min(self.metrics_history, key=lambda x: x.overall_score)
        
        best_loss = min(self.metrics_history, key=lambda x: x.total_loss)
        best_visual = max(self.metrics_history, key=lambda x: x.visual_similarity)
        best_fashion = max(self.metrics_history, key=lambda x: x.fashion_clip_similarity)
        
        report += f"""
### æœ€ä½³è¡¨ç¾
- æœ€ä½³æ•´é«”åˆ†æ•¸ï¼šç¬¬ {best_overall.iteration} è¼ªï¼ˆ{best_overall.overall_score:.3f}ï¼‰
- æœ€ä½ç¸½æå¤±ï¼šç¬¬ {best_loss.iteration} è¼ªï¼ˆ{best_loss.total_loss:.3f}ï¼‰
- æœ€é«˜è¦–è¦ºç›¸ä¼¼åº¦ï¼šç¬¬ {best_visual.iteration} è¼ªï¼ˆ{best_visual.visual_similarity:.3f}ï¼‰
- æœ€é«˜ FashionCLIP ç›¸ä¼¼åº¦ï¼šç¬¬ {best_fashion.iteration} è¼ªï¼ˆ{best_fashion.fashion_clip_similarity:.3f}ï¼‰

### æœ€å·®è¡¨ç¾
- æœ€å·®æ•´é«”åˆ†æ•¸ï¼šç¬¬ {worst_overall.iteration} è¼ªï¼ˆ{worst_overall.overall_score:.3f}ï¼‰

### æ”¹å–„å¹…åº¦
"""
        
        if len(self.metrics_history) >= 2:
            first = self.metrics_history[0]
            last = self.metrics_history[-1]
            
            loss_improvement = (first.total_loss - last.total_loss) / first.total_loss * 100
            visual_improvement = (last.visual_similarity - first.visual_similarity) / max(first.visual_similarity, 0.001) * 100
            fashion_improvement = (last.fashion_clip_similarity - first.fashion_clip_similarity) / max(first.fashion_clip_similarity, 0.001) * 100
            overall_improvement = (last.overall_score - first.overall_score) / max(first.overall_score, 0.001) * 100
            
            report += f"""
- ç¸½æå¤±æ”¹å–„ï¼š{loss_improvement:+.1f}%
- è¦–è¦ºç›¸ä¼¼åº¦æ”¹å–„ï¼š{visual_improvement:+.1f}%
- FashionCLIP ç›¸ä¼¼åº¦æ”¹å–„ï¼š{fashion_improvement:+.1f}%
- æ•´é«”åˆ†æ•¸æ”¹å–„ï¼š{overall_improvement:+.1f}%
"""
        
        report += f"""
## è©³ç´°æ•¸æ“š

| è¿­ä»£ | ç¸½æå¤± | è¦–è¦ºç›¸ä¼¼åº¦ | FashionCLIP | æ•´é«”åˆ†æ•¸ | æ™‚é–“ |
|------|--------|------------|-------------|----------|------|
"""
        
        for metrics in self.metrics_history:
            report += f"| {metrics.iteration} | {metrics.total_loss:.3f} | {metrics.visual_similarity:.3f} | {metrics.fashion_clip_similarity:.3f} | {metrics.overall_score:.3f} | {metrics.timestamp[:19]} |\n"
        
        return report
    
    def start_monitoring(self, interval: int = 30):
        """é–‹å§‹ç›£æ§"""
        self.is_monitoring = True
        
        def monitor_loop():
            while self.is_monitoring:
                try:
                    # è¼‰å…¥æœ€æ–°å ±å‘Š
                    report = self.load_latest_report()
                    if report:
                        metrics = self.extract_metrics(report)
                        if metrics:
                            # æª¢æŸ¥æ˜¯å¦æ˜¯æ–°çš„è¿­ä»£
                            if not self.metrics_history or metrics.timestamp != self.metrics_history[-1].timestamp:
                                self.update_metrics(metrics)
                                self.generate_dashboard()
                    
                    time.sleep(interval)
                except Exception as e:
                    print(f"âŒ ç›£æ§éŒ¯èª¤ï¼š{e}")
                    time.sleep(interval)
        
        self.monitor_thread = threading.Thread(target=monitor_loop)
        self.monitor_thread.daemon = True
        self.monitor_thread.start()
        
        print(f"ğŸ” é–‹å§‹ç›£æ§ LoRA èª¿å„ªï¼Œé–“éš” {interval} ç§’")
    
    def stop_monitoring(self):
        """åœæ­¢ç›£æ§"""
        self.is_monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join()
        print("â¹ï¸ ç›£æ§å·²åœæ­¢")
    
    def save_history(self, filename: str = None):
        """ä¿å­˜ç›£æ§æ­·å²"""
        if not filename:
            filename = f"tuning_history_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        history_data = {
            "metadata": {
                "total_iterations": len(self.metrics_history),
                "monitoring_start": self.metrics_history[0].timestamp if self.metrics_history else None,
                "monitoring_end": self.metrics_history[-1].timestamp if self.metrics_history else None
            },
            "metrics_history": [m.to_dict() for m in self.metrics_history],
            "alert_thresholds": self.alert_thresholds
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(history_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ç›£æ§æ­·å²å·²ä¿å­˜ï¼š{filename}")
        return filename

def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description="LoRA èª¿å„ªç›£æ§å·¥å…·")
    parser.add_argument("--monitor_dir", type=str, default="test_results", help="ç›£æ§ç›®éŒ„")
    parser.add_argument("--interval", type=int, default=30, help="ç›£æ§é–“éš”ï¼ˆç§’ï¼‰")
    parser.add_argument("--mode", type=str, choices=["monitor", "report", "dashboard"], default="monitor", help="é‹è¡Œæ¨¡å¼")
    parser.add_argument("--output", type=str, default="tuning_dashboard.png", help="è¼¸å‡ºæ–‡ä»¶å")
    
    args = parser.parse_args()
    
    # å‰µå»ºç›£æ§å™¨
    monitor = LoRATuningMonitor(args.monitor_dir)
    
    if args.mode == "monitor":
        # å³æ™‚ç›£æ§æ¨¡å¼
        try:
            monitor.start_monitoring(args.interval)
            print("æŒ‰ Ctrl+C åœæ­¢ç›£æ§")
            
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\nğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡è™Ÿ")
            monitor.stop_monitoring()
            
            # ä¿å­˜æ­·å²
            history_file = monitor.save_history()
            
            # ç”Ÿæˆæœ€çµ‚å ±å‘Š
            report = monitor.generate_comparison_report()
            report_file = f"tuning_report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            
            print(f"ğŸ“‹ æœ€çµ‚å ±å‘Šå·²ä¿å­˜ï¼š{report_file}")
    
    elif args.mode == "report":
        # å ±å‘Šæ¨¡å¼
        report = monitor.load_latest_report()
        if report:
            metrics = monitor.extract_metrics(report)
            if metrics:
                monitor.update_metrics(metrics)
                
                comparison_report = monitor.generate_comparison_report()
                print(comparison_report)
                
                # ä¿å­˜å ±å‘Š
                report_file = f"tuning_report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
                with open(report_file, 'w', encoding='utf-8') as f:
                    f.write(comparison_report)
                
                print(f"ğŸ“‹ å ±å‘Šå·²ä¿å­˜ï¼š{report_file}")
        else:
            print("âŒ æ‰¾ä¸åˆ°åˆ†æå ±å‘Š")
    
    elif args.mode == "dashboard":
        # å„€è¡¨æ¿æ¨¡å¼
        # è¼‰å…¥æ‰€æœ‰æ­·å²å ±å‘Š
        if os.path.exists(args.monitor_dir):
            json_files = [f for f in os.listdir(args.monitor_dir) 
                         if f.startswith("training_report_") and f.endswith(".json")]
            json_files.sort()
            
            for json_file in json_files:
                file_path = os.path.join(args.monitor_dir, json_file)
                with open(file_path, 'r', encoding='utf-8') as f:
                    report = json.load(f)
                
                metrics = monitor.extract_metrics(report)
                if metrics:
                    monitor.update_metrics(metrics)
            
            # ç”Ÿæˆå„€è¡¨æ¿
            dashboard_file = monitor.generate_dashboard(args.output)
            print(f"ğŸ“Š å„€è¡¨æ¿å·²ç”Ÿæˆï¼š{dashboard_file}")
        else:
            print("âŒ æ‰¾ä¸åˆ°ç›£æ§ç›®éŒ„")

if __name__ == "__main__":
    main()
