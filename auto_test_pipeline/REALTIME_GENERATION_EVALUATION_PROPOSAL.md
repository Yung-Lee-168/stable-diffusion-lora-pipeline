# LoRA è¨“ç·´æœŸé–“å¯¦æ™‚ç”Ÿåœ–è©•ä¼°æ–¹æ¡ˆåˆ†æ

**ææ¡ˆæ—¥æœŸ:** 2025å¹´7æœˆ8æ—¥  
**ææ¡ˆå…§å®¹:** åœ¨ LoRA è¨“ç·´éç¨‹ä¸­ä½¿ç”¨æœ¬æ©Ÿå¯¦æ™‚ç”Ÿåœ–é€²è¡ŒçœŸå¯¦æ€§èƒ½è©•ä¼°

## ğŸ¯ **ææ¡ˆæ ¸å¿ƒæ€æƒ³**

### ç•¶å‰å•é¡Œ
- LoRA è¨“ç·´æœŸé–“ä½¿ç”¨è™›æ“¬/é è¨­å€¼è¨ˆç®—æ€§èƒ½æŒ‡æ¨™
- ç„¡æ³•ç²å¾—çœŸå¯¦çš„ Visual/FashionCLIP/Color Loss
- å¿…é ˆç­‰åˆ°è¨“ç·´å®Œæˆå¾Œæ‰èƒ½è©•ä¼°å¯¦éš›æ•ˆæœ

### æ”¹é€²ç›®æ¨™
- **è¨“ç·´æœŸé–“å¯¦æ™‚ç”Ÿåœ–**: æ¯éš”ä¸€å®šæ­¥æ•¸ä½¿ç”¨ç•¶å‰ LoRA æ¬Šé‡ç”Ÿæˆæ¸¬è©¦åœ–ç‰‡
- **çœŸå¯¦æŒ‡æ¨™è¨ˆç®—**: åŸºæ–¼å¯¦éš›ç”Ÿæˆåœ–ç‰‡è¨ˆç®—æº–ç¢ºçš„æ€§èƒ½æŒ‡æ¨™
- **å³æ™‚åé¥‹**: åœ¨è¨“ç·´éç¨‹ä¸­å°±èƒ½çœ‹åˆ°å¯¦éš›æ”¹å–„æ•ˆæœ

## ğŸ“Š **å¯è¡Œæ€§åˆ†æ**

### ğŸŸ¢ **å„ªé»**
1. **æ•¸æ“šçœŸå¯¦æ€§**: ç²å¾—çœŸæ­£çš„æ€§èƒ½æŒ‡æ¨™ï¼Œä¸å†æ˜¯è™›æ“¬å€¼
2. **å³æ™‚ç›£æ§**: è¨“ç·´éç¨‹ä¸­å°±èƒ½çœ‹åˆ° LoRA çš„å¯¦éš›æ•ˆæœ
3. **æ—©æœŸåœæ­¢**: å¦‚æœæ•ˆæœä¸ä½³å¯ä»¥åŠæ—©åœæ­¢è¨“ç·´
4. **èª¿åƒæŒ‡å°**: æ ¹æ“šå¯¦æ™‚æ•ˆæœèª¿æ•´è¨“ç·´åƒæ•¸

### ğŸ”´ **æŒ‘æˆ°**
1. **è¨ˆç®—è³‡æº**: ç”Ÿåœ–éœ€è¦é¡å¤–çš„ GPU è¨˜æ†¶é«”å’Œæ™‚é–“
2. **è¨“ç·´ä¸­æ–·**: ç”Ÿåœ–éç¨‹å¯èƒ½å¹²æ“¾è¨“ç·´æµç¨‹
3. **æŠ€è¡“è¤‡é›œ**: éœ€è¦åœ¨è¨“ç·´æœŸé–“è¼‰å…¥éƒ¨åˆ†æ¬Šé‡é€²è¡Œæ¨ç†
4. **æ™‚é–“æˆæœ¬**: æ¯æ¬¡ç”Ÿåœ–éœ€è¦ 10-30 ç§’

## ğŸ”§ **æŠ€è¡“å¯¦æ–½æ–¹æ¡ˆ**

### æ–¹æ¡ˆä¸€ï¼šè¨“ç·´é–“éš”ç”Ÿåœ– (æ¨è–¦)
```python
def enhanced_training_with_realtime_evaluation():
    for step in range(max_train_steps):
        # æ­£å¸¸è¨“ç·´æ­¥é©Ÿ
        loss = train_one_step()
        
        # æ¯Næ­¥é€²è¡Œå¯¦æ™‚è©•ä¼°
        if step % evaluation_interval == 0:
            # 1. æš«å­˜ç•¶å‰è¨“ç·´ç‹€æ…‹
            save_checkpoint_temp()
            
            # 2. è¼‰å…¥ç•¶å‰ LoRA æ¬Šé‡åˆ°æ¨ç†æ¨¡å‹
            load_current_lora_for_inference()
            
            # 3. ç”Ÿæˆæ¸¬è©¦åœ–ç‰‡
            generated_images = generate_test_images(test_prompts)
            
            # 4. è¨ˆç®—çœŸå¯¦æ€§èƒ½æŒ‡æ¨™
            visual_loss, fashion_loss, color_loss = calculate_real_metrics(
                original_images, generated_images
            )
            
            # 5. è¨˜éŒ„çœŸå¯¦æŒ‡æ¨™
            log_real_metrics(step, visual_loss, fashion_loss, color_loss)
            
            # 6. æ¢å¾©è¨“ç·´ç‹€æ…‹
            restore_training_state()
```

### æ–¹æ¡ˆäºŒï¼šé›™é€²ç¨‹æ¶æ§‹
```python
# ä¸»é€²ç¨‹ï¼šLoRA è¨“ç·´
def training_process():
    while training:
        train_step()
        if should_evaluate():
            save_current_lora()
            signal_evaluation_process()

# å‰¯é€²ç¨‹ï¼šå¯¦æ™‚è©•ä¼°
def evaluation_process():
    while True:
        wait_for_signal()
        load_new_lora()
        generate_and_evaluate()
        report_results()
```

## ğŸ“‹ **å…·é«”å¯¦æ–½è¨ˆåŠƒ**

### éšæ®µä¸€ï¼šåŸºç¤æ¶æ§‹ (1-2å¤©)
```python
# 1. ä¿®æ”¹ train_lora.py å¢åŠ ç”Ÿåœ–åŠŸèƒ½
def setup_inference_pipeline():
    """è¨­ç½®æ¨ç†ç®¡é“ç”¨æ–¼è¨“ç·´æœŸé–“ç”Ÿåœ–"""
    from diffusers import StableDiffusionPipeline
    
    # è¼‰å…¥åŸºç¤æ¨¡å‹
    pipe = StableDiffusionPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5",
        torch_dtype=torch.float16
    )
    pipe = pipe.to("cuda")
    return pipe

def generate_test_images_during_training(pipe, current_lora_path, test_prompts):
    """åœ¨è¨“ç·´æœŸé–“ç”Ÿæˆæ¸¬è©¦åœ–ç‰‡"""
    # è¼‰å…¥ç•¶å‰ LoRA æ¬Šé‡
    pipe.load_lora_weights(current_lora_path)
    
    generated_images = []
    for prompt in test_prompts:
        image = pipe(prompt, num_inference_steps=20).images[0]
        generated_images.append(image)
    
    return generated_images
```

### éšæ®µäºŒï¼šæ•´åˆåˆ°è¨“ç·´å¾ªç’° (2-3å¤©)
```python
def monitor_training_with_realtime_generation(cmd, env, output_dir, max_train_steps):
    """å¢å¼·çš„è¨“ç·´ç›£æ§ï¼ŒåŒ…å«å¯¦æ™‚ç”Ÿåœ–è©•ä¼°"""
    
    # è¨­ç½®æ¨ç†ç®¡é“
    inference_pipe = setup_inference_pipeline()
    
    # æº–å‚™æ¸¬è©¦æç¤ºè©
    test_prompts = load_test_prompts()  # å¾è¨“ç·´æ•¸æ“šæå–
    original_test_images = load_original_test_images()
    
    # è©•ä¼°é–“éš”è¨­å®š
    evaluation_interval = 20  # æ¯20æ­¥è©•ä¼°ä¸€æ¬¡
    
    # è¨“ç·´ç›£æ§ä¸»å¾ªç’°
    for step, total_loss in training_loop:
        print(f"ğŸ“Š Step {step}: è¨“ç·´Loss={total_loss:.6f}")
        
        # å¯¦æ™‚è©•ä¼°æª¢æŸ¥
        if step % evaluation_interval == 0 and step > 0:
            print(f"\nğŸ¨ Step {step}: é–‹å§‹å¯¦æ™‚ç”Ÿåœ–è©•ä¼°...")
            
            try:
                # 1. ä¿å­˜ç•¶å‰ LoRA æ¬Šé‡
                current_lora_path = save_current_lora_state(step)
                
                # 2. ç”Ÿæˆæ¸¬è©¦åœ–ç‰‡
                generated_images = generate_test_images_during_training(
                    inference_pipe, current_lora_path, test_prompts
                )
                
                # 3. è¨ˆç®—çœŸå¯¦æ€§èƒ½æŒ‡æ¨™
                real_visual_loss = calculate_visual_loss_batch(
                    original_test_images, generated_images
                )
                real_fashion_loss = calculate_fashion_clip_loss_batch(
                    original_test_images, generated_images  
                )
                real_color_loss = calculate_color_loss_batch(
                    original_test_images, generated_images
                )
                
                # 4. è¨˜éŒ„çœŸå¯¦æŒ‡æ¨™
                with open(loss_tracker_file, 'a', encoding='utf-8') as f:
                    f.write(f"{step},{current_epoch},{total_loss},"
                           f"{real_visual_loss:.3f},{real_fashion_loss:.3f},"
                           f"{real_color_loss:.3f},{current_lr},{timestamp}\n")
                
                print(f"   âœ… çœŸå¯¦æŒ‡æ¨™: Visual={real_visual_loss:.3f}, "
                      f"FashionCLIP={real_fashion_loss:.3f}, Color={real_color_loss:.3f}")
                
                # 5. ä¿å­˜ç”Ÿæˆçš„æ¸¬è©¦åœ–ç‰‡
                save_generated_test_images(generated_images, step)
                
            except Exception as e:
                print(f"   âŒ å¯¦æ™‚è©•ä¼°å¤±æ•—: {e}")
                # å›é€€åˆ°é è¨­å€¼æˆ–è·³é
```

### éšæ®µä¸‰ï¼šæ€§èƒ½å„ªåŒ– (1-2å¤©)
```python
# è¨˜æ†¶é«”ç®¡ç†å„ªåŒ–
def optimize_memory_usage():
    """å„ªåŒ–è¨˜æ†¶é«”ä½¿ç”¨ï¼Œé¿å… OOM"""
    # 1. æ¸…ç†ä¸å¿…è¦çš„è¨ˆç®—åœ–
    torch.cuda.empty_cache()
    
    # 2. ä½¿ç”¨ä½ç²¾åº¦æ¨ç†
    with torch.autocast("cuda"):
        generated_images = pipe(prompts)
    
    # 3. æ‰¹é‡å¤§å°æ§åˆ¶
    batch_size = 1  # ä¸€æ¬¡åªç”Ÿæˆä¸€å¼µåœ–
    
    # 4. åŠæ™‚é‡‹æ”¾è®Šæ•¸
    del generated_images
    torch.cuda.empty_cache()

# æ™‚é–“ç®¡ç†å„ªåŒ–
def optimize_evaluation_timing():
    """å„ªåŒ–è©•ä¼°æ™‚æ©Ÿï¼Œæ¸›å°‘å°è¨“ç·´çš„å½±éŸ¿"""
    # 1. å‹•æ…‹èª¿æ•´è©•ä¼°é–“éš”
    if step < 100:
        evaluation_interval = 50  # å‰æœŸè¼ƒå°‘è©•ä¼°
    elif step < 200:
        evaluation_interval = 20  # ä¸­æœŸé©ä¸­è©•ä¼°
    else:
        evaluation_interval = 10  # å¾ŒæœŸå¯†é›†è©•ä¼°
    
    # 2. å¿«é€Ÿç”Ÿåœ–è¨­å®š
    num_inference_steps = 15  # æ¸›å°‘æ¨ç†æ­¥æ•¸
    guidance_scale = 7.0  # é©ä¸­çš„å¼•å°å¼·åº¦
```

## âš–ï¸ **è³‡æºéœ€æ±‚è©•ä¼°**

### ç¡¬é«”éœ€æ±‚
```
åŸºæœ¬éœ€æ±‚ (è¨“ç·´ + å¶çˆ¾ç”Ÿåœ–):
- GPU: RTX 3080 (10GB) æˆ–ä»¥ä¸Š
- RAM: 16GB ä»¥ä¸Š
- å­˜å„²: é¡å¤– 2-5GB (å­˜æ”¾æ¸¬è©¦åœ–ç‰‡)

ç†æƒ³é…ç½® (æµæš¢å¯¦æ™‚è©•ä¼°):
- GPU: RTX 4090 (24GB) æˆ– A100
- RAM: 32GB ä»¥ä¸Š  
- å­˜å„²: é¡å¤– 10GB ä»¥ä¸Š
```

### æ™‚é–“æˆæœ¬
```
æ¯æ¬¡å¯¦æ™‚è©•ä¼°è€—æ™‚:
- è¼‰å…¥ LoRA æ¬Šé‡: ~2ç§’
- ç”Ÿæˆ 5å¼µæ¸¬è©¦åœ–: ~10-15ç§’  
- è¨ˆç®—æ€§èƒ½æŒ‡æ¨™: ~3-5ç§’
- ç¸½è¨ˆ: ~15-22ç§’

å°è¨“ç·´å½±éŸ¿:
- æ¯20æ­¥è©•ä¼°ä¸€æ¬¡
- 200æ­¥è¨“ç·´å¢åŠ : ~10æ¬¡è©•ä¼° = ~3-4åˆ†é˜
- ç›¸å°å½±éŸ¿: ç´„å¢åŠ 10-15%è¨“ç·´æ™‚é–“
```

## ğŸ¯ **å¯¦æ–½å»ºè­°**

### æ¨è–¦æ–¹æ¡ˆ
1. **å…ˆå¯¦æ–½éšæ®µä¸€**: å»ºç«‹åŸºç¤ç”Ÿåœ–èƒ½åŠ›
2. **å°ç¯„åœæ¸¬è©¦**: æ¯50æ­¥è©•ä¼°ä¸€æ¬¡ï¼Œè§€å¯Ÿæ•ˆæœ
3. **é€æ­¥å„ªåŒ–**: æ ¹æ“šå¯¦éš›ä½¿ç”¨èª¿æ•´è©•ä¼°é »ç‡
4. **å¯é¸é–‹é—œ**: æä¾›é¸é …è®“ç”¨æˆ¶æ±ºå®šæ˜¯å¦å•Ÿç”¨å¯¦æ™‚è©•ä¼°

### é…ç½®é¸é …
```python
# åœ¨ train_lora.py ä¸­å¢åŠ é…ç½®
ENABLE_REALTIME_EVALUATION = True  # æ˜¯å¦å•Ÿç”¨å¯¦æ™‚è©•ä¼°
EVALUATION_INTERVAL = 20           # è©•ä¼°é–“éš”æ­¥æ•¸
EVALUATION_PROMPTS_COUNT = 3       # æ¯æ¬¡è©•ä¼°ç”Ÿæˆåœ–ç‰‡æ•¸
INFERENCE_STEPS = 15               # ç”Ÿåœ–æ¨ç†æ­¥æ•¸ (é€Ÿåº¦å„ªå…ˆ)
```

## ğŸ’¡ **çµè«–**

**é€™å€‹æƒ³æ³•éå¸¸å¯è¡Œä¸”æœ‰åƒ¹å€¼ï¼** 

ä¸»è¦å„ªé»ï¼š
- âœ… ç²å¾—çœŸå¯¦çš„æ€§èƒ½æŒ‡æ¨™
- âœ… å³æ™‚ç›£æ§è¨“ç·´æ•ˆæœ  
- âœ… æŠ€è¡“ä¸Šå®Œå…¨å¯å¯¦ç¾

ä¸»è¦è€ƒé‡ï¼š
- âš ï¸ éœ€è¦é¡å¤–çš„è¨ˆç®—è³‡æº
- âš ï¸ æœƒå¢åŠ ä¸€äº›è¨“ç·´æ™‚é–“
- âš ï¸ å¯¦æ–½éœ€è¦ä¸€å®šçš„é–‹ç™¼å·¥ä½œ

**å»ºè­°å…ˆå¯¦æ–½ä¸€å€‹ç°¡åŒ–ç‰ˆæœ¬é€²è¡Œæ¸¬è©¦ï¼Œå¦‚æœæ•ˆæœå¥½å†é€²è¡Œå…¨é¢å„ªåŒ–ã€‚**

æ‚¨è¦ºå¾—é€™å€‹å¯¦æ–½æ–¹æ¡ˆå¦‚ä½•ï¼Ÿæˆ‘å¯ä»¥é–‹å§‹ä¿®æ”¹ `train_lora.py` ä¾†å¯¦ç¾é€™å€‹åŠŸèƒ½ï¼
