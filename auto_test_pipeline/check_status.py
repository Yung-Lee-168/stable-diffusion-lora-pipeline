#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿç‹€æ…‹æª¢æŸ¥ - æª¢æŸ¥è¨“ç·´ç’°å¢ƒå’Œç¾æœ‰æª”æ¡ˆ
"""
import os
import sys
from pathlib import Path
import glob

def check_training_status():
    """æª¢æŸ¥è¨“ç·´ç‹€æ…‹"""
    print("ğŸ” æª¢æŸ¥ LoRA è¨“ç·´ç‹€æ…‹...")
    print("=" * 50)
    
    current_dir = Path(__file__).parent
    
    # æª¢æŸ¥è¨“ç·´è³‡æ–™
    train_data_dir = current_dir / "lora_train_set" / "10_test"
    if train_data_dir.exists():
        images = list(train_data_dir.glob("*.jpg")) + list(train_data_dir.glob("*.jpeg"))
        texts = list(train_data_dir.glob("*.txt"))
        print(f"ğŸ“ è¨“ç·´è³‡æ–™ç›®éŒ„: {train_data_dir}")
        print(f"ğŸ–¼ï¸ åœ–ç‰‡æ•¸é‡: {len(images)}")
        print(f"ğŸ“ æ¨™ç±¤æ•¸é‡: {len(texts)}")
        
        if len(images) != len(texts):
            print("âš ï¸ åœ–ç‰‡å’Œæ¨™ç±¤æ•¸é‡ä¸ä¸€è‡´ï¼")
        else:
            print("âœ… åœ–ç‰‡å’Œæ¨™ç±¤æ•¸é‡ä¸€è‡´")
    else:
        print("âŒ è¨“ç·´è³‡æ–™ç›®éŒ„ä¸å­˜åœ¨")
    
    print()
    
    # æª¢æŸ¥è¼¸å‡ºç›®éŒ„
    output_dir = current_dir / "lora_output"
    if output_dir.exists():
        print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {output_dir}")
        
        # æª¢æŸ¥ LoRA æª”æ¡ˆ
        lora_files = list(output_dir.glob("*.safetensors"))
        backup_files = list(output_dir.glob("backup_*.safetensors"))
        
        print(f"ğŸ¯ LoRA æª”æ¡ˆ: {len(lora_files)}")
        for f in lora_files:
            if not f.name.startswith("backup_"):
                size_mb = f.stat().st_size / (1024 * 1024)
                print(f"   - {f.name} ({size_mb:.1f} MB)")
        
        print(f"ğŸ’¾ å‚™ä»½æª”æ¡ˆ: {len(backup_files)}")
        for f in backup_files:
            size_mb = f.stat().st_size / (1024 * 1024)
            print(f"   - {f.name} ({size_mb:.1f} MB)")
        
        # æª¢æŸ¥ç‹€æ…‹ç›®éŒ„
        state_dirs = [d for d in output_dir.iterdir() if d.is_dir() and d.name.startswith("state_")]
        print(f"ğŸ”„ ç‹€æ…‹ç›®éŒ„: {len(state_dirs)}")
        for d in state_dirs:
            print(f"   - {d.name}")
        
        # æª¢æŸ¥æ—¥èªŒ
        log_files = list(output_dir.glob("*.log"))
        print(f"ğŸ“œ æ—¥èªŒæª”æ¡ˆ: {len(log_files)}")
        for f in log_files:
            print(f"   - {f.name}")
        
    else:
        print("ğŸ“ è¼¸å‡ºç›®éŒ„ä¸å­˜åœ¨ (å°‡åœ¨é¦–æ¬¡è¨“ç·´æ™‚å‰µå»º)")
    
    print()
    
    # æª¢æŸ¥è…³æœ¬
    scripts = [
        "train_lora.py",
        "train_lora_monitor.py", 
        "train_lora_monitored_new.py",
        "infer_lora_direct.py"
    ]
    
    print("ğŸ”§ è…³æœ¬æª¢æŸ¥:")
    for script in scripts:
        script_path = current_dir / script
        if script_path.exists():
            print(f"âœ… {script}")
        else:
            print(f"âŒ {script} (ä¸å­˜åœ¨)")
    
    print()
    
    # æª¢æŸ¥è¨“ç·´ç’°å¢ƒ
    print("ğŸŒ ç’°å¢ƒæª¢æŸ¥:")
    
    # æª¢æŸ¥ Python ç‰ˆæœ¬
    print(f"ğŸ Python ç‰ˆæœ¬: {sys.version.split()[0]}")
    
    # æª¢æŸ¥ SD WebUI è·¯å¾‘
    webui_path = current_dir.parent
    if (webui_path / "webui.py").exists():
        print(f"âœ… SD WebUI è·¯å¾‘: {webui_path}")
    else:
        print(f"âŒ SD WebUI è·¯å¾‘ç„¡æ•ˆ: {webui_path}")
    
    # æª¢æŸ¥åŸºç¤æ¨¡å‹
    models_path = webui_path / "models" / "Stable-diffusion"
    if models_path.exists():
        model_files = list(models_path.glob("*.safetensors")) + list(models_path.glob("*.ckpt"))
        print(f"ğŸ­ åŸºç¤æ¨¡å‹æ•¸é‡: {len(model_files)}")
        if model_files:
            print(f"   - æœ€æ–°: {model_files[-1].name}")
    
    print()
    print("ğŸ‰ ç‹€æ…‹æª¢æŸ¥å®Œæˆï¼")

if __name__ == "__main__":
    check_training_status()
