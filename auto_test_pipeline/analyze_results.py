import os
import json
import shutil
from datetime import datetime
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from skimage.metrics import structural_similarity as ssim
import cv2
import torch
from transformers import CLIPProcessor, CLIPModel
import traceback
import sys

# è‡ªå®šç¾© JSON åºåˆ—åŒ–å™¨ä»¥è™•ç† NumPy é¡å‹
class CustomJSONEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.bool_):
            return bool(obj)
        return super(CustomJSONEncoder, self).default(obj)

# å˜—è©¦åŒ¯å…¥ FashionCLIP
try:
    sys.path.append("..")
    import ç‰¹å¾µå€¼
    FASHION_CLIP_AVAILABLE = True
    print("âœ… æˆåŠŸåŒ¯å…¥ ç‰¹å¾µå€¼.py")
except Exception as e:
    print(f"âš ï¸ åŒ¯å…¥ç‰¹å¾µå€¼.py å¤±æ•—ï¼š{e}")
    FASHION_CLIP_AVAILABLE = False

def calculate_image_similarity(img1_path, img2_path):
    """è¨ˆç®—å…©å¼µåœ–ç‰‡çš„ç›¸ä¼¼åº¦"""
    try:
        # è®€å–åœ–ç‰‡
        img1 = cv2.imread(img1_path)
        img2 = cv2.imread(img2_path)
        
        if img1 is None or img2 is None:
            return None
        
        # è½‰æ›ç‚ºç°éš
        gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
        gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
        
        # ç¢ºä¿å°ºå¯¸ä¸€è‡´
        if gray1.shape != gray2.shape:
            gray2 = cv2.resize(gray2, (gray1.shape[1], gray1.shape[0]))
        
        # è¨ˆç®— SSIM
        similarity = ssim(gray1, gray2)
        return similarity
        
    except Exception as e:
        print(f"âŒ è¨ˆç®—ç›¸ä¼¼åº¦å¤±æ•—: {str(e)}")
        return None

def compare_images_with_originals(report):
    """æ¯”è¼ƒç”Ÿæˆåœ–ç‰‡èˆ‡åŸå§‹è¨“ç·´åœ–ç‰‡"""
    print("ğŸ” æ¯”è¼ƒç”Ÿæˆåœ–ç‰‡èˆ‡åŸå§‹åœ–ç‰‡...")
    
    comparison_results = {
        "original_count": 0,
        "generated_count": 0,
        "backup_available": False,
        "resolution_consistency": True,
        "similarity_scores": [],
        "average_similarity": 0.0,
        "fashion_analysis": {}
    }
    
    # åˆå§‹åŒ– FashionCLIP
    fashion_model, fashion_processor, device = None, None, None
    labels_dict = {}
    
    if FASHION_CLIP_AVAILABLE:
        fashion_model, fashion_processor, device = load_fashion_clip_model()
        if fashion_model and fashion_processor:
            # æº–å‚™ç‰¹å¾µæ¨™ç±¤
            for k, v in ç‰¹å¾µå€¼.__dict__.items():
                if isinstance(v, (list, tuple)):
                    labels_dict[k] = list(v)
                elif isinstance(v, dict):
                    for kk, vv in v.items():
                        if isinstance(vv, (list, tuple)):
                            labels_dict[kk] = list(vv)
            print(f"âœ… FashionCLIP æº–å‚™å®Œæˆï¼Œå…± {len(labels_dict)} å€‹ç‰¹å¾µé¡åˆ¥")
    
    # æª¢æŸ¥åŸå§‹åœ–ç‰‡
    original_path = "lora_train_set/10_test"
    backup_path = "lora_train_set/10_test/original_backup"
    
    if os.path.exists(original_path):
        # çµ±è¨ˆæ‰€æœ‰åœ–ç‰‡æ ¼å¼ï¼šjpg, jpeg, png
        original_images = [f for f in os.listdir(original_path) 
                          if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        comparison_results["original_count"] = len(original_images)
        
        # æª¢æŸ¥å‚™ä»½æ˜¯å¦å­˜åœ¨
        if os.path.exists(backup_path):
            comparison_results["backup_available"] = True
            print(f"  ğŸ“ æ‰¾åˆ°åŸå§‹åœ–ç‰‡å‚™ä»½ï¼š{backup_path}")
        
        # æª¢æŸ¥ç”Ÿæˆçš„æ¸¬è©¦åœ–ç‰‡
        if os.path.exists("test_images"):
            test_images = [f for f in os.listdir("test_images") if f.endswith('.png')]
            comparison_results["generated_count"] = len(test_images)
            
            print(f"  ğŸ“Š åŸå§‹åœ–ç‰‡ï¼š{len(original_images)} å¼µ")
            print(f"  ğŸ“Š ç”Ÿæˆåœ–ç‰‡ï¼š{len(test_images)} å¼µ")
            
            # è¨ˆç®—åœ–ç‰‡ç›¸ä¼¼åº¦ - æ¯”è¼ƒæ‰€æœ‰åœ–ç‰‡
            if len(original_images) > 0 and len(test_images) > 0:
                similarity_scores = []
                fashion_comparisons = []
                
                # æ¯”è¼ƒæ‰€æœ‰åœ–ç‰‡å°
                max_compare = min(len(original_images), len(test_images))
                
                for i in range(max_compare):
                    original_img_path = os.path.join(original_path, original_images[i])
                    test_img_path = os.path.join("test_images", test_images[i])
                    
                    # SSIM ç›¸ä¼¼åº¦
                    similarity = calculate_image_similarity(original_img_path, test_img_path)
                    if similarity is not None:
                        similarity_scores.append(similarity)
                        print(f"  ğŸ“ˆ SSIM ç›¸ä¼¼åº¦ {original_images[i]} vs {test_images[i]}: {similarity:.3f}")
                    
                    # FashionCLIP åˆ†æ
                    if fashion_model and fashion_processor and labels_dict:
                        print(f"  ğŸ¨ FashionCLIP åˆ†æ {original_images[i]} vs {test_images[i]}...")
                        
                        orig_analysis = analyze_image_with_fashion_clip(
                            original_img_path, fashion_model, fashion_processor, device, labels_dict
                        )
                        gen_analysis = analyze_image_with_fashion_clip(
                            test_img_path, fashion_model, fashion_processor, device, labels_dict
                        )
                        
                        if orig_analysis and gen_analysis:
                            feature_comparison = compare_fashion_features(orig_analysis, gen_analysis)
                            if feature_comparison:
                                fashion_comparisons.append({
                                    "original_image": original_images[i],
                                    "generated_image": test_images[i],
                                    "original_analysis": orig_analysis,
                                    "generated_analysis": gen_analysis,
                                    "feature_comparison": feature_comparison
                                })
                                
                                # è¨ˆç®—æ•´é«”ç‰¹å¾µç›¸ä¼¼åº¦
                                overall_similarity = sum(
                                    comp["combined_similarity"] for comp in feature_comparison.values()
                                ) / len(feature_comparison)
                                print(f"  ğŸ¯ ç‰¹å¾µç›¸ä¼¼åº¦ {original_images[i]} vs {test_images[i]}: {overall_similarity:.3f}")
                
                if similarity_scores:
                    comparison_results["similarity_scores"] = similarity_scores
                    comparison_results["average_similarity"] = sum(similarity_scores) / len(similarity_scores)
                    print(f"  ğŸ“Š å¹³å‡ SSIM ç›¸ä¼¼åº¦ï¼š{comparison_results['average_similarity']:.3f}")
                
                if fashion_comparisons:
                    comparison_results["fashion_analysis"] = {
                        "comparisons": fashion_comparisons,
                        "total_comparisons": len(fashion_comparisons),
                        "feature_categories": list(labels_dict.keys())
                    }
                    print(f"  ğŸ¨ å®Œæˆ {len(fashion_comparisons)} å°åœ–ç‰‡çš„ FashionCLIP åˆ†æ")
    
    return comparison_results

def create_comparison_gallery():
    """å»ºç«‹åœ–ç‰‡æ¯”è¼ƒç•«å»Š"""
    print("ğŸ¨ å»ºç«‹åœ–ç‰‡æ¯”è¼ƒç•«å»Š...")
    
    gallery_html = ""
    
    # æª¢æŸ¥åŸå§‹åœ–ç‰‡å’Œç”Ÿæˆåœ–ç‰‡
    original_path = "lora_train_set/10_test"
    test_path = "test_images"
    
    if os.path.exists(original_path) and os.path.exists(test_path):
        # çµ±è¨ˆæ‰€æœ‰åœ–ç‰‡æ ¼å¼ï¼šjpg, jpeg, png
        original_images = [f for f in os.listdir(original_path) 
                          if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        test_images = [f for f in os.listdir(test_path) if f.endswith('.png')]
        
        # å‰µå»ºæ¯”è¼ƒç•«å»Š
        gallery_html = """
        <div class="comparison-gallery">
            <h3>ğŸ” åœ–ç‰‡æ¯”è¼ƒç•«å»Š</h3>
            <div class="gallery-grid">
        """
        
        # é¡¯ç¤ºåŸå§‹åœ–ç‰‡
        gallery_html += """
        <div class="gallery-section">
            <h4>ğŸ“š åŸå§‹è¨“ç·´åœ–ç‰‡</h4>
            <div class="image-row">
        """
        
        for i, img in enumerate(original_images):  # é¡¯ç¤ºæ‰€æœ‰åœ–ç‰‡
            gallery_html += f"""
            <div class="image-item">
                <div class="image-container">
                    <img src="../{original_path}/{img}" alt="{img}">
                </div>
                <p>{img}</p>
            </div>
            """
        
        gallery_html += """
            </div>
        </div>
        """
        
        # é¡¯ç¤ºç”Ÿæˆåœ–ç‰‡
        gallery_html += """
        <div class="gallery-section">
            <h4>ğŸ¨ ç”Ÿæˆæ¸¬è©¦åœ–ç‰‡</h4>
            <div class="image-row">
        """
        
        for i, img in enumerate(test_images):  # é¡¯ç¤ºæ‰€æœ‰åœ–ç‰‡
            gallery_html += f"""
            <div class="image-item">
                <div class="image-container">
                    <img src="../{test_path}/{img}" alt="{img}">
                </div>
                <p>{img}</p>
            </div>
            """
        
        gallery_html += """
            </div>
        </div>
        </div>
        """
    
    return gallery_html

def load_training_progress_records():
    """è¼‰å…¥è¨“ç·´é€²åº¦è¨˜éŒ„"""
    print("ğŸ“ˆ è¼‰å…¥è¨“ç·´é€²åº¦è¨˜éŒ„...")
    
    training_records = {
        "progress_available": False,
        "training_history": [],
        "training_summary": {},
        "training_metrics": {},
        "training_charts": []
    }
    
    # æª¢æŸ¥è¨“ç·´æ—¥èªŒç›®éŒ„
    log_dir = "training_logs"
    if os.path.exists(log_dir):
        # å°‹æ‰¾æœ€æ–°çš„è¨“ç·´å ±å‘Š
        report_files = [f for f in os.listdir(log_dir) if f.startswith("training_report_") and f.endswith(".json")]
        if report_files:
            # æŒ‰æ™‚é–“æ’åºï¼Œå–æœ€æ–°çš„
            report_files.sort(key=lambda x: os.path.getmtime(os.path.join(log_dir, x)), reverse=True)
            latest_report = os.path.join(log_dir, report_files[0])
            
            try:
                with open(latest_report, 'r', encoding='utf-8') as f:
                    training_data = json.load(f)
                    
                training_records["progress_available"] = True
                training_records["training_summary"] = training_data.get("training_summary", {})
                training_records["training_metrics"] = training_data.get("training_metrics", {})
                training_records["training_evaluation"] = training_data.get("training_evaluation", {})
                training_records["recommendations"] = training_data.get("recommendations", [])
                
                print(f"âœ… è¼‰å…¥è¨“ç·´è¨˜éŒ„ï¼š{latest_report}")
                print(f"  ğŸ“Š ç¸½æ­¥æ•¸ï¼š{training_records['training_summary'].get('total_steps', 'N/A')}")
                print(f"  ğŸ¯ æœ€ä½³æå¤±ï¼š{training_records['training_summary'].get('best_loss', 'N/A')}")
                print(f"  ğŸ“ˆ æå¤±æ”¹å–„ï¼š{training_records['training_metrics'].get('loss_improvement', 'N/A')}")
                
            except Exception as e:
                print(f"âŒ è¼‰å…¥è¨“ç·´è¨˜éŒ„å¤±æ•—ï¼š{e}")
        
        # å°‹æ‰¾è¨“ç·´åœ–è¡¨
        chart_files = [f for f in os.listdir(log_dir) if f.startswith("training_chart_") and f.endswith(".png")]
        if chart_files:
            chart_files.sort(key=lambda x: os.path.getmtime(os.path.join(log_dir, x)), reverse=True)
            training_records["training_charts"] = [os.path.join(log_dir, f) for f in chart_files[:3]]  # æœ€æ–°3å€‹
            print(f"ğŸ“Š æ‰¾åˆ° {len(training_records['training_charts'])} å€‹è¨“ç·´åœ–è¡¨")
    
    return training_records

def analyze_training_results():
    """åˆ†æè¨“ç·´çµæœä¸¦ç”¢ç”Ÿå ±å‘Š"""
    
    print("ğŸ“Š é–‹å§‹åˆ†æè¨“ç·´çµæœ...")
    
    # å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾å’Œæ™‚é–“æˆ³è¨˜
    output_dir = "test_results"
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    
    report = {
        "analysis_time": datetime.now().isoformat(),
        "training_info": {},
        "model_info": {},
        "test_results": {},
        "image_comparison": {},
        "training_progress": {},
        "summary": {}
    }
    
    # ğŸ¯ æ–°å¢ï¼šè¼‰å…¥è¨“ç·´é€²åº¦è¨˜éŒ„
    training_records = load_training_progress_records()
    report["training_progress"] = training_records
    
    # åˆ†æè¨“ç·´è³‡æ–™
    print("ğŸ“š åˆ†æè¨“ç·´è³‡æ–™...")
    if os.path.exists("lora_train_set/10_test"):
        # çµ±è¨ˆæ‰€æœ‰åœ–ç‰‡æ ¼å¼ï¼šjpg, jpeg, png
        train_images = [f for f in os.listdir("lora_train_set/10_test") 
                       if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        train_texts = [f for f in os.listdir("lora_train_set/10_test") if f.endswith('.txt')]
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å‚™ä»½è³‡æ–™å¤¾
        backup_exists = os.path.exists("lora_train_set/10_test/original_backup")
        
        report["training_info"] = {
            "train_image_count": len(train_images),
            "train_text_count": len(train_texts),
            "training_folder": "10_test",
            "repeat_count": 10,
            "total_training_steps": len(train_images) * 10,
            "backup_created": backup_exists
        }
        
        print(f"  è¨“ç·´åœ–ç‰‡ï¼š{len(train_images)} å¼µ")
        print(f"  æ–‡å­—æª”æ¡ˆï¼š{len(train_texts)} å€‹")
        print(f"  ç¸½è¨“ç·´æ­¥æ•¸ï¼š{len(train_images) * 10}")
        
        if backup_exists:
            backup_images = [f for f in os.listdir("lora_train_set/10_test/original_backup") 
                            if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
            print(f"  åŸå§‹å‚™ä»½ï¼š{len(backup_images)} å¼µ")
    
    # åˆ†æ LoRA æ¨¡å‹
    print("ğŸ“ åˆ†æ LoRA æ¨¡å‹...")
    if os.path.exists("lora_output"):
        lora_files = [f for f in os.listdir("lora_output") if f.endswith('.safetensors')]
        if lora_files:
            latest_lora = max(lora_files, key=lambda x: os.path.getmtime(os.path.join("lora_output", x)))
            lora_size = os.path.getsize(os.path.join("lora_output", latest_lora)) / (1024*1024)
            
            report["model_info"] = {
                "filename": latest_lora,
                "size_mb": round(lora_size, 2),
                "total_models": len(lora_files),
                "creation_time": datetime.fromtimestamp(
                    os.path.getctime(os.path.join("lora_output", latest_lora))
                ).isoformat()
            }
            
            print(f"  LoRA æ¨¡å‹ï¼š{latest_lora}")
            print(f"  æª”æ¡ˆå¤§å°ï¼š{lora_size:.2f} MB")
            print(f"  ç¸½æ¨¡å‹æ•¸ï¼š{len(lora_files)}")
    
    # åˆ†ææ¸¬è©¦åœ–ç‰‡
    print("ğŸ¨ åˆ†ææ¸¬è©¦åœ–ç‰‡...")
    if os.path.exists("test_images"):
        test_images = [f for f in os.listdir("test_images") if f.endswith('.png')]
        
        # è®€å–æ¸¬è©¦è³‡è¨Š
        test_info = {}
        if os.path.exists("test_images/test_info.json"):
            with open("test_images/test_info.json", 'r', encoding='utf-8') as f:
                test_info = json.load(f)
        
        # åˆ†æåœ–ç‰‡å±¬æ€§
        image_analysis = []
        for img_file in test_images:
            img_path = os.path.join("test_images", img_file)
            try:
                with Image.open(img_path) as img:
                    image_analysis.append({
                        "filename": img_file,
                        "size": f"{img.width}x{img.height}",
                        "mode": img.mode,
                        "file_size_kb": round(os.path.getsize(img_path) / 1024, 2)
                    })
            except Exception as e:
                print(f"  ç„¡æ³•åˆ†æåœ–ç‰‡ {img_file}: {str(e)}")
        
        report["test_results"] = {
            "test_image_count": len(test_images),
            "success_rate": test_info.get("success_count", 0) / max(test_info.get("total_count", 1), 1) * 100,
            "test_info": test_info,
            "image_analysis": image_analysis
        }
        
        print(f"  æ¸¬è©¦åœ–ç‰‡ï¼š{len(test_images)} å¼µ")
        print(f"  æˆåŠŸç‡ï¼š{report['test_results']['success_rate']:.1f}%")
    
    # ğŸ¯ æ–°å¢ï¼šåœ–ç‰‡æ¯”è¼ƒåˆ†æ
    report["image_comparison"] = compare_images_with_originals(report)
    
    # ğŸ¯ æ–°å¢ï¼šä¸‰åŸºæº–é»æ€§èƒ½è©•ä¼°
    if "image_comparison" in report and report["image_comparison"].get("fashion_analysis"):
        print("ğŸ“Š åŸ·è¡Œä¸‰åŸºæº–é»æ€§èƒ½è©•ä¼°...")
        benchmark_analysis = benchmark_results_with_three_points(report["image_comparison"])
        report["benchmark_analysis"] = benchmark_analysis
        
        # é¡¯ç¤ºè©•ä¼°çµæœ
        if benchmark_analysis["total_evaluated"] > 0:
            perf_dist = benchmark_analysis["performance_distribution"]
            print(f"ğŸ¯ æ€§èƒ½åˆ†å¸ƒ: å„ªç§€={perf_dist['excellent']}, è‰¯å¥½={perf_dist['good']}, ä¸€èˆ¬={perf_dist['average']}, å¾…æ”¹å–„={perf_dist['poor']}")
            
            if benchmark_analysis["recommendations"]:
                print("ğŸ’¡ æ”¹å–„å»ºè­°:")
                for rec in benchmark_analysis["recommendations"]:
                    print(f"   {rec}")
    
    # ğŸ¯ æ–°å¢ï¼šLoRA èª¿å„ªæŒ‡æ¨™åˆ†æ
    print("ğŸ”§ åŸ·è¡Œ LoRA èª¿å„ªæŒ‡æ¨™åˆ†æ...")
    lora_tuning_metrics = calculate_lora_tuning_metrics(report)
    report["lora_tuning"] = lora_tuning_metrics
    
    # ğŸ¯ æ–°å¢ï¼šç”Ÿæˆèª¿å„ªç›®æ¨™
    tuning_targets = generate_lora_tuning_target(report)
    report["tuning_targets"] = tuning_targets
    
    print(f"ğŸ¯ LoRA èª¿å„ªåˆ†æ•¸: {lora_tuning_metrics.get('overall_tuning_score', 0):.3f}")
    if lora_tuning_metrics.get("tuning_recommendations"):
        print("ğŸ”§ èª¿å„ªå»ºè­°:")
        for rec in lora_tuning_metrics["tuning_recommendations"]:
            print(f"   {rec}")
    
    # ç”¢ç”Ÿç¸½çµ
    report["summary"] = {
        "training_completed": "model_info" in report and bool(report["model_info"]),
        "testing_completed": "test_results" in report and report["test_results"]["test_image_count"] > 0,
        "comparison_completed": "image_comparison" in report and report["image_comparison"]["generated_count"] > 0,
        "overall_success": False
    }
    
    # åˆ¤å®šæ•´é«”æ˜¯å¦æˆåŠŸ
    if (report["summary"]["training_completed"] and 
        report["summary"]["testing_completed"] and 
        report["test_results"]["success_rate"] > 0):
        report["summary"]["overall_success"] = True
        print("âœ… æ•´é«”æµç¨‹æˆåŠŸ")
    else:
        print("âŒ æ•´é«”æµç¨‹æœ‰å•é¡Œ")
    
    # å„²å­˜ JSON å ±å‘Š
    report_path = os.path.join(output_dir, f"training_report_{timestamp}.json")
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False, cls=CustomJSONEncoder)
    
    # ç”¢ç”Ÿ HTML å ±å‘Š
    html_report = generate_html_report(report, timestamp)
    html_path = os.path.join(output_dir, f"training_report_{timestamp}.html")
    with open(html_path, 'w', encoding='utf-8') as f:
        f.write(html_report)
    
    # ç”¢ç”Ÿåœ–è¡¨
    chart_path = generate_charts(report, output_dir, timestamp)
    
    print(f"âœ… åˆ†æå®Œæˆ")
    print(f"ğŸ“‹ JSON å ±å‘Šï¼š{report_path}")
    print(f"ğŸŒ HTML å ±å‘Šï¼š{html_path}")
    print(f"ğŸ“Š åœ–è¡¨ï¼š{chart_path}")
    
    return report

def create_training_progress_section(training_records):
    """å»ºç«‹è¨“ç·´é€²åº¦å€æ®µçš„ HTML"""
    if not training_records.get("progress_available", False):
        return """
        <div class="section">
            <h2>ğŸ“ˆ è¨“ç·´é€²åº¦è¨˜éŒ„</h2>
            <p class="warning">âš ï¸ æ²’æœ‰æ‰¾åˆ°è¨“ç·´é€²åº¦è¨˜éŒ„</p>
            <p>å»ºè­°ä½¿ç”¨ training_progress_monitor.py ä¾†ç›£æ§è¨“ç·´éç¨‹</p>
        </div>
        """
    
    training_summary = training_records.get("training_summary", {})
    training_metrics = training_records.get("training_metrics", {})
    training_evaluation = training_records.get("training_evaluation", {})
    
    html = """
    <div class="section">
        <h2>ğŸ“ˆ è¨“ç·´é€²åº¦è¨˜éŒ„</h2>
        <div class="training-progress">
    """
    
    # è¨“ç·´ç¸½çµ
    html += """
        <div class="training-summary">
            <h4>ğŸ“Š è¨“ç·´ç¸½çµ</h4>
            <table>
                <tr><th>é …ç›®</th><th>æ•¸å€¼</th></tr>
    """
    
    summary_items = [
        ("ç¸½è¨“ç·´æ­¥æ•¸", training_summary.get("total_steps", "N/A")),
        ("æœ€ä½³æå¤±", f"{training_summary.get('best_loss', 0):.4f}" if isinstance(training_summary.get('best_loss'), (int, float)) else "N/A"),
        ("æœ€çµ‚æå¤±", f"{training_summary.get('final_loss', 0):.4f}" if isinstance(training_summary.get('final_loss'), (int, float)) else "N/A"),
        ("æœ€çµ‚å­¸ç¿’ç‡", f"{training_summary.get('final_lr', 0):.6f}" if isinstance(training_summary.get('final_lr'), (int, float)) else "N/A")
    ]
    
    for item, value in summary_items:
        html += f"<tr><td>{item}</td><td>{value}</td></tr>"
    
    html += """
            </table>
        </div>
    """
    
    # è¨“ç·´æŒ‡æ¨™
    html += """
        <div class="training-metrics">
            <h4>ğŸ“ˆ è¨“ç·´æŒ‡æ¨™</h4>
            <table>
                <tr><th>æŒ‡æ¨™</th><th>æ•¸å€¼</th></tr>
    """
    
    metrics_items = [
        ("æå¤±æ”¹å–„", f"{training_metrics.get('loss_improvement', 0):.4f}" if isinstance(training_metrics.get('loss_improvement'), (int, float)) else "N/A"),
        ("æå¤±é™ä½ç‡", f"{training_metrics.get('loss_reduction_rate', 0):.2f}%" if isinstance(training_metrics.get('loss_reduction_rate'), (int, float)) else "N/A"),
        ("å¹³å‡æå¤±", f"{training_metrics.get('average_loss', 0):.4f}" if isinstance(training_metrics.get('average_loss'), (int, float)) else "N/A")
    ]
    
    for metric, value in metrics_items:
        html += f"<tr><td>{metric}</td><td>{value}</td></tr>"
    
    html += """
            </table>
        </div>
    """
    
    # è¨“ç·´è©•ä¼°
    if training_evaluation:
        html += """
        <div class="training-evaluation">
            <h4>ğŸ¯ è¨“ç·´è©•ä¼°</h4>
            <table>
                <tr><th>è©•ä¼°é …ç›®</th><th>åˆ†æ•¸/ç­‰ç´š</th></tr>
        """
        
        eval_items = [
            ("æ€§èƒ½ç­‰ç´š", training_evaluation.get('performance_grade', 'N/A').upper()),
            ("è¨“ç·´æ•ˆç‡", f"{training_evaluation.get('efficiency', 0):.4f}" if isinstance(training_evaluation.get('efficiency'), (int, float)) else "N/A"),
            ("æ”¶æ–‚ç‡", f"{training_evaluation.get('convergence_rate', 0):.4f}" if isinstance(training_evaluation.get('convergence_rate'), (int, float)) else "N/A")
        ]
        
        for item, value in eval_items:
            grade_class = ""
            if "ç­‰ç´š" in item:
                if value == "EXCELLENT":
                    grade_class = "excellent"
                elif value == "GOOD":
                    grade_class = "good"
                elif value == "AVERAGE":
                    grade_class = "average"
                else:
                    grade_class = "poor"
                    
            html += f"<tr class='{grade_class}'><td>{item}</td><td>{value}</td></tr>"
        
        html += """
            </table>
        </div>
        """
    
    html += """
        </div>
    </div>
    """
    
    return html

def generate_html_report(report, timestamp):
    """ç”¢ç”Ÿ HTML æ ¼å¼çš„å ±å‘Š"""
    
    # å»ºç«‹æ¯”è¼ƒç•«å»Š
    comparison_gallery = create_comparison_gallery()
    
    # åœ–è¡¨æª”æ¡ˆåç¨±ï¼ˆåŒ…å«æ™‚é–“æˆ³è¨˜ï¼‰
    chart_filename = f"training_charts_{timestamp}.png"
    
    # ç›¸ä¼¼åº¦åˆ†æ
    similarity_section = ""
    if "image_comparison" in report and report["image_comparison"].get("similarity_scores"):
        similarity_scores = report["image_comparison"]["similarity_scores"]
        avg_similarity = report["image_comparison"]["average_similarity"]
        
        similarity_section = f"""
        <div class="section">
            <h2>ğŸ“ˆ SSIM ç›¸ä¼¼åº¦åˆ†æ</h2>
            <table>
                <tr><th>é …ç›®</th><th>æ•¸å€¼</th></tr>
                <tr><td>å¹³å‡ç›¸ä¼¼åº¦</td><td>{avg_similarity:.3f}</td></tr>
                <tr><td>æœ€é«˜ç›¸ä¼¼åº¦</td><td>{max(similarity_scores):.3f}</td></tr>
                <tr><td>æœ€ä½ç›¸ä¼¼åº¦</td><td>{min(similarity_scores):.3f}</td></tr>
                <tr><td>æ¯”è¼ƒåœ–ç‰‡æ•¸</td><td>{len(similarity_scores)}</td></tr>
            </table>
        </div>
        """
    
    # FashionCLIP åˆ†æçµæœ
    fashion_section = ""
    if "image_comparison" in report and report["image_comparison"].get("fashion_analysis"):
        fashion_data = report["image_comparison"]["fashion_analysis"]
        if fashion_data.get("comparisons"):
            fashion_section = """
            <div class="section">
                <h2>ğŸ¨ FashionCLIP ç‰¹å¾µåˆ†æ</h2>
                <div class="fashion-analysis">
            """
            
            for comp in fashion_data["comparisons"][:3]:  # åªé¡¯ç¤ºå‰3å€‹æ¯”è¼ƒ
                fashion_section += f"""
                <div class="comparison-pair">
                    <h4>ğŸ“¸ {comp['original_image']} vs {comp['generated_image']}</h4>
                    <table>
                        <tr><th>ç‰¹å¾µé¡åˆ¥</th><th>åŸå§‹åœ–ç‰‡</th><th>ç”Ÿæˆåœ–ç‰‡</th><th>ç›¸ä¼¼åº¦</th></tr>
                """
                
                for cat, feature_comp in comp["feature_comparison"].items():
                    fashion_section += f"""
                    <tr>
                        <td>{cat}</td>
                        <td>{feature_comp['original_label']}</td>
                        <td>{feature_comp['generated_label']}</td>
                        <td>{feature_comp['combined_similarity']:.3f}</td>
                    </tr>
                    """
                
                fashion_section += """
                    </table>
                </div>
                """
            
            fashion_section += """
                </div>
            </div>
            """
    
    # ä¸‰åŸºæº–é»è©•ä¼°çµæœ
    benchmark_section = ""
    if "benchmark_analysis" in report and report["benchmark_analysis"].get("total_evaluated", 0) > 0:
        benchmark_data = report["benchmark_analysis"]
        perf_dist = benchmark_data["performance_distribution"]
        avg_metrics = benchmark_data.get("average_metrics", {})
        
        benchmark_section = f"""
        <div class="section">
            <h2>ğŸ¯ ä¸‰åŸºæº–é»æ€§èƒ½è©•ä¼°</h2>
            <div class="benchmark-summary">
                <h4>ğŸ“Š æ€§èƒ½åˆ†å¸ƒ (å…± {benchmark_data['total_evaluated']} å¼µåœ–ç‰‡)</h4>
                <table>
                    <tr><th>è©•ç´š</th><th>æ•¸é‡</th><th>æ¯”ä¾‹</th></tr>
                    <tr class="excellent"><td>ğŸ¯ å„ªç§€</td><td>{perf_dist['excellent']}</td><td>{perf_dist['excellent']/benchmark_data['total_evaluated']*100:.1f}%</td></tr>
                    <tr class="good"><td>âœ… è‰¯å¥½</td><td>{perf_dist['good']}</td><td>{perf_dist['good']/benchmark_data['total_evaluated']*100:.1f}%</td></tr>
                    <tr class="average"><td>âš ï¸ ä¸€èˆ¬</td><td>{perf_dist['average']}</td><td>{perf_dist['average']/benchmark_data['total_evaluated']*100:.1f}%</td></tr>
                    <tr class="poor"><td>âŒ å¾…æ”¹å–„</td><td>{perf_dist['poor']}</td><td>{perf_dist['poor']/benchmark_data['total_evaluated']*100:.1f}%</td></tr>
                </table>
            </div>
        """
        
        if avg_metrics:
            benchmark_section += f"""
            <div class="benchmark-metrics">
                <h4>ğŸ“ˆ å¹³å‡æŒ‡æ¨™</h4>
                <table>
                    <tr><th>æŒ‡æ¨™</th><th>å¹³å‡å€¼</th><th>åƒè€ƒå€¼</th><th>å·®ç•°</th></tr>
                    <tr><td>ç¸½æå¤±</td><td>{avg_metrics.get('avg_total_loss', 0):.3f}</td><td>0.709</td><td>{avg_metrics.get('avg_total_loss', 0) - 0.709:+.3f}</td></tr>
                    <tr><td>è¦–è¦ºç›¸ä¼¼åº¦</td><td>{avg_metrics.get('avg_visual_similarity', 0):.3f}</td><td>0.326</td><td>{avg_metrics.get('avg_visual_similarity', 0) - 0.326:+.3f}</td></tr>
                    <tr><td>FashionCLIPç›¸ä¼¼åº¦</td><td>{avg_metrics.get('avg_fashion_clip_similarity', 0):.3f}</td><td>0.523</td><td>{avg_metrics.get('avg_fashion_clip_similarity', 0) - 0.523:+.3f}</td></tr>
                    <tr><td>è‰²å½©ç›¸ä¼¼åº¦</td><td>{avg_metrics.get('avg_color_similarity', 0):.3f}</td><td>0.012</td><td>{avg_metrics.get('avg_color_similarity', 0) - 0.012:+.3f}</td></tr>
                </table>
            </div>
            """
        
        if benchmark_data.get("recommendations"):
            benchmark_section += """
            <div class="recommendations">
                <h4>ğŸ’¡ æ”¹å–„å»ºè­°</h4>
                <ul>
            """
            for rec in benchmark_data["recommendations"]:
                benchmark_section += f"<li>{rec}</li>"
            
            benchmark_section += """
                </ul>
            </div>
            """
        
        benchmark_section += """
        </div>
        """
    
    # LoRA èª¿å„ªæŒ‡æ¨™çµæœ
    lora_tuning_section = ""
    if "lora_tuning" in report and report["lora_tuning"].get("overall_tuning_score", 0) > 0:
        lora_data = report["lora_tuning"]
        overall_score = lora_data["overall_tuning_score"]
        overall_grade = lora_data.get("overall_grade", "unknown")
        
        lora_tuning_section = f"""
        <div class="section">
            <h2>ğŸ”§ LoRA èª¿å„ªæŒ‡æ¨™åˆ†æ</h2>
            <div class="lora-summary">
                <h4>ğŸ¯ æ•´é«”èª¿å„ªè©•åˆ†</h4>
                <div class="tuning-score {overall_grade}">
                    <span class="score-value">{overall_score:.3f}</span>
                    <span class="score-grade">({overall_grade.upper()})</span>
                </div>
            </div>
        """
        
        # è©³ç´°æŒ‡æ¨™
        if any(key in lora_data for key in ["training_efficiency", "generation_quality", "feature_preservation"]):
            lora_tuning_section += """
            <div class="detailed-metrics">
                <h4>ğŸ“Š è©³ç´°æŒ‡æ¨™</h4>
                <table>
                    <tr><th>æŒ‡æ¨™é¡åˆ¥</th><th>åˆ†æ•¸</th><th>è©•ç´š</th><th>è©³ç´°è³‡è¨Š</th></tr>
            """
            
            if "training_efficiency" in lora_data:
                eff = lora_data["training_efficiency"]
                lora_tuning_section += f"""
                <tr class="{eff.get('grade', 'unknown')}">
                    <td>ğŸš€ è¨“ç·´æ•ˆç‡</td>
                    <td>{eff.get('score', 0):.3f}</td>
                    <td>{eff.get('grade', 'N/A').upper()}</td>
                    <td>æ­¥æ•¸: {eff.get('steps', 0)}, æ¨¡å‹: {eff.get('model_size_mb', 0):.1f}MB</td>
                </tr>
                """
            
            if "generation_quality" in lora_data:
                qual = lora_data["generation_quality"]
                lora_tuning_section += f"""
                <tr class="{qual.get('grade', 'unknown')}">
                    <td>ğŸ¨ ç”Ÿæˆå“è³ª</td>
                    <td>{qual.get('score', 0):.3f}</td>
                    <td>{qual.get('grade', 'N/A').upper()}</td>
                    <td>SSIM: {qual.get('average_ssim', 0):.3f}, åœ–ç‰‡: {qual.get('image_count', 0)}å¼µ</td>
                </tr>
                """
            
            if "feature_preservation" in lora_data:
                feat = lora_data["feature_preservation"]
                lora_tuning_section += f"""
                <tr class="{feat.get('grade', 'unknown')}">
                    <td>ğŸ¯ ç‰¹å¾µä¿æŒ</td>
                    <td>{feat.get('score', 0):.3f}</td>
                    <td>{feat.get('grade', 'N/A').upper()}</td>
                    <td>FashionCLIP: {feat.get('fashion_clip_similarity', 0):.3f}</td>
                </tr>
                """
            
            lora_tuning_section += """
                </table>
            </div>
            """
        
        # èª¿å„ªå»ºè­°
        if lora_data.get("tuning_recommendations"):
            lora_tuning_section += """
            <div class="tuning-recommendations">
                <h4>ğŸ”§ èª¿å„ªå»ºè­°</h4>
                <ul>
            """
            for rec in lora_data["tuning_recommendations"]:
                lora_tuning_section += f"<li>{rec}</li>"
            
            lora_tuning_section += """
                </ul>
            </div>
            """
        
        lora_tuning_section += """
        </div>
        """
    
    # èª¿å„ªç›®æ¨™
    tuning_target_section = ""
    if "tuning_targets" in report and report["tuning_targets"].get("target_metrics"):
        target_data = report["tuning_targets"]
        current_perf = target_data.get("current_performance", {})
        target_metrics = target_data.get("target_metrics", {})
        
        tuning_target_section = f"""
        <div class="section">
            <h2>ğŸ¯ ä¸‹ä¸€è¼ªèª¿å„ªç›®æ¨™</h2>
            <div class="target-comparison">
                <h4>ğŸ“ˆ ç›®æ¨™ vs ç•¶å‰è¡¨ç¾</h4>
                <table>
                    <tr><th>æŒ‡æ¨™</th><th>ç•¶å‰å€¼</th><th>ç›®æ¨™å€¼</th><th>æ”¹å–„å¹…åº¦</th></tr>
                    <tr><td>ç¸½æå¤±</td><td>{current_perf.get('total_loss', 0):.3f}</td><td>{target_metrics.get('target_total_loss', 0):.3f}</td><td>{((current_perf.get('total_loss', 1) - target_metrics.get('target_total_loss', 1)) / current_perf.get('total_loss', 1) * 100):+.1f}%</td></tr>
                    <tr><td>è¦–è¦ºç›¸ä¼¼åº¦</td><td>{current_perf.get('visual_similarity', 0):.3f}</td><td>{target_metrics.get('target_visual_similarity', 0):.3f}</td><td>{((target_metrics.get('target_visual_similarity', 0) - current_perf.get('visual_similarity', 0)) / max(current_perf.get('visual_similarity', 0.001), 0.001) * 100):+.1f}%</td></tr>
                    <tr><td>FashionCLIPç›¸ä¼¼åº¦</td><td>{current_perf.get('fashion_clip_similarity', 0):.3f}</td><td>{target_metrics.get('target_fashion_clip_similarity', 0):.3f}</td><td>{((target_metrics.get('target_fashion_clip_similarity', 0) - current_perf.get('fashion_clip_similarity', 0)) / max(current_perf.get('fashion_clip_similarity', 0.001), 0.001) * 100):+.1f}%</td></tr>
                </table>
            </div>
        """
        
        if target_data.get("action_plan"):
            tuning_target_section += """
            <div class="action-plan">
                <h4>ğŸ“‹ è¡Œå‹•è¨ˆåŠƒ</h4>
                <ul>
            """
            for action in target_data["action_plan"]:
                tuning_target_section += f"<li>{action}</li>"
            
            tuning_target_section += """
                </ul>
            </div>
            """
        
        if target_data.get("parameter_suggestions"):
            tuning_target_section += """
            <div class="parameter-suggestions">
                <h4>âš™ï¸ åƒæ•¸å»ºè­°</h4>
                <table>
                    <tr><th>åƒæ•¸</th><th>å»ºè­°</th></tr>
            """
            for param, suggestion in target_data["parameter_suggestions"].items():
                tuning_target_section += f"<tr><td>{param}</td><td>{suggestion}</td></tr>"
            
            tuning_target_section += """
                </table>
            </div>
            """
        
        tuning_target_section += """
        </div>
        """
    
    # ğŸ¯ æ–°å¢ï¼šè¨“ç·´é€²åº¦å€æ®µ
    training_progress_section = ""
    if "training_progress" in report:
        training_progress_section = create_training_progress_section(report["training_progress"])

    html = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>LoRA è¨“ç·´å®Œæ•´å ±å‘Š</title>
        <meta charset="utf-8">
        <style>
            body {{ font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; }}
            .header {{ background: #f4f4f4; padding: 20px; border-radius: 5px; }}
            .section {{ margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }}
            .success {{ color: #28a745; }}
            .error {{ color: #dc3545; }}
            .info {{ color: #17a2b8; }}
            .warning {{ color: #ffc107; }}
            table {{ width: 100%; border-collapse: collapse; }}
            th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
            th {{ background-color: #f2f2f2; }}
            .gallery {{ text-align: center; }}
            .summary {{ font-size: 18px; font-weight: bold; }}
            .comparison-gallery {{ margin: 20px 0; }}
            .gallery-section {{ margin: 15px 0; }}
            .image-row {{ display: flex; flex-wrap: wrap; gap: 15px; justify-content: flex-start; }}
            .image-item {{ text-align: center; flex: 0 0 calc(20% - 12px); max-width: calc(20% - 12px); }}
            .image-container {{ height: 200px; display: flex; align-items: center; justify-content: center; border: 1px solid #ddd; border-radius: 5px; background-color: #f9f9f9; }}
            .image-item img {{ max-width: 100%; max-height: 100%; object-fit: contain; }}
            .image-item p {{ margin: 5px 0; font-size: 12px; word-break: break-all; }}
            .fashion-analysis {{ margin: 15px 0; }}
            .comparison-pair {{ margin: 20px 0; padding: 15px; border: 1px solid #ccc; border-radius: 5px; background-color: #fafafa; }}
            .comparison-pair h4 {{ margin: 0 0 10px 0; color: #333; }}
            .benchmark-summary {{ margin: 15px 0; }}
            .benchmark-metrics {{ margin: 15px 0; }}
            .recommendations {{ margin: 15px 0; padding: 15px; border: 1px solid #e67e22; border-radius: 5px; background-color: #fef9e7; }}
            .recommendations ul {{ margin: 10px 0; padding-left: 20px; }}
            .excellent {{ background-color: #d5f4e6; }}
            .good {{ background-color: #ffeaa7; }}
            .average {{ background-color: #fab1a0; }}
            .poor {{ background-color: #ff7675; color: white; }}
        </style>
    </head>
    <body>
        <div class="header">
            <h1>ğŸ¯ LoRA è¨“ç·´å®Œæ•´å ±å‘Š</h1>
            <p><strong>åˆ†ææ™‚é–“ï¼š</strong>{report['analysis_time']}</p>
            <p class="summary {'success' if report['summary']['overall_success'] else 'error'}">
                æ•´é«”ç‹€æ…‹ï¼š{'âœ… æˆåŠŸ' if report['summary']['overall_success'] else 'âŒ å¤±æ•—'}
            </p>
        </div>
        
        <div class="section">
            <h2>ğŸ“Š è¨“ç·´è³‡æ–™çµ±è¨ˆ</h2>
            <table>
                <tr><th>é …ç›®</th><th>æ•¸å€¼</th></tr>
                <tr><td>è¨“ç·´åœ–ç‰‡æ•¸é‡</td><td>{report['training_info'].get('train_image_count', 'N/A')}</td></tr>
                <tr><td>æ–‡å­—æª”æ¡ˆæ•¸é‡</td><td>{report['training_info'].get('train_text_count', 'N/A')}</td></tr>
                <tr><td>é‡è¤‡æ¬¡æ•¸</td><td>{report['training_info'].get('repeat_count', 'N/A')}</td></tr>
                <tr><td>ç¸½è¨“ç·´æ­¥æ•¸</td><td>{report['training_info'].get('total_training_steps', 'N/A')}</td></tr>
                <tr><td>åŸå§‹å‚™ä»½</td><td>{'âœ… å·²å»ºç«‹' if report['training_info'].get('backup_created', False) else 'âŒ æœªå»ºç«‹'}</td></tr>
            </table>
        </div>
        
        <div class="section">
            <h2>ğŸ“ LoRA æ¨¡å‹è³‡è¨Š</h2>
            <table>
                <tr><th>é …ç›®</th><th>æ•¸å€¼</th></tr>
                <tr><td>æª”æ¡ˆåç¨±</td><td>{report['model_info'].get('filename', 'N/A')}</td></tr>
                <tr><td>æª”æ¡ˆå¤§å°</td><td>{report['model_info'].get('size_mb', 'N/A')} MB</td></tr>
                <tr><td>å»ºç«‹æ™‚é–“</td><td>{report['model_info'].get('creation_time', 'N/A')}</td></tr>
                <tr><td>ç¸½æ¨¡å‹æ•¸</td><td>{report['model_info'].get('total_models', 'N/A')}</td></tr>
            </table>
        </div>
        
        <div class="section">
            <h2>ğŸ¨ æ¸¬è©¦çµæœ</h2>
            <table>
                <tr><th>é …ç›®</th><th>æ•¸å€¼</th></tr>
                <tr><td>æ¸¬è©¦åœ–ç‰‡æ•¸é‡</td><td>{report['test_results'].get('test_image_count', 'N/A')}</td></tr>
                <tr><td>æˆåŠŸç‡</td><td>{report['test_results'].get('success_rate', 'N/A'):.1f}%</td></tr>
            </table>
        </div>
        
        <div class="section">
            <h2>ğŸ” åœ–ç‰‡æ¯”è¼ƒçµ±è¨ˆ</h2>
            <table>
                <tr><th>é …ç›®</th><th>æ•¸å€¼</th></tr>
                <tr><td>åŸå§‹åœ–ç‰‡æ•¸é‡</td><td>{report['image_comparison'].get('original_count', 'N/A')}</td></tr>
                <tr><td>ç”Ÿæˆåœ–ç‰‡æ•¸é‡</td><td>{report['image_comparison'].get('generated_count', 'N/A')}</td></tr>
                <tr><td>å‚™ä»½å¯ç”¨æ€§</td><td>{'âœ… å¯ç”¨' if report['image_comparison'].get('backup_available', False) else 'âŒ ä¸å¯ç”¨'}</td></tr>
                <tr><td>è§£æåº¦ä¸€è‡´æ€§</td><td>{'âœ… ä¸€è‡´' if report['image_comparison'].get('resolution_consistency', False) else 'âŒ ä¸ä¸€è‡´'}</td></tr>
            </table>
        </div>
        
        {similarity_section}
        
        {fashion_section}
        
        {benchmark_section}
        
        {lora_tuning_section}
        
        {tuning_target_section}
        
        {training_progress_section}
        
        <div class="section">
            {comparison_gallery}
        </div>
        
        <div class="section">
            <h2>ğŸ“ˆ æ•ˆèƒ½åœ–è¡¨</h2>
            <img src="{chart_filename}" style="max-width: 100%; height: auto;">
        </div>
    </body>
    </html>
    """
    return html

def generate_charts(report, output_dir, timestamp):
    """ç”¢ç”Ÿè¨“ç·´åœ–è¡¨"""
    
    try:
        # è¨­å®šä¸­æ–‡å­—é«”
        plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'SimHei', 'Arial Unicode MS']
        plt.rcParams['axes.unicode_minus'] = False
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('LoRA Training Analysis Charts', fontsize=16, fontweight='bold')
        
        # åœ–è¡¨1ï¼šè¨“ç·´è³‡æ–™çµ±è¨ˆ
        train_data = [
            report['training_info'].get('train_image_count', 0),
            report['training_info'].get('train_text_count', 0)
        ]
        bars1 = ax1.bar(['Training Images', 'Text Files'], train_data, color=['skyblue', 'lightgreen'])
        ax1.set_title('Training Data Statistics')
        ax1.set_ylabel('Count')
        for bar in bars1:
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.1, f'{int(height)}', 
                    ha='center', va='bottom')
        
        # åœ–è¡¨2ï¼šæ¨¡å‹æª”æ¡ˆå¤§å°
        model_size = report['model_info'].get('size_mb', 0)
        bars2 = ax2.bar(['LoRA Model'], [model_size], color=['orange'])
        ax2.set_title('Model File Size')
        ax2.set_ylabel('Size (MB)')
        for bar in bars2:
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.1, f'{height:.1f} MB', 
                    ha='center', va='bottom')
        
        # åœ–è¡¨3ï¼šæ¸¬è©¦æˆåŠŸç‡
        success_rate = report['test_results'].get('success_rate', 0)
        colors = ['lightgreen' if success_rate > 80 else 'orange' if success_rate > 50 else 'lightcoral', 'lightgray']
        ax3.pie([success_rate, 100-success_rate], 
                labels=['Success', 'Failed'], 
                autopct='%1.1f%%',
                colors=colors)
        ax3.set_title('Test Success Rate')
        
        # åœ–è¡¨4ï¼šç›¸ä¼¼åº¦åˆ†æ
        if 'image_comparison' in report and report['image_comparison'].get('similarity_scores'):
            similarity_scores = report['image_comparison']['similarity_scores']
            x_pos = range(len(similarity_scores))
            bars4 = ax4.bar(x_pos, similarity_scores, color='lightblue', edgecolor='navy')
            ax4.set_title('Image Similarity Analysis')
            ax4.set_xlabel('Image Number')
            ax4.set_ylabel('Similarity Score')
            ax4.set_ylim(0, 1)
            
            # æ·»åŠ æ•¸å€¼æ¨™ç±¤
            for i, bar in enumerate(bars4):
                height = bar.get_height()
                ax4.text(bar.get_x() + bar.get_width()/2., height + 0.01, f'{height:.3f}', 
                        ha='center', va='bottom')
        else:
            ax4.text(0.5, 0.5, 'No similarity data available', ha='center', va='center', transform=ax4.transAxes)
            ax4.set_title('Image Similarity Analysis')
        
        plt.tight_layout()
        
        # å„²å­˜åœ–è¡¨åˆ°æŒ‡å®šè³‡æ–™å¤¾ï¼Œæª”ååŒ…å«æ™‚é–“æˆ³è¨˜
        chart_path = os.path.join(output_dir, f"training_charts_{timestamp}.png")
        plt.savefig(chart_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"ğŸ“Š åœ–è¡¨å·²ç”¢ç”Ÿï¼š{chart_path}")
        return chart_path
        
    except Exception as e:
        print(f"âŒ åœ–è¡¨ç”¢ç”Ÿå¤±æ•—ï¼š{str(e)}")
        return None

def load_fashion_clip_model():
    """è¼‰å…¥ FashionCLIP æ¨¡å‹"""
    try:
        model = CLIPModel.from_pretrained("patrickjohncyh/fashion-clip")
        processor = CLIPProcessor.from_pretrained("patrickjohncyh/fashion-clip")
        device = "cuda" if torch.cuda.is_available() else "cpu"
        model = model.to(device)
        print("âœ… FashionCLIP æ¨¡å‹è¼‰å…¥æˆåŠŸ")
        return model, processor, device
    except Exception as e:
        print(f"âŒ FashionCLIP æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼š{e}")
        return None, None, None

def analyze_image_with_fashion_clip(image_path, model, processor, device, labels_dict):
    """ä½¿ç”¨ FashionCLIP åˆ†æåœ–ç‰‡ç‰¹å¾µ"""
    try:
        image = Image.open(image_path).convert("RGB")
        analysis_results = {}
        
        # å°æ¯å€‹ç‰¹å¾µé¡åˆ¥é€²è¡Œåˆ†æ
        for cat, cat_labels in labels_dict.items():
            if not cat_labels:
                continue
                
            inputs = processor(text=cat_labels, images=image, return_tensors="pt", padding=True)
            inputs = {k: v.to(device) for k, v in inputs.items()}
            
            with torch.no_grad():
                outputs = model(**inputs)
                logits_per_image = outputs.logits_per_image
                probs = logits_per_image.softmax(dim=1)
                
                # ç²å–æœ€é«˜åˆ†æ•¸çš„æ¨™ç±¤
                best_idx = probs[0].argmax().item()
                best_label = cat_labels[best_idx]
                best_score = probs[0][best_idx].item()
                
                # ç²å–å‰3å€‹æœ€é«˜åˆ†æ•¸çš„æ¨™ç±¤
                top3_indices = probs[0].argsort(descending=True)[:3]
                top3_labels = [(cat_labels[i], probs[0][i].item()) for i in top3_indices]
                
                analysis_results[cat] = {
                    "best_label": best_label,
                    "best_score": best_score,
                    "top3": top3_labels
                }
        
        return analysis_results
    except Exception as e:
        print(f"âŒ FashionCLIP åˆ†æå¤±æ•—ï¼š{e}")
        return None

def compare_fashion_features(original_analysis, generated_analysis):
    """æ¯”è¼ƒåŸå§‹åœ–ç‰‡å’Œç”Ÿæˆåœ–ç‰‡çš„æ™‚å°šç‰¹å¾µ"""
    if not original_analysis or not generated_analysis:
        return None
    
    feature_similarity = {}
    
    for cat in original_analysis:
        if cat in generated_analysis:
            orig_label = original_analysis[cat]["best_label"]
            gen_label = generated_analysis[cat]["best_label"]
            
            # è¨ˆç®—æ¨™ç±¤åŒ¹é…åº¦
            label_match = 1.0 if orig_label == gen_label else 0.0
            
            # è¨ˆç®—åˆ†æ•¸ç›¸ä¼¼åº¦
            orig_score = original_analysis[cat]["best_score"]
            gen_score = generated_analysis[cat]["best_score"]
            score_similarity = 1.0 - abs(orig_score - gen_score)
            
            feature_similarity[cat] = {
                "original_label": orig_label,
                "generated_label": gen_label,
                "label_match": label_match,
                "score_similarity": score_similarity,
                "combined_similarity": (label_match + score_similarity) / 2
            }
    
    return feature_similarity

def benchmark_results_with_three_points(comparison_results):
    """åŸºæ–¼ä¸‰å€‹åŸºæº–é»è©•ä¼°çµæœ - åƒè€ƒ day3_fashion_training.py"""
    print("ğŸ¯ ä¸‰åŸºæº–é»æ€§èƒ½è©•ä¼°...")
    
    # åƒè€ƒåŸºæº–å€¼ (ä¾†è‡ª day3_fashion_training.py)
    benchmarks = {
        "total_loss": {
            "excellent": 0.3,    # å„ªç§€
            "good": 0.5,         # è‰¯å¥½  
            "average": 0.7,      # ä¸€èˆ¬
            "reference": 0.709   # åƒè€ƒå€¼
        },
        "visual_similarity": {
            "excellent": 0.7,    # å„ªç§€
            "good": 0.5,         # è‰¯å¥½
            "average": 0.3,      # ä¸€èˆ¬
            "reference": 0.326   # åƒè€ƒå€¼
        },
        "fashion_clip_similarity": {
            "excellent": 0.7,    # å„ªç§€
            "good": 0.5,         # è‰¯å¥½
            "average": 0.3,      # ä¸€èˆ¬
            "reference": 0.523   # åƒè€ƒå€¼
        },
        "color_similarity": {
            "excellent": 0.8,    # å„ªç§€
            "good": 0.6,         # è‰¯å¥½
            "average": 0.4,      # ä¸€èˆ¬
            "reference": 0.012   # åƒè€ƒå€¼ (æ¥µä½)
        }
    }
    
    benchmark_results = {
        "total_evaluated": 0,
        "performance_distribution": {
            "excellent": 0,
            "good": 0, 
            "average": 0,
            "poor": 0
        },
        "detailed_analysis": [],
        "recommendations": [],
        "average_metrics": {},
        "benchmark_comparison": {}
    }
    
    # è™•ç† SSIM ç›¸ä¼¼åº¦æ•¸æ“š
    if comparison_results.get("similarity_scores"):
        similarity_scores = comparison_results["similarity_scores"]
        benchmark_results["total_evaluated"] = len(similarity_scores)
        
        # ä½¿ç”¨ SSIM ç›¸ä¼¼åº¦é€²è¡ŒåŸºæœ¬è©•ä¼°
        avg_visual_sim = sum(similarity_scores) / len(similarity_scores)
        
        # è¨ˆç®—åŸºæ–¼ day3_fashion_training.py æ¬Šé‡çš„ç¸½æå¤±
        weights = {"visual": 0.2, "fashion_clip": 0.6, "color": 0.2}
        visual_loss = 1.0 - avg_visual_sim
        
        # å‡è¨­è‰²å½©ç›¸ä¼¼åº¦ç‚ºä¸­ç­‰æ°´å¹³ (å› ç‚ºæ²’æœ‰å…·é«”æ•¸æ“š)
        assumed_color_sim = 0.5
        color_loss = 1.0 - assumed_color_sim
        
        # å¦‚æœæœ‰ FashionCLIP åˆ†ææ•¸æ“š
        if "fashion_analysis" in comparison_results and comparison_results["fashion_analysis"].get("comparisons"):
            comparisons = comparison_results["fashion_analysis"]["comparisons"]
            
            for i, comp in enumerate(comparisons):
                if i < len(similarity_scores):
                    visual_sim = similarity_scores[i]
                    
                    # å¾ FashionCLIP åˆ†æä¸­ç²å–èªæ„ç›¸ä¼¼åº¦
                    fashion_sim = 0.5  # é è¨­å€¼
                    if "feature_comparison" in comp:
                        feature_sims = [feat["combined_similarity"] for feat in comp["feature_comparison"].values()]
                        if feature_sims:
                            fashion_sim = sum(feature_sims) / len(feature_sims)
                    
                    color_sim = assumed_color_sim  # é è¨­è‰²å½©ç›¸ä¼¼åº¦
                    
                    # è¨ˆç®—ç¸½æå¤±
                    fashion_clip_loss = 1.0 - fashion_sim
                    total_loss = (
                        weights["visual"] * visual_loss +
                        weights["fashion_clip"] * fashion_clip_loss +
                        weights["color"] * color_loss
                    )
                    
                    # ä¸‰åŸºæº–é»è©•ä¼°
                    analysis = evaluate_against_three_benchmarks(
                        total_loss, visual_sim, fashion_sim, color_sim, benchmarks
                    )
                    
                    benchmark_results["detailed_analysis"].append({
                        "image_pair": f"{comp.get('original_image', f'image_{i+1}')} vs {comp.get('generated_image', f'gen_{i+1}')}",
                        "metrics": {
                            "total_loss": total_loss,
                            "visual_similarity": visual_sim,
                            "fashion_clip_similarity": fashion_sim,
                            "color_similarity": color_sim
                        },
                        "benchmark_evaluation": analysis
                    })
                    
                    # æ›´æ–°æ€§èƒ½åˆ†ä½ˆ
                    overall_performance = analysis["overall_performance"]
                    benchmark_results["performance_distribution"][overall_performance] += 1
                    
                    print(f"  ğŸ“Š {comp.get('original_image', f'image_{i+1}')}: {overall_performance.upper()}")
                    print(f"     ç¸½æå¤±: {total_loss:.3f}, è¦–è¦º: {visual_sim:.3f}, FashionCLIP: {fashion_sim:.3f}")
        else:
            # åªæœ‰ SSIM æ•¸æ“šçš„æƒ…æ³
            for i, visual_sim in enumerate(similarity_scores):
                # é è¨­ FashionCLIP å’Œè‰²å½©ç›¸ä¼¼åº¦
                fashion_sim = 0.5
                color_sim = 0.5
                
                fashion_clip_loss = 1.0 - fashion_sim
                total_loss = (
                    weights["visual"] * (1.0 - visual_sim) +
                    weights["fashion_clip"] * fashion_clip_loss +
                    weights["color"] * (1.0 - color_sim)
                )
                
                analysis = evaluate_against_three_benchmarks(
                    total_loss, visual_sim, fashion_sim, color_sim, benchmarks
                )
                
                benchmark_results["detailed_analysis"].append({
                    "image_pair": f"image_{i+1}",
                    "metrics": {
                        "total_loss": total_loss,
                        "visual_similarity": visual_sim,
                        "fashion_clip_similarity": fashion_sim,
                        "color_similarity": color_sim
                    },
                    "benchmark_evaluation": analysis
                })
                
                overall_performance = analysis["overall_performance"]
                benchmark_results["performance_distribution"][overall_performance] += 1
    
    # è¨ˆç®—å¹³å‡æŒ‡æ¨™
    if benchmark_results["detailed_analysis"]:
        analyses = benchmark_results["detailed_analysis"]
        n = len(analyses)
        
        benchmark_results["average_metrics"] = {
            "avg_total_loss": sum(a["metrics"]["total_loss"] for a in analyses) / n,
            "avg_visual_similarity": sum(a["metrics"]["visual_similarity"] for a in analyses) / n,
            "avg_fashion_clip_similarity": sum(a["metrics"]["fashion_clip_similarity"] for a in analyses) / n,
            "avg_color_similarity": sum(a["metrics"]["color_similarity"] for a in analyses) / n
        }
        
        # èˆ‡åƒè€ƒå€¼æ¯”è¼ƒ
        avg_metrics = benchmark_results["average_metrics"]
        benchmark_results["benchmark_comparison"] = {
            "vs_reference_total_loss": avg_metrics["avg_total_loss"] - benchmarks["total_loss"]["reference"],
            "vs_reference_visual": avg_metrics["avg_visual_similarity"] - benchmarks["visual_similarity"]["reference"],
            "vs_reference_fashion": avg_metrics["avg_fashion_clip_similarity"] - benchmarks["fashion_clip_similarity"]["reference"],
            "vs_reference_color": avg_metrics["avg_color_similarity"] - benchmarks["color_similarity"]["reference"]
        }
    
    # ç”Ÿæˆå»ºè­°
    benchmark_results["recommendations"] = generate_improvement_recommendations(
        benchmark_results["detailed_analysis"], benchmarks
    )
    
    return benchmark_results

def evaluate_against_three_benchmarks(total_loss, visual_sim, fashion_sim, color_sim, benchmarks):
    """é‡å°ä¸‰å€‹åŸºæº–é»è©•ä¼°å–®ä¸€çµæœ"""
    
    # è©•ä¼°æ¯å€‹æŒ‡æ¨™
    evaluations = {}
    
    # ç¸½æå¤± (è¶Šä½è¶Šå¥½)
    if total_loss <= benchmarks["total_loss"]["excellent"]:
        evaluations["total_loss"] = "excellent"
    elif total_loss <= benchmarks["total_loss"]["good"]:
        evaluations["total_loss"] = "good"
    elif total_loss <= benchmarks["total_loss"]["average"]:
        evaluations["total_loss"] = "average"
    else:
        evaluations["total_loss"] = "poor"
    
    # è¦–è¦ºç›¸ä¼¼åº¦ (è¶Šé«˜è¶Šå¥½)
    if visual_sim >= benchmarks["visual_similarity"]["excellent"]:
        evaluations["visual_similarity"] = "excellent"
    elif visual_sim >= benchmarks["visual_similarity"]["good"]:
        evaluations["visual_similarity"] = "good"
    elif visual_sim >= benchmarks["visual_similarity"]["average"]:
        evaluations["visual_similarity"] = "average"
    else:
        evaluations["visual_similarity"] = "poor"
    
    # FashionCLIP ç›¸ä¼¼åº¦ (è¶Šé«˜è¶Šå¥½)
    if fashion_sim >= benchmarks["fashion_clip_similarity"]["excellent"]:
        evaluations["fashion_clip_similarity"] = "excellent"
    elif fashion_sim >= benchmarks["fashion_clip_similarity"]["good"]:
        evaluations["fashion_clip_similarity"] = "good"
    elif fashion_sim >= benchmarks["fashion_clip_similarity"]["average"]:
        evaluations["fashion_clip_similarity"] = "average"
    else:
        evaluations["fashion_clip_similarity"] = "poor"
    
    # è‰²å½©ç›¸ä¼¼åº¦ (è¶Šé«˜è¶Šå¥½)
    if color_sim >= benchmarks["color_similarity"]["excellent"]:
        evaluations["color_similarity"] = "excellent"
    elif color_sim >= benchmarks["color_similarity"]["good"]:
        evaluations["color_similarity"] = "good"
    elif color_sim >= benchmarks["color_similarity"]["average"]:
        evaluations["color_similarity"] = "average"
    else:
        evaluations["color_similarity"] = "poor"
    
    # ç¶œåˆè©•ä¼° (åŸºæ–¼ FashionCLIP ç‚ºä¸»è¦æŒ‡æ¨™)
    if evaluations["fashion_clip_similarity"] == "excellent" and evaluations["total_loss"] in ["excellent", "good"]:
        overall = "excellent"
    elif evaluations["fashion_clip_similarity"] == "good" and evaluations["total_loss"] in ["excellent", "good", "average"]:
        overall = "good"
    elif evaluations["fashion_clip_similarity"] == "average":
        overall = "average"
    else:
        overall = "poor"
    
    return {
        "individual_evaluations": evaluations,
        "overall_performance": overall,
        "benchmark_comparison": {
            "vs_reference_total_loss": total_loss - benchmarks["total_loss"]["reference"],
            "vs_reference_visual": visual_sim - benchmarks["visual_similarity"]["reference"],
            "vs_reference_fashion": fashion_sim - benchmarks["fashion_clip_similarity"]["reference"],
            "vs_reference_color": color_sim - benchmarks["color_similarity"]["reference"]
        }
    }

def generate_improvement_recommendations(detailed_analysis, benchmarks):
    """ç”Ÿæˆæ”¹å–„å»ºè­°"""
    recommendations = []
    
    if not detailed_analysis:
        return recommendations
    
    # åˆ†ææ•´é«”è¶¨å‹¢
    total_count = len(detailed_analysis)
    poor_total_loss = sum(1 for analysis in detailed_analysis 
                         if analysis["benchmark_evaluation"]["individual_evaluations"]["total_loss"] == "poor")
    poor_fashion_clip = sum(1 for analysis in detailed_analysis 
                           if analysis["benchmark_evaluation"]["individual_evaluations"]["fashion_clip_similarity"] == "poor")
    poor_visual = sum(1 for analysis in detailed_analysis 
                     if analysis["benchmark_evaluation"]["individual_evaluations"]["visual_similarity"] == "poor")
    poor_color = sum(1 for analysis in detailed_analysis 
                    if analysis["benchmark_evaluation"]["individual_evaluations"]["color_similarity"] == "poor")
    
    # ç”Ÿæˆå…·é«”å»ºè­°
    if poor_total_loss > total_count * 0.5:
        recommendations.append("ğŸ¯ ç¸½æå¤±éé«˜ï¼šå»ºè­°èª¿æ•´è¨“ç·´åƒæ•¸æˆ–æç¤ºè©ç­–ç•¥")
    
    if poor_fashion_clip > total_count * 0.5:
        recommendations.append("ğŸ¨ FashionCLIP ç›¸ä¼¼åº¦ä½ï¼šå»ºè­°å„ªåŒ–ç‰¹å¾µæå–æˆ–ä½¿ç”¨æ›´ç²¾æº–çš„æœè£æè¿°")
    
    if poor_visual > total_count * 0.5:
        recommendations.append("ğŸ‘ï¸ è¦–è¦ºç›¸ä¼¼åº¦ä½ï¼šå»ºè­°èª¿æ•´ç”Ÿæˆåƒæ•¸æˆ–ä½¿ç”¨æ›´é«˜è§£æåº¦")
    
    if poor_color > total_count * 0.7:  # è‰²å½©ç›¸ä¼¼åº¦åƒè€ƒå€¼å¾ˆä½ï¼Œæ¨™æº–è¼ƒå¯¬é¬†
        recommendations.append("ğŸ¨ è‰²å½©ç›¸ä¼¼åº¦éœ€æ”¹å–„ï¼šå»ºè­°åœ¨æç¤ºè©ä¸­åŠ å…¥å…·é«”è‰²å½©æè¿°")
    
    # åŸºæ–¼åƒè€ƒå€¼çš„å»ºè­°
    if detailed_analysis:
        avg_fashion_diff = sum(analysis["benchmark_evaluation"]["benchmark_comparison"]["vs_reference_fashion"] 
                              for analysis in detailed_analysis) / total_count
        
        if avg_fashion_diff > 0.1:
            recommendations.append("âœ… FashionCLIP è¡¨ç¾è¶…è¶Šåƒè€ƒå€¼ï¼Œæ¨¡å‹æ•ˆæœè‰¯å¥½")
        elif avg_fashion_diff < -0.1:
            recommendations.append("âš ï¸ FashionCLIP è¡¨ç¾ä½æ–¼åƒè€ƒå€¼ï¼Œå»ºè­°æª¢æŸ¥è¨“ç·´æ•¸æ“šè³ªé‡")
    
    return recommendations

def calculate_lora_tuning_metrics(report):
    """è¨ˆç®— LoRA èª¿å„ªæŒ‡æ¨™ - åƒè€ƒ day3_fashion_training.py çš„æå¤±å‡½æ•¸"""
    print("ğŸ¯ è¨ˆç®— LoRA èª¿å„ªæŒ‡æ¨™...")
    
    tuning_metrics = {
        "training_efficiency": {},
        "generation_quality": {},
        "feature_preservation": {},
        "overall_tuning_score": 0.0,
        "tuning_recommendations": []
    }
    
    # 1. è¨“ç·´æ•ˆç‡æŒ‡æ¨™
    if "training_info" in report and "model_info" in report:
        train_steps = report["training_info"].get("total_training_steps", 0)
        model_size = report["model_info"].get("size_mb", 0)
        
        # è¨ˆç®—æ•ˆç‡æ¯”ç‡
        if train_steps > 0:
            efficiency_ratio = model_size / train_steps * 1000  # æ¯åƒæ­¥çš„æ¨¡å‹å¤§å°
            
            # æ•ˆç‡è©•ä¼° (åƒè€ƒæ¨™æº–: 18MB / 100æ­¥ â‰ˆ 0.18)
            if efficiency_ratio < 0.15:
                efficiency_grade = "excellent"
                efficiency_score = 1.0
            elif efficiency_ratio < 0.25:
                efficiency_grade = "good"
                efficiency_score = 0.8
            elif efficiency_ratio < 0.35:
                efficiency_grade = "average"
                efficiency_score = 0.6
            else:
                efficiency_grade = "poor"
                efficiency_score = 0.4
            
            tuning_metrics["training_efficiency"] = {
                "steps": train_steps,
                "model_size_mb": model_size,
                "efficiency_ratio": efficiency_ratio,
                "grade": efficiency_grade,
                "score": efficiency_score
            }
            
            print(f"  ğŸ“Š è¨“ç·´æ•ˆç‡: {efficiency_grade.upper()} (æ¯”ç‡: {efficiency_ratio:.3f})")
    
    # 2. ç”Ÿæˆå“è³ªæŒ‡æ¨™ (åŸºæ–¼ç›¸ä¼¼åº¦åˆ†æ)
    if "image_comparison" in report:
        comparison = report["image_comparison"]
        
        # SSIM ç›¸ä¼¼åº¦å“è³ª
        ssim_scores = comparison.get("similarity_scores", [])
        if ssim_scores:
            avg_ssim = sum(ssim_scores) / len(ssim_scores)
            
            # å“è³ªè©•ä¼° (åƒè€ƒ day3_fashion_training.py çš„åŸºæº–)
            if avg_ssim >= 0.7:
                quality_grade = "excellent"
                quality_score = 1.0
            elif avg_ssim >= 0.5:
                quality_grade = "good"
                quality_score = 0.8
            elif avg_ssim >= 0.3:
                quality_grade = "average"
                quality_score = 0.6
            else:
                quality_grade = "poor"
                quality_score = 0.4
            
            tuning_metrics["generation_quality"] = {
                "average_ssim": avg_ssim,
                "image_count": len(ssim_scores),
                "grade": quality_grade,
                "score": quality_score,
                "benchmark_comparison": avg_ssim - 0.326  # èˆ‡åƒè€ƒå€¼æ¯”è¼ƒ
            }
            
            print(f"  ğŸ¨ ç”Ÿæˆå“è³ª: {quality_grade.upper()} (SSIM: {avg_ssim:.3f})")
    
    # 3. ç‰¹å¾µä¿æŒæŒ‡æ¨™ (åŸºæ–¼ FashionCLIP åˆ†æ)
    if "benchmark_analysis" in report:
        benchmark = report["benchmark_analysis"]
        avg_metrics = benchmark.get("average_metrics", {})
        
        fashion_clip_sim = avg_metrics.get("avg_fashion_clip_similarity", 0)
        
        # ç‰¹å¾µä¿æŒè©•ä¼°
        if fashion_clip_sim >= 0.7:
            feature_grade = "excellent"
            feature_score = 1.0
        elif fashion_clip_sim >= 0.5:
            feature_grade = "good"
            feature_score = 0.8
        elif fashion_clip_sim >= 0.3:
            feature_grade = "average"
            feature_score = 0.6
        else:
            feature_grade = "poor"
            feature_score = 0.4
        
        tuning_metrics["feature_preservation"] = {
            "fashion_clip_similarity": fashion_clip_sim,
            "grade": feature_grade,
            "score": feature_score,
            "benchmark_comparison": fashion_clip_sim - 0.523  # èˆ‡åƒè€ƒå€¼æ¯”è¼ƒ
        }
        
        print(f"  ğŸ¯ ç‰¹å¾µä¿æŒ: {feature_grade.upper()} (FashionCLIP: {fashion_clip_sim:.3f})")
    
    # 4. è¨ˆç®—æ•´é«”èª¿å„ªåˆ†æ•¸ (åŸºæ–¼ day3_fashion_training.py çš„æ¬Šé‡)
    weights = {
        "training_efficiency": 0.2,
        "generation_quality": 0.4,
        "feature_preservation": 0.4
    }
    
    overall_score = 0.0
    valid_scores = 0
    
    for metric_name, weight in weights.items():
        if metric_name in tuning_metrics and "score" in tuning_metrics[metric_name]:
            overall_score += tuning_metrics[metric_name]["score"] * weight
            valid_scores += 1
    
    if valid_scores > 0:
        tuning_metrics["overall_tuning_score"] = overall_score
        
        # æ•´é«”è©•ç´š
        if overall_score >= 0.9:
            overall_grade = "excellent"
            recommendation = "ğŸ¯ LoRA èª¿å„ªå·²é”åˆ°å„ªç§€æ°´å¹³ï¼Œå¯ä»¥ç”¨æ–¼ç”Ÿç”¢ç’°å¢ƒ"
        elif overall_score >= 0.7:
            overall_grade = "good"
            recommendation = "âœ… LoRA èª¿å„ªæ•ˆæœè‰¯å¥½ï¼Œå¯è€ƒæ…®é€²ä¸€æ­¥å¾®èª¿"
        elif overall_score >= 0.5:
            overall_grade = "average"
            recommendation = "âš ï¸ LoRA èª¿å„ªéœ€è¦æ”¹å–„ï¼Œå»ºè­°èª¿æ•´è¨“ç·´åƒæ•¸"
        else:
            overall_grade = "poor"
            recommendation = "âŒ LoRA èª¿å„ªæ•ˆæœä¸ä½³ï¼Œéœ€è¦é‡æ–°æª¢è¦–è¨“ç·´ç­–ç•¥"
        
        tuning_metrics["overall_grade"] = overall_grade
        tuning_metrics["tuning_recommendations"].append(recommendation)
        
        print(f"ğŸ¯ æ•´é«”èª¿å„ªåˆ†æ•¸: {overall_score:.3f} ({overall_grade.upper()})")
    
    # 5. ç”Ÿæˆå…·é«”èª¿å„ªå»ºè­°
    recommendations = generate_lora_tuning_recommendations(tuning_metrics, report)
    tuning_metrics["tuning_recommendations"].extend(recommendations)
    
    return tuning_metrics

def generate_lora_tuning_recommendations(tuning_metrics, report):
    """ç”Ÿæˆ LoRA èª¿å„ªå»ºè­°"""
    recommendations = []
    
    # è¨“ç·´æ•ˆç‡å»ºè­°
    if "training_efficiency" in tuning_metrics:
        efficiency = tuning_metrics["training_efficiency"]
        if efficiency.get("grade") == "poor":
            recommendations.append("ğŸ“‰ è¨“ç·´æ•ˆç‡ä½ï¼šå»ºè­°æ¸›å°‘è¨“ç·´æ­¥æ•¸æˆ–ä½¿ç”¨æ›´é«˜æ•ˆçš„å­¸ç¿’ç‡")
            recommendations.append("ğŸ”§ å»ºè­°åƒæ•¸ï¼šsteps=80-120, learning_rate=0.0005-0.001")
        elif efficiency.get("grade") == "excellent":
            recommendations.append("ğŸš€ è¨“ç·´æ•ˆç‡å„ªç§€ï¼šç•¶å‰è¨­å®šé©åˆä½œç‚ºåŸºæº–é…ç½®")
    


    # ç”Ÿæˆå“è³ªå»ºè­°
    if "generation_quality" in tuning_metrics:
        quality = tuning_metrics["generation_quality"]
        benchmark_diff = quality.get("benchmark_comparison", 0)
        
        if quality.get("grade") == "poor":
            if benchmark_diff < -0.1:
                recommendations.append("ğŸ¨ ç”Ÿæˆå“è³ªä½æ–¼åŸºæº–ï¼šå»ºè­°å¢åŠ è¨“ç·´æ•¸æ“šæˆ–èª¿æ•´æå¤±å‡½æ•¸æ¬Šé‡")
                recommendations.append("ğŸ“Š å»ºè­°ï¼šå¢åŠ è¦–è¦ºæå¤±æ¬Šé‡è‡³ 0.3-0.4")
            else:
                recommendations.append("ğŸ¨ ç”Ÿæˆå“è³ªéœ€æ”¹å–„ï¼šå»ºè­°èª¿æ•´å­¸ç¿’ç‡æˆ–å¢åŠ è¨“ç·´æ­¥æ•¸")
                recommendations.append("âš™ï¸ å»ºè­°ï¼šsteps=150-200, é™ä½å­¸ç¿’ç‡è‡³ 0.0003-0.0005")
        elif benchmark_diff > 0.1:
            recommendations.append("âœ¨ ç”Ÿæˆå“è³ªè¶…è¶ŠåŸºæº–ï¼šæ¨¡å‹è¡¨ç¾å„ªç•°")
        
        # åŸºæ–¼ SSIM åˆ†æ•¸çš„å…·é«”å»ºè­°
        avg_ssim = quality.get("average_ssim", 0)
        if avg_ssim < 0.3:
            recommendations.append("âš ï¸ SSIM éä½ï¼šå»ºè­°æª¢æŸ¥è¼¸å…¥åœ–ç‰‡å“è³ªæˆ–èª¿æ•´ç”Ÿæˆåƒæ•¸")
        elif avg_ssim > 0.8:
            recommendations.append("ğŸ¯ SSIM å„ªç§€ï¼šè¦–è¦ºç›¸ä¼¼åº¦é”åˆ°é«˜æ°´æº–")
    
    # ç‰¹å¾µä¿æŒå»ºè­°
    if "feature_preservation" in tuning_metrics:
        feature = tuning_metrics["feature_preservation"]
        benchmark_diff = feature.get("benchmark_comparison", 0)
        
        if feature.get("grade") == "poor":
            recommendations.append("ğŸ¯ ç‰¹å¾µä¿æŒèƒ½åŠ›å¼±ï¼šå»ºè­°ä½¿ç”¨ FashionCLIP å¼•å°çš„æå¤±å‡½æ•¸")
            recommendations.append("ğŸ”§ å»ºè­°ï¼šæé«˜ FashionCLIP æ¬Šé‡è‡³ 0.7-0.8")
        elif benchmark_diff > 0.1:
            recommendations.append("ğŸ¯ ç‰¹å¾µä¿æŒå„ªç§€ï¼šFashionCLIP èªæ„ç†è§£è¶…è¶ŠåŸºæº–")
        
        # åŸºæ–¼ FashionCLIP åˆ†æ•¸çš„å…·é«”å»ºè­°
        fashion_sim = feature.get("fashion_clip_similarity", 0)
        if fashion_sim < 0.3:
            recommendations.append("âŒ FashionCLIP ç›¸ä¼¼åº¦æ¥µä½ï¼šå»ºè­°é‡æ–°æª¢è¦–è¨“ç·´æ•¸æ“šå’Œæç¤ºè©")
        elif fashion_sim > 0.7:
            recommendations.append("ğŸ¨ FashionCLIP ç›¸ä¼¼åº¦æ¥µä½³ï¼šç‰¹å¾µç†è§£é”åˆ°å°ˆæ¥­æ°´æº–")
    
    # å¹³è¡¡æ€§å»ºè­°
    efficiency_score = tuning_metrics.get("training_efficiency", {}).get("score", 0)
    quality_score = tuning_metrics.get("generation_quality", {}).get("score", 0)  
    feature_score = tuning_metrics.get("feature_preservation", {}).get("score", 0)
    
    # æª¢æŸ¥ä¸å¹³è¡¡å•é¡Œ
    scores = [efficiency_score, quality_score, feature_score]
    if max(scores) - min(scores) > 0.4:
        recommendations.append("âš–ï¸ æŒ‡æ¨™ä¸å¹³è¡¡ï¼šå»ºè­°èª¿æ•´æ¬Šé‡ä»¥å¹³è¡¡å„é …æŒ‡æ¨™")
        
        if efficiency_score < 0.5 and quality_score > 0.8:
            recommendations.append("ğŸ”„ æ•ˆç‡ä½ä½†å“è³ªé«˜ï¼šå¯è€ƒæ…®æ¸›å°‘è¨“ç·´æ­¥æ•¸ä»¥æé«˜æ•ˆç‡")
        elif efficiency_score > 0.8 and quality_score < 0.5:
            recommendations.append("ğŸ”„ æ•ˆç‡é«˜ä½†å“è³ªä½ï¼šå»ºè­°å¢åŠ è¨“ç·´æ­¥æ•¸æˆ–èª¿æ•´å­¸ç¿’ç‡")
    
    # æ•´é«”ç­–ç•¥å»ºè­°
    overall_score = tuning_metrics.get("overall_tuning_score", 0)
    if overall_score < 0.5:
        recommendations.append("ğŸš¨ æ•´é«”è¡¨ç¾éœ€å¤§å¹…æ”¹å–„ï¼šå»ºè­°é‡æ–°æª¢è¦–è¨“ç·´æ•¸æ“šå’ŒåŸºç¤åƒæ•¸")
    elif overall_score > 0.85:
        recommendations.append("ğŸ–ï¸ æ•´é«”è¡¨ç¾å„ªç§€ï¼šå¯è€ƒæ…®é€²è¡Œç´°å¾®èª¿æ•´ä»¥é”åˆ°å®Œç¾")
    
    return recommendations

def generate_lora_tuning_target(report):
    """åŸºæ–¼ç•¶å‰çµæœç”Ÿæˆä¸‹ä¸€è¼ªèª¿å„ªç›®æ¨™"""
    print("ğŸ¯ ç”Ÿæˆ LoRA èª¿å„ªç›®æ¨™...")
    
    tuning_targets = {
        "current_performance": {},
        "target_metrics": {},
        "action_plan": [],
        "parameter_suggestions": {},
        "automation_config": {},
        "priority_level": "medium"
    }
    
    # åˆ†æç•¶å‰è¡¨ç¾
    if "benchmark_analysis" in report:
        benchmark = report["benchmark_analysis"]
        avg_metrics = benchmark.get("average_metrics", {})
        
        current_total_loss = avg_metrics.get("avg_total_loss", 1.0)
        current_visual_sim = avg_metrics.get("avg_visual_similarity", 0.0)
        current_fashion_sim = avg_metrics.get("avg_fashion_clip_similarity", 0.0)
        current_color_sim = avg_metrics.get("avg_color_similarity", 0.0)
        
        tuning_targets["current_performance"] = {
            "total_loss": current_total_loss,
            "visual_similarity": current_visual_sim,
            "fashion_clip_similarity": current_fashion_sim,
            "color_similarity": current_color_sim
        }
        
        # è¨­å®šç›®æ¨™ (åŸºæ–¼ day3_fashion_training.py çš„å„ªç§€æ¨™æº–)
        target_loss = min(0.3, current_total_loss * 0.8)  # ç›®æ¨™ï¼šæå¤±æ¸›å°‘ 20%
        target_visual = min(0.7, current_visual_sim * 1.2)  # ç›®æ¨™ï¼šè¦–è¦ºç›¸ä¼¼åº¦æå‡ 20%
        target_fashion = min(0.7, current_fashion_sim * 1.1)  # ç›®æ¨™ï¼šç‰¹å¾µç›¸ä¼¼åº¦æå‡ 10%
        target_color = min(0.8, current_color_sim * 1.3)  # ç›®æ¨™ï¼šè‰²å½©ç›¸ä¼¼åº¦æå‡ 30%
        
        tuning_targets["target_metrics"] = {
            "target_total_loss": target_loss,
            "target_visual_similarity": target_visual,
            "target_fashion_clip_similarity": target_fashion,
            "target_color_similarity": target_color
        }
        
        print(f"  ğŸ“Š ç•¶å‰è¡¨ç¾: æå¤±={current_total_loss:.3f}, è¦–è¦º={current_visual_sim:.3f}, ç‰¹å¾µ={current_fashion_sim:.3f}, è‰²å½©={current_color_sim:.3f}")
        print(f"  ğŸ¯ èª¿å„ªç›®æ¨™: æå¤±={target_loss:.3f}, è¦–è¦º={target_visual:.3f}, ç‰¹å¾µ={target_fashion:.3f}, è‰²å½©={target_color:.3f}")
        
        # åˆ¤æ–·å„ªå…ˆç´š
        if current_total_loss > 0.7 or current_fashion_sim < 0.3:
            tuning_targets["priority_level"] = "high"
        elif current_total_loss > 0.5 or current_visual_sim < 0.4:
            tuning_targets["priority_level"] = "medium"
        else:
            tuning_targets["priority_level"] = "low"
        
        # ç”Ÿæˆè¡Œå‹•è¨ˆåŠƒ
        if current_total_loss > 0.6:
            tuning_targets["action_plan"].append("ğŸ”§ å„ªå…ˆé™ä½ç¸½æå¤±ï¼šèª¿æ•´å­¸ç¿’ç‡å’Œæ¬Šé‡é…ç½®")
            tuning_targets["action_plan"].append("ğŸ“Š å»ºè­°åŸ·è¡Œå®Œæ•´çš„æå¤±å‡½æ•¸æ¬Šé‡èª¿æ•´")
        
        if current_visual_sim < 0.4:
            tuning_targets["action_plan"].append("ğŸ‘ï¸ æå‡è¦–è¦ºç›¸ä¼¼åº¦ï¼šå¢åŠ è¦–è¦ºæå¤±æ¬Šé‡æˆ–èª¿æ•´ç”Ÿæˆåƒæ•¸")
            tuning_targets["action_plan"].append("ğŸ¨ æª¢æŸ¥ç”Ÿæˆåœ–ç‰‡çš„è§£æåº¦å’Œå“è³ªè¨­å®š")
        
        if current_fashion_sim < 0.5:
            tuning_targets["action_plan"].append("ğŸ¨ å¼·åŒ–ç‰¹å¾µä¿æŒï¼šæé«˜ FashionCLIP æå¤±æ¬Šé‡")
            tuning_targets["action_plan"].append("ğŸ“ å„ªåŒ–è¨“ç·´æ•¸æ“šçš„æ¨™ç±¤æè¿°")
        
        if current_color_sim < 0.3:
            tuning_targets["action_plan"].append("ğŸŒˆ æ”¹å–„è‰²å½©ç›¸ä¼¼åº¦ï¼šåœ¨æç¤ºè©ä¸­åŠ å…¥å…·é«”è‰²å½©æè¿°")
            tuning_targets["action_plan"].append("ğŸ¨ è€ƒæ…®ä½¿ç”¨è‰²å½©å¼•å°çš„ç”Ÿæˆæ–¹å¼")
        
        # è©³ç´°åƒæ•¸å»ºè­°
        if current_total_loss > 0.7:
            tuning_targets["parameter_suggestions"]["learning_rate"] = "0.0003-0.0005 (é™ä½å­¸ç¿’ç‡)"
            tuning_targets["parameter_suggestions"]["steps"] = "200-300 (å¢åŠ è¨“ç·´æ­¥æ•¸)"
            tuning_targets["parameter_suggestions"]["batch_size"] = "1-2 (ä½¿ç”¨å°æ‰¹æ¬¡)"
        elif current_total_loss > 0.5:
            tuning_targets["parameter_suggestions"]["learning_rate"] = "0.0005-0.001 (é©ä¸­å­¸ç¿’ç‡)"
            tuning_targets["parameter_suggestions"]["steps"] = "150-200 (ä¸­ç­‰è¨“ç·´æ­¥æ•¸)"
        else:
            tuning_targets["parameter_suggestions"]["learning_rate"] = "0.001-0.002 (å¯ç¨å¾®æé«˜)"
            tuning_targets["parameter_suggestions"]["steps"] = "100-150 (ç¶­æŒæ•ˆç‡)"
        
        if current_fashion_sim < 0.4:
            tuning_targets["parameter_suggestions"]["fashion_clip_weight"] = "0.7-0.8 (æé«˜ç‰¹å¾µæ¬Šé‡)"
            tuning_targets["parameter_suggestions"]["text_encoder_lr"] = "0.0001-0.0002 (å¾®èª¿æ–‡æœ¬ç·¨ç¢¼å™¨)"
        elif current_fashion_sim > 0.6:
            tuning_targets["parameter_suggestions"]["fashion_clip_weight"] = "0.5-0.6 (ç¶­æŒå¹³è¡¡)"
        
        if current_visual_sim < 0.3:
            tuning_targets["parameter_suggestions"]["visual_weight"] = "0.3-0.4 (æé«˜è¦–è¦ºæ¬Šé‡)"
            tuning_targets["parameter_suggestions"]["resolution"] = "768x768 æˆ–æ›´é«˜ (æå‡è§£æåº¦)"
        
        # è‡ªå‹•åŒ–é…ç½®å»ºè­°
        tuning_targets["automation_config"] = {
            "auto_adjust_lr": current_total_loss > 0.6,
            "auto_adjust_steps": current_fashion_sim < 0.4,
            "auto_adjust_weights": current_visual_sim < 0.3,
            "suggested_iterations": 3 if tuning_targets["priority_level"] == "high" else 2
        }
        
        # ä¸‹ä¸€è¼ªè¨“ç·´çš„å…·é«”é…ç½®
        base_config = {
            "learning_rate": 0.0005,
            "steps": 100,
            "batch_size": 1,
            "resolution": "512x512"
        }
        
        # æ ¹æ“šç•¶å‰è¡¨ç¾èª¿æ•´é…ç½®
        if current_total_loss > 0.6:
            base_config["learning_rate"] = 0.0003
            base_config["steps"] = 200
        elif current_total_loss < 0.4:
            base_config["learning_rate"] = 0.001
            base_config["steps"] = 80
        
        if current_visual_sim < 0.3:
            base_config["resolution"] = "768x768"
        
        tuning_targets["recommended_config"] = base_config
        
        # æˆåŠŸæ¨™æº–
        tuning_targets["success_criteria"] = {
            "minimum_total_loss": 0.5,
            "minimum_visual_similarity": 0.4,
            "minimum_fashion_clip_similarity": 0.5,
            "target_overall_score": 0.7
        }
        
        print(f"  ğŸ¯ å„ªå…ˆç´š: {tuning_targets['priority_level'].upper()}")
        print(f"  ğŸ”§ å»ºè­°é…ç½®: LR={base_config['learning_rate']}, Steps={base_config['steps']}")
    
    return tuning_targets

# ä¸»ç¨‹åºå…¥å£é»
if __name__ == "__main__":
    try:
        print("ğŸš€ é–‹å§‹åŸ·è¡Œ LoRA è¨“ç·´çµæœåˆ†æ...")
        report = analyze_training_results()
        
        if report:
            print("\nâœ… åˆ†æå®Œæˆï¼")
            print(f"ğŸ“Š ç¸½çµï¼š")
            print(f"  è¨“ç·´å®Œæˆ: {'âœ…' if report['summary']['training_completed'] else 'âŒ'}")
            print(f"  æ¸¬è©¦å®Œæˆ: {'âœ…' if report['summary']['testing_completed'] else 'âŒ'}")
            print(f"  æ¯”è¼ƒå®Œæˆ: {'âœ…' if report['summary']['comparison_completed'] else 'âŒ'}")
            print(f"  æ•´é«”ç‹€æ…‹: {'âœ… æˆåŠŸ' if report['summary']['overall_success'] else 'âŒ å¤±æ•—'}")
            
            # é¡¯ç¤ºé—œéµæŒ‡æ¨™
            if "lora_tuning" in report:
                lora_score = report["lora_tuning"].get("overall_tuning_score", 0)
                print(f"  LoRA èª¿å„ªåˆ†æ•¸: {lora_score:.3f}")
            
            if "image_comparison" in report:
                avg_sim = report["image_comparison"].get("average_similarity", 0)
                print(f"  å¹³å‡ç›¸ä¼¼åº¦: {avg_sim:.3f}")
            
            if "benchmark_analysis" in report:
                bench_data = report["benchmark_analysis"]
                total_eval = bench_data.get("total_evaluated", 0)
                perf_dist = bench_data.get("performance_distribution", {})
                if total_eval > 0:
                    print(f"  æ€§èƒ½è©•ä¼°: å„ªç§€={perf_dist.get('excellent', 0)}, è‰¯å¥½={perf_dist.get('good', 0)}, ä¸€èˆ¬={perf_dist.get('average', 0)}, å¾…æ”¹å–„={perf_dist.get('poor', 0)}")
            
            print("\nğŸ“‹ æª¢æŸ¥è¼¸å‡ºç›®éŒ„ 'test_results' ä»¥æŸ¥çœ‹è©³ç´°å ±å‘Š")
            
        else:
            print("âŒ åˆ†æå¤±æ•—ï¼Œè«‹æª¢æŸ¥ç›¸é—œæª”æ¡ˆæ˜¯å¦å­˜åœ¨")
            
    except Exception as e:
        print(f"âŒ åŸ·è¡Œåˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        import traceback
        traceback.print_exc()