#!/usr/bin/env python3
"""
æ¸¬è©¦ train_lora.py çš„è¨“ç·´å‘½ä»¤
"""
import os
import sys

# åŠ å…¥ train_lora.py çš„è·¯å¾‘
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def test_command_generation():
    """æ¸¬è©¦å‘½ä»¤ç”Ÿæˆ"""
    from train_lora import train_lora
    
    # æš«æ™‚é‡å¯« train_lora å‡½æ•¸ä¾†åªè¿”å›å‘½ä»¤
    import train_lora as tl
    
    # å‚™ä»½åŸå‡½æ•¸
    original_train_lora = tl.train_lora
    
    def mock_train_lora(continue_from_checkpoint=False):
        """Mockç‰ˆæœ¬ï¼Œåªç”Ÿæˆå‘½ä»¤ä¸åŸ·è¡Œ"""
        
        # åŸºæœ¬è¨“ç·´æŒ‡ä»¤
        cmd_parts = [
            "python train_network.py",
            "--pretrained_model_name_or_path=../models/Stable-diffusion/v1-5-pruned-emaonly.safetensors",
            "--train_data_dir=lora_train_set",
            "--output_dir=lora_output",
            "--resolution=512,512",
            "--network_module=networks.lora",
            "--network_dim=32",
            "--train_batch_size=1",
            "--max_train_steps=100",
            "--mixed_precision=fp16",
            "--cache_latents",
            "--learning_rate=5e-5",
            "--save_every_n_epochs=50",
            "--save_model_as=safetensors",
            "--save_state"
        ]
        
        cmd = " ".join(cmd_parts)
        print(f"ç”Ÿæˆçš„å‘½ä»¤: {cmd}")
        return cmd
    
    # æ¸¬è©¦å‘½ä»¤ç”Ÿæˆ
    cmd = mock_train_lora()
    
    # æª¢æŸ¥æ˜¯å¦åŒ…å« logging_interval
    if "logging_interval" in cmd:
        print("âŒ ç™¼ç¾ logging_interval åƒæ•¸ï¼")
        return False
    else:
        print("âœ… æ²’æœ‰ç™¼ç¾ logging_interval åƒæ•¸")
        return True

if __name__ == "__main__":
    print("ğŸ§ª æ¸¬è©¦è¨“ç·´å‘½ä»¤ç”Ÿæˆ...")
    success = test_command_generation()
    sys.exit(0 if success else 1)
