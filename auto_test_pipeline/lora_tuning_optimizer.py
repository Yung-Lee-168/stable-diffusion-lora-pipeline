#!/usr/bin/env python3
"""
LoRA èª¿å„ªè‡ªå‹•åŒ–è…³æœ¬
æ ¹æ“šåˆ†æçµæœè‡ªå‹•èª¿æ•´ LoRA è¨“ç·´åƒæ•¸ï¼Œä¸¦ç”Ÿæˆä¸‹ä¸€è¼ªè¨“ç·´é…ç½®

åŠŸèƒ½ï¼š
1. è®€å–åˆ†æå ±å‘Š
2. è‡ªå‹•è¨ˆç®—æœ€ä½³åƒæ•¸
3. ç”Ÿæˆè¨“ç·´é…ç½®æ–‡ä»¶
4. æä¾›åƒæ•¸èª¿æ•´å»ºè­°
5. æ”¯æ´å¤šè¼ªè¿­ä»£å„ªåŒ–
"""

import json
import os
import datetime
import argparse
from typing import Dict, Any, List, Tuple

class LoRATuningOptimizer:
    """LoRA èª¿å„ªå„ªåŒ–å™¨"""
    
    def __init__(self):
        self.base_config = {
            "learning_rate": 0.0005,
            "steps": 100,
            "batch_size": 1,
            "resolution": "512x512",
            "network_dim": 32,
            "network_alpha": 32,
            "clip_skip": 2,
            "mixed_precision": "fp16",
            "save_every_n_epochs": 1,
            "lr_scheduler": "cosine",
            "lr_warmup_steps": 0,
            "noise_offset": 0.0,
            "adaptive_noise_scale": 0.0,
            "cache_latents": True,
            "cache_text_encoder_outputs": True,
            "enable_bucket": True,
            "bucket_no_upscale": True,
            "bucket_reso_steps": 64,
            "min_bucket_reso": 256,
            "max_bucket_reso": 1024
        }
        
        self.optimization_history = []
        self.iteration_count = 0
        
    def load_analysis_report(self, report_path: str) -> Dict[str, Any]:
        """è¼‰å…¥åˆ†æå ±å‘Š"""
        try:
            with open(report_path, 'r', encoding='utf-8') as f:
                report = json.load(f)
            print(f"âœ… æˆåŠŸè¼‰å…¥åˆ†æå ±å‘Šï¼š{report_path}")
            return report
        except Exception as e:
            print(f"âŒ è¼‰å…¥åˆ†æå ±å‘Šå¤±æ•—ï¼š{e}")
            return {}
    
    def analyze_current_performance(self, report: Dict[str, Any]) -> Dict[str, float]:
        """åˆ†æç•¶å‰æ€§èƒ½æŒ‡æ¨™"""
        performance = {
            "total_loss": 1.0,
            "visual_similarity": 0.0,
            "fashion_clip_similarity": 0.0,
            "color_similarity": 0.0,
            "overall_score": 0.0,
            "training_efficiency": 0.0
        }
        
        # å¾ benchmark_analysis æå–æŒ‡æ¨™
        if "benchmark_analysis" in report:
            benchmark = report["benchmark_analysis"]
            avg_metrics = benchmark.get("average_metrics", {})
            
            performance["total_loss"] = avg_metrics.get("avg_total_loss", 1.0)
            performance["visual_similarity"] = avg_metrics.get("avg_visual_similarity", 0.0)
            performance["fashion_clip_similarity"] = avg_metrics.get("avg_fashion_clip_similarity", 0.0)
            performance["color_similarity"] = avg_metrics.get("avg_color_similarity", 0.0)
        
        # å¾ lora_tuning æå–æ•´é«”åˆ†æ•¸
        if "lora_tuning" in report:
            lora_tuning = report["lora_tuning"]
            performance["overall_score"] = lora_tuning.get("overall_tuning_score", 0.0)
            
            # è¨“ç·´æ•ˆç‡
            if "training_efficiency" in lora_tuning:
                performance["training_efficiency"] = lora_tuning["training_efficiency"].get("score", 0.0)
        
        return performance
    
    def calculate_optimal_parameters(self, performance: Dict[str, float]) -> Dict[str, Any]:
        """æ ¹æ“šæ€§èƒ½æŒ‡æ¨™è¨ˆç®—æœ€ä½³åƒæ•¸"""
        config = self.base_config.copy()
        
        total_loss = performance["total_loss"]
        visual_sim = performance["visual_similarity"]
        fashion_sim = performance["fashion_clip_similarity"]
        overall_score = performance["overall_score"]
        efficiency = performance["training_efficiency"]
        
        # å­¸ç¿’ç‡èª¿æ•´ç­–ç•¥
        if total_loss > 0.8:
            config["learning_rate"] = 0.0002  # å¤§å¹…é™ä½
        elif total_loss > 0.6:
            config["learning_rate"] = 0.0003  # é©åº¦é™ä½
        elif total_loss > 0.4:
            config["learning_rate"] = 0.0005  # æ¨™æº–å€¼
        elif total_loss > 0.2:
            config["learning_rate"] = 0.0008  # ç¨å¾®æé«˜
        else:
            config["learning_rate"] = 0.001   # å¯ä»¥æ›´ç©æ¥µ
        
        # è¨“ç·´æ­¥æ•¸èª¿æ•´
        if fashion_sim < 0.3:
            config["steps"] = 300  # éœ€è¦æ›´å¤šè¨“ç·´
        elif fashion_sim < 0.5:
            config["steps"] = 200  # é©åº¦å¢åŠ 
        elif fashion_sim < 0.7:
            config["steps"] = 150  # æ¨™æº–è¨“ç·´
        else:
            config["steps"] = 100  # ä¿æŒæ•ˆç‡
        
        # ç¶²è·¯ç¶­åº¦èª¿æ•´
        if overall_score < 0.4:
            config["network_dim"] = 64   # å¢åŠ å®¹é‡
            config["network_alpha"] = 64
        elif overall_score < 0.6:
            config["network_dim"] = 48   # é©åº¦å¢åŠ 
            config["network_alpha"] = 48
        elif overall_score > 0.8:
            config["network_dim"] = 16   # æ¸›å°‘éæ“¬åˆ
            config["network_alpha"] = 16
        
        # è§£æåº¦èª¿æ•´
        if visual_sim < 0.3:
            config["resolution"] = "768x768"  # æé«˜è§£æåº¦
        elif visual_sim < 0.5:
            config["resolution"] = "640x640"  # é©åº¦æé«˜
        else:
            config["resolution"] = "512x512"  # æ¨™æº–è§£æåº¦
        
        # å­¸ç¿’ç‡èª¿åº¦å™¨
        if total_loss > 0.6:
            config["lr_scheduler"] = "cosine_with_restarts"
            config["lr_warmup_steps"] = config["steps"] // 10
        elif efficiency < 0.5:
            config["lr_scheduler"] = "polynomial"
            config["lr_warmup_steps"] = 0
        else:
            config["lr_scheduler"] = "cosine"
            config["lr_warmup_steps"] = 0
        
        # é›œè¨Šåç§»èª¿æ•´
        if visual_sim < 0.4:
            config["noise_offset"] = 0.1  # å¢åŠ è®ŠåŒ–
        elif visual_sim > 0.7:
            config["noise_offset"] = 0.0  # ä¿æŒç©©å®š
        
        # æ··åˆç²¾åº¦
        if efficiency < 0.6:
            config["mixed_precision"] = "bf16"  # æ›´é«˜æ•ˆç‡
        else:
            config["mixed_precision"] = "fp16"  # å¹³è¡¡å“è³ª
        
        return config
    
    def generate_training_weights(self, performance: Dict[str, float]) -> Dict[str, float]:
        """ç”Ÿæˆè¨“ç·´æ¬Šé‡é…ç½®"""
        weights = {
            "visual_weight": 0.2,
            "fashion_clip_weight": 0.6,
            "color_weight": 0.2,
            "text_encoder_weight": 1.0,
            "unet_weight": 1.0
        }
        
        visual_sim = performance["visual_similarity"]
        fashion_sim = performance["fashion_clip_similarity"]
        color_sim = performance["color_similarity"]
        
        # å‹•æ…‹èª¿æ•´æ¬Šé‡
        if visual_sim < 0.3:
            weights["visual_weight"] = 0.4  # åŠ å¼·è¦–è¦º
            weights["fashion_clip_weight"] = 0.4
            weights["color_weight"] = 0.2
        elif fashion_sim < 0.4:
            weights["visual_weight"] = 0.15  # åŠ å¼·ç‰¹å¾µ
            weights["fashion_clip_weight"] = 0.7
            weights["color_weight"] = 0.15
        elif color_sim < 0.3:
            weights["visual_weight"] = 0.15  # åŠ å¼·è‰²å½©
            weights["fashion_clip_weight"] = 0.55
            weights["color_weight"] = 0.3
        
        # æ–‡æœ¬ç·¨ç¢¼å™¨æ¬Šé‡
        if fashion_sim < 0.4:
            weights["text_encoder_weight"] = 0.5  # æ¸›å°‘æ–‡æœ¬ç·¨ç¢¼å™¨å­¸ç¿’
        elif fashion_sim > 0.7:
            weights["text_encoder_weight"] = 0.2  # é€²ä¸€æ­¥æ¸›å°‘
        
        return weights
    
    def create_optimization_plan(self, performance: Dict[str, float]) -> List[Dict[str, Any]]:
        """å‰µå»ºå¤šè¼ªå„ªåŒ–è¨ˆåŠƒ"""
        plan = []
        
        total_loss = performance["total_loss"]
        overall_score = performance["overall_score"]
        
        # æ ¹æ“šç•¶å‰è¡¨ç¾æ±ºå®šè¼ªæ•¸
        if overall_score < 0.4:
            iterations = 4  # éœ€è¦å¤šè¼ªå„ªåŒ–
        elif overall_score < 0.6:
            iterations = 3  # é©åº¦å„ªåŒ–
        elif overall_score < 0.8:
            iterations = 2  # å¾®èª¿
        else:
            iterations = 1  # ç¶­æŒ
        
        for i in range(iterations):
            # æ¯è¼ªé€æ­¥èª¿æ•´
            iteration_performance = performance.copy()
            
            # æ¨¡æ“¬æ”¹å–„
            iteration_performance["total_loss"] *= (0.8 ** (i + 1))
            iteration_performance["visual_similarity"] *= (1.1 ** (i + 1))
            iteration_performance["fashion_clip_similarity"] *= (1.05 ** (i + 1))
            iteration_performance["overall_score"] *= (1.1 ** (i + 1))
            
            # é™åˆ¶åœ¨åˆç†ç¯„åœ
            iteration_performance["total_loss"] = max(0.1, iteration_performance["total_loss"])
            iteration_performance["visual_similarity"] = min(0.9, iteration_performance["visual_similarity"])
            iteration_performance["fashion_clip_similarity"] = min(0.9, iteration_performance["fashion_clip_similarity"])
            iteration_performance["overall_score"] = min(1.0, iteration_performance["overall_score"])
            
            config = self.calculate_optimal_parameters(iteration_performance)
            weights = self.generate_training_weights(iteration_performance)
            
            plan.append({
                "iteration": i + 1,
                "target_performance": iteration_performance,
                "config": config,
                "weights": weights,
                "description": f"ç¬¬ {i + 1} è¼ªå„ªåŒ–ï¼š{'åŸºç¤æ”¹å–„' if i == 0 else 'é€²éšèª¿æ•´' if i == 1 else 'ç´°å¾®èª¿æ•´' if i == 2 else 'ç²¾ç´°å„ªåŒ–'}"
            })
        
        return plan
    
    def save_optimization_configs(self, plan: List[Dict[str, Any]], output_dir: str = "optimization_configs"):
        """ä¿å­˜å„ªåŒ–é…ç½®æ–‡ä»¶"""
        os.makedirs(output_dir, exist_ok=True)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        
        saved_files = []
        
        for iteration_plan in plan:
            iteration = iteration_plan["iteration"]
            config = iteration_plan["config"]
            weights = iteration_plan["weights"]
            
            # ä¿å­˜è¨“ç·´é…ç½®
            config_file = os.path.join(output_dir, f"lora_config_iter_{iteration}_{timestamp}.json")
            full_config = {
                "metadata": {
                    "iteration": iteration,
                    "timestamp": timestamp,
                    "description": iteration_plan["description"]
                },
                "training_config": config,
                "loss_weights": weights,
                "target_performance": iteration_plan["target_performance"]
            }
            
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(full_config, f, indent=2, ensure_ascii=False)
            
            saved_files.append(config_file)
            
            # ç”Ÿæˆå‘½ä»¤è¡Œåƒæ•¸
            cmd_file = os.path.join(output_dir, f"lora_command_iter_{iteration}_{timestamp}.txt")
            command = self.generate_training_command(config, weights)
            
            with open(cmd_file, 'w', encoding='utf-8') as f:
                f.write(command)
            
            saved_files.append(cmd_file)
        
        # ä¿å­˜å„ªåŒ–è¨ˆåŠƒç¸½è¦½
        plan_file = os.path.join(output_dir, f"optimization_plan_{timestamp}.json")
        with open(plan_file, 'w', encoding='utf-8') as f:
            json.dump(plan, f, indent=2, ensure_ascii=False)
        
        saved_files.append(plan_file)
        
        return saved_files
    
    def generate_training_command(self, config: Dict[str, Any], weights: Dict[str, float]) -> str:
        """ç”Ÿæˆè¨“ç·´å‘½ä»¤"""
        command = "python train_lora.py"
        
        # åŸºæœ¬åƒæ•¸
        command += f" --learning_rate {config['learning_rate']}"
        command += f" --max_train_steps {config['steps']}"
        command += f" --train_batch_size {config['batch_size']}"
        command += f" --resolution {config['resolution']}"
        command += f" --network_dim {config['network_dim']}"
        command += f" --network_alpha {config['network_alpha']}"
        command += f" --clip_skip {config['clip_skip']}"
        command += f" --mixed_precision {config['mixed_precision']}"
        command += f" --save_every_n_epochs {config['save_every_n_epochs']}"
        command += f" --lr_scheduler {config['lr_scheduler']}"
        
        # å¯é¸åƒæ•¸
        if config.get('lr_warmup_steps', 0) > 0:
            command += f" --lr_warmup_steps {config['lr_warmup_steps']}"
        
        if config.get('noise_offset', 0) > 0:
            command += f" --noise_offset {config['noise_offset']}"
        
        # æ¬Šé‡åƒæ•¸
        command += f" --visual_weight {weights['visual_weight']}"
        command += f" --fashion_clip_weight {weights['fashion_clip_weight']}"
        command += f" --color_weight {weights['color_weight']}"
        command += f" --text_encoder_lr {config['learning_rate'] * weights['text_encoder_weight']}"
        command += f" --unet_lr {config['learning_rate'] * weights['unet_weight']}"
        
        # æ•ˆèƒ½å„ªåŒ–
        if config.get('cache_latents', True):
            command += " --cache_latents"
        if config.get('cache_text_encoder_outputs', True):
            command += " --cache_text_encoder_outputs"
        if config.get('enable_bucket', True):
            command += " --enable_bucket"
        if config.get('bucket_no_upscale', True):
            command += " --bucket_no_upscale"
        
        command += f" --bucket_reso_steps {config.get('bucket_reso_steps', 64)}"
        command += f" --min_bucket_reso {config.get('min_bucket_reso', 256)}"
        command += f" --max_bucket_reso {config.get('max_bucket_reso', 1024)}"
        
        return command
    
    def generate_optimization_report(self, plan: List[Dict[str, Any]], performance: Dict[str, float]) -> str:
        """ç”Ÿæˆå„ªåŒ–å ±å‘Š"""
        report = f"""
# LoRA èª¿å„ªå„ªåŒ–å ±å‘Š
ç”Ÿæˆæ™‚é–“ï¼š{datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## ç•¶å‰æ€§èƒ½åˆ†æ
- ç¸½æå¤±ï¼š{performance['total_loss']:.3f}
- è¦–è¦ºç›¸ä¼¼åº¦ï¼š{performance['visual_similarity']:.3f}
- FashionCLIP ç›¸ä¼¼åº¦ï¼š{performance['fashion_clip_similarity']:.3f}
- è‰²å½©ç›¸ä¼¼åº¦ï¼š{performance['color_similarity']:.3f}
- æ•´é«”åˆ†æ•¸ï¼š{performance['overall_score']:.3f}
- è¨“ç·´æ•ˆç‡ï¼š{performance['training_efficiency']:.3f}

## å„ªåŒ–è¨ˆåŠƒï¼ˆå…± {len(plan)} è¼ªï¼‰
"""
        
        for i, iteration_plan in enumerate(plan):
            config = iteration_plan["config"]
            weights = iteration_plan["weights"]
            target = iteration_plan["target_performance"]
            
            report += f"""
### ç¬¬ {i + 1} è¼ªï¼š{iteration_plan['description']}

**ç›®æ¨™æ€§èƒ½ï¼š**
- ç¸½æå¤±ï¼š{target['total_loss']:.3f}
- è¦–è¦ºç›¸ä¼¼åº¦ï¼š{target['visual_similarity']:.3f}
- FashionCLIP ç›¸ä¼¼åº¦ï¼š{target['fashion_clip_similarity']:.3f}

**è¨“ç·´åƒæ•¸ï¼š**
- å­¸ç¿’ç‡ï¼š{config['learning_rate']}
- è¨“ç·´æ­¥æ•¸ï¼š{config['steps']}
- ç¶²è·¯ç¶­åº¦ï¼š{config['network_dim']}
- è§£æåº¦ï¼š{config['resolution']}
- èª¿åº¦å™¨ï¼š{config['lr_scheduler']}

**æå¤±æ¬Šé‡ï¼š**
- è¦–è¦ºæ¬Šé‡ï¼š{weights['visual_weight']:.2f}
- FashionCLIP æ¬Šé‡ï¼š{weights['fashion_clip_weight']:.2f}
- è‰²å½©æ¬Šé‡ï¼š{weights['color_weight']:.2f}
"""
        
        report += f"""
## åŸ·è¡Œå»ºè­°
1. æŒ‰é †åºåŸ·è¡Œå„è¼ªé…ç½®
2. æ¯è¼ªè¨“ç·´å¾ŒåŸ·è¡Œåˆ†æè…³æœ¬
3. æ ¹æ“šçµæœèª¿æ•´ä¸‹ä¸€è¼ªåƒæ•¸
4. ä¿å­˜æ¯è¼ªçš„æœ€ä½³æª¢æŸ¥é»

## æˆåŠŸæ¨™æº–
- ç¸½æå¤± < 0.4
- è¦–è¦ºç›¸ä¼¼åº¦ > 0.5
- FashionCLIP ç›¸ä¼¼åº¦ > 0.6
- æ•´é«”åˆ†æ•¸ > 0.7
"""
        
        return report

def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description="LoRA èª¿å„ªè‡ªå‹•åŒ–å·¥å…·")
    parser.add_argument("--report", type=str, help="åˆ†æå ±å‘Š JSON æ–‡ä»¶è·¯å¾‘")
    parser.add_argument("--output_dir", type=str, default="optimization_configs", help="è¼¸å‡ºç›®éŒ„")
    parser.add_argument("--iterations", type=int, default=None, help="æŒ‡å®šå„ªåŒ–è¼ªæ•¸")
    
    args = parser.parse_args()
    
    # å¦‚æœæ²’æœ‰æŒ‡å®šå ±å‘Šï¼Œå°‹æ‰¾æœ€æ–°çš„
    if not args.report:
        report_dir = "test_results"
        if os.path.exists(report_dir):
            json_files = [f for f in os.listdir(report_dir) if f.startswith("training_report_") and f.endswith(".json")]
            if json_files:
                json_files.sort(reverse=True)
                args.report = os.path.join(report_dir, json_files[0])
                print(f"ğŸ“„ ä½¿ç”¨æœ€æ–°å ±å‘Šï¼š{args.report}")
            else:
                print("âŒ æ‰¾ä¸åˆ°åˆ†æå ±å‘Šæ–‡ä»¶")
                return
        else:
            print("âŒ æ‰¾ä¸åˆ° test_results ç›®éŒ„")
            return
    
    # å‰µå»ºå„ªåŒ–å™¨
    optimizer = LoRATuningOptimizer()
    
    # è¼‰å…¥å ±å‘Š
    report = optimizer.load_analysis_report(args.report)
    if not report:
        print("âŒ ç„¡æ³•è¼‰å…¥åˆ†æå ±å‘Š")
        return
    
    # åˆ†ææ€§èƒ½
    performance = optimizer.analyze_current_performance(report)
    print(f"ğŸ“Š ç•¶å‰æ€§èƒ½ï¼šç¸½æå¤±={performance['total_loss']:.3f}, æ•´é«”åˆ†æ•¸={performance['overall_score']:.3f}")
    
    # å‰µå»ºå„ªåŒ–è¨ˆåŠƒ
    plan = optimizer.create_optimization_plan(performance)
    print(f"ğŸ“‹ å„ªåŒ–è¨ˆåŠƒï¼š{len(plan)} è¼ªèª¿å„ª")
    
    # ä¿å­˜é…ç½®
    saved_files = optimizer.save_optimization_configs(plan, args.output_dir)
    print(f"ğŸ’¾ å·²ä¿å­˜ {len(saved_files)} å€‹é…ç½®æ–‡ä»¶åˆ°ï¼š{args.output_dir}")
    
    # ç”Ÿæˆå ±å‘Š
    optimization_report = optimizer.generate_optimization_report(plan, performance)
    report_file = os.path.join(args.output_dir, f"optimization_report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.md")
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(optimization_report)
    
    print(f"ğŸ“‹ å„ªåŒ–å ±å‘Šå·²ä¿å­˜ï¼š{report_file}")
    print("âœ… LoRA èª¿å„ªé…ç½®ç”Ÿæˆå®Œæˆ")
    
    # é¡¯ç¤ºä¸‹ä¸€æ­¥å»ºè­°
    print("\nğŸš€ åŸ·è¡Œå»ºè­°ï¼š")
    for i, iteration_plan in enumerate(plan):
        config_file = [f for f in saved_files if f.endswith(f"iter_{i + 1}_*.json")][0]
        cmd_file = [f for f in saved_files if f.endswith(f"iter_{i + 1}_*.txt")][0]
        print(f"   {i + 1}. ä½¿ç”¨é…ç½®ï¼š{config_file}")
        print(f"      å‘½ä»¤æ–‡ä»¶ï¼š{cmd_file}")

if __name__ == "__main__":
    main()
