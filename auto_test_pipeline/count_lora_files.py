#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LoRA è¨“ç·´çµæœæ–‡ä»¶è¨ˆæ•¸å™¨
ç²¾ç¢ºè¨ˆç®— LoRA è¨“ç·´å®Œæˆå¾Œæœƒç”¢ç”Ÿå¤šå°‘å€‹æ–‡ä»¶
"""

import os
import sys
from pathlib import Path

def count_lora_output_files(output_dir="lora_output"):
    """çµ±è¨ˆ LoRA è¼¸å‡ºç›®éŒ„ä¸­çš„æ‰€æœ‰æ–‡ä»¶"""
    
    if not os.path.exists(output_dir):
        print(f"âŒ è¼¸å‡ºç›®éŒ„ä¸å­˜åœ¨: {output_dir}")
        return
    
    print(f"ğŸ“Š çµ±è¨ˆ LoRA è¨“ç·´è¼¸å‡ºæ–‡ä»¶")
    print("=" * 50)
    
    total_files = 0
    total_size = 0
    
    # 1. ä¸»è¦ LoRA æ¨¡å‹æ–‡ä»¶ (.safetensors)
    lora_files = []
    for file in os.listdir(output_dir):
        if file.endswith('.safetensors') and os.path.isfile(os.path.join(output_dir, file)):
            lora_files.append(file)
            file_path = os.path.join(output_dir, file)
            file_size = os.path.getsize(file_path)
            total_size += file_size
    
    print(f"\nğŸ¯ ä¸»è¦ LoRA æ¨¡å‹æ–‡ä»¶:")
    print(f"   æ•¸é‡: {len(lora_files)} å€‹")
    for lora_file in lora_files:
        file_path = os.path.join(output_dir, lora_file)
        file_size = os.path.getsize(file_path) / (1024*1024)  # MB
        print(f"   ğŸ“„ {lora_file} ({file_size:.2f} MB)")
    total_files += len(lora_files)
    
    # 2. è¨“ç·´ç‹€æ…‹ç›®éŒ„ä¸­çš„æ–‡ä»¶
    state_dirs = []
    for item in os.listdir(output_dir):
        item_path = os.path.join(output_dir, item)
        if os.path.isdir(item_path) and not item.startswith('logs'):
            state_dirs.append(item_path)
    
    state_files_total = 0
    print(f"\nğŸ”„ è¨“ç·´ç‹€æ…‹ç›®éŒ„:")
    print(f"   ç‹€æ…‹ç›®éŒ„æ•¸é‡: {len(state_dirs)} å€‹")
    
    for state_dir in state_dirs:
        if os.path.exists(state_dir):
            state_files = []
            for root, dirs, files in os.walk(state_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    state_files.append(file_path)
                    file_size = os.path.getsize(file_path)
                    total_size += file_size
            
            state_files_total += len(state_files)
            dir_name = os.path.basename(state_dir)
            print(f"   ğŸ“ {dir_name}: {len(state_files)} å€‹æ–‡ä»¶")
            
            # é¡¯ç¤ºä¸»è¦æ–‡ä»¶é¡å‹
            file_types = {}
            for file_path in state_files:
                ext = os.path.splitext(file_path)[1] or 'ç„¡å‰¯æª”å'
                file_types[ext] = file_types.get(ext, 0) + 1
            
            print(f"      æ–‡ä»¶é¡å‹: {dict(file_types)}")
    
    total_files += state_files_total
    
    # 3. TensorBoard æ—¥èªŒæ–‡ä»¶
    log_dir = os.path.join(output_dir, "logs")
    log_files_total = 0
    
    print(f"\nğŸ“Š TensorBoard æ—¥èªŒ:")
    if os.path.exists(log_dir):
        log_files = []
        for root, dirs, files in os.walk(log_dir):
            for file in files:
                file_path = os.path.join(root, file)
                log_files.append(file_path)
                file_size = os.path.getsize(file_path)
                total_size += file_size
        
        log_files_total = len(log_files)
        print(f"   æ—¥èªŒæ–‡ä»¶æ•¸é‡: {log_files_total} å€‹")
        
        # æŒ‰æ–‡ä»¶é¡å‹åˆ†é¡
        tb_events = [f for f in log_files if 'events.out.tfevents' in os.path.basename(f)]
        other_logs = [f for f in log_files if 'events.out.tfevents' not in os.path.basename(f)]
        
        print(f"   ğŸ“ˆ TensorBoard äº‹ä»¶æ–‡ä»¶: {len(tb_events)} å€‹")
        print(f"   ğŸ“ å…¶ä»–æ—¥èªŒæ–‡ä»¶: {len(other_logs)} å€‹")
        
        # é¡¯ç¤ºä¸€äº›å…·é«”æ–‡ä»¶
        if tb_events:
            for tb_file in tb_events[:3]:  # åªé¡¯ç¤ºå‰3å€‹
                file_size = os.path.getsize(tb_file) / 1024  # KB
                print(f"      ğŸ“Š {os.path.basename(tb_file)} ({file_size:.1f} KB)")
    else:
        print(f"   âŒ æ—¥èªŒç›®éŒ„ä¸å­˜åœ¨")
    
    total_files += log_files_total
    
    # 4. æª¢æŸ¥å‚™ä»½æ–‡ä»¶
    backup_files_total = 0
    backup_patterns = ["lora_backup_", "backup_", "_backup"]
    
    print(f"\nğŸ—„ï¸ å‚™ä»½æ–‡ä»¶:")
    backup_files = []
    for file in os.listdir(output_dir):
        if any(pattern in file for pattern in backup_patterns) and file.endswith('.safetensors'):
            backup_files.append(file)
            file_path = os.path.join(output_dir, file)
            file_size = os.path.getsize(file_path)
            total_size += file_size
    
    backup_files_total = len(backup_files)
    print(f"   å‚™ä»½æ–‡ä»¶æ•¸é‡: {backup_files_total} å€‹")
    for backup_file in backup_files:
        file_path = os.path.join(output_dir, backup_file)
        file_size = os.path.getsize(file_path) / (1024*1024)  # MB
        print(f"   ğŸ—‚ï¸ {backup_file} ({file_size:.2f} MB)")
    
    total_files += backup_files_total
    
    # 5. å…¶ä»–é›œé …æ–‡ä»¶
    other_files = []
    for file in os.listdir(output_dir):
        file_path = os.path.join(output_dir, file)
        if os.path.isfile(file_path):
            # æ’é™¤å·²çµ±è¨ˆçš„æ–‡ä»¶
            if (not file.endswith('.safetensors') and 
                not any(pattern in file for pattern in backup_patterns)):
                other_files.append(file)
                file_size = os.path.getsize(file_path)
                total_size += file_size
    
    print(f"\nğŸ“„ å…¶ä»–æ–‡ä»¶:")
    print(f"   å…¶ä»–æ–‡ä»¶æ•¸é‡: {len(other_files)} å€‹")
    for other_file in other_files:
        file_path = os.path.join(output_dir, other_file)
        file_size = os.path.getsize(file_path) / 1024  # KB
        print(f"   ğŸ“‹ {other_file} ({file_size:.1f} KB)")
    
    total_files += len(other_files)
    
    # ç¸½çµ
    print("\n" + "=" * 50)
    print(f"ğŸ“ˆ ç¸½è¨ˆçµ±è¨ˆ:")
    print(f"   ğŸ¯ LoRA æ¨¡å‹æ–‡ä»¶: {len(lora_files)} å€‹")
    print(f"   ğŸ”„ ç‹€æ…‹æ–‡ä»¶: {state_files_total} å€‹")
    print(f"   ğŸ“Š æ—¥èªŒæ–‡ä»¶: {log_files_total} å€‹")
    print(f"   ğŸ—„ï¸ å‚™ä»½æ–‡ä»¶: {backup_files_total} å€‹")
    print(f"   ğŸ“„ å…¶ä»–æ–‡ä»¶: {len(other_files)} å€‹")
    print(f"   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print(f"   ğŸ“Š ç¸½æ–‡ä»¶æ•¸é‡: {total_files} å€‹")
    print(f"   ğŸ’¾ ç¸½å ç”¨ç©ºé–“: {total_size / (1024*1024):.2f} MB")
    print("=" * 50)

def estimate_typical_file_count():
    """ä¼°ç®—å…¸å‹ LoRA è¨“ç·´æœƒç”¢ç”Ÿçš„æ–‡ä»¶æ•¸é‡"""
    print(f"\nğŸ¯ å…¸å‹ LoRA è¨“ç·´æ–‡ä»¶æ•¸é‡ä¼°ç®—:")
    print("=" * 40)
    
    print(f"ğŸ“‹ åŸºæ–¼è¨“ç·´åƒæ•¸çš„å…¸å‹æ–‡ä»¶æ•¸é‡:")
    print(f"   ğŸ¯ LoRA æ¨¡å‹æ–‡ä»¶:")
    print(f"      - last.safetensors (æœ€çµ‚æ¨¡å‹): 1 å€‹")
    print(f"      - å¦‚æœ‰ save_every_n_steps: å¯èƒ½ 2-5 å€‹")
    
    print(f"   ğŸ”„ è¨“ç·´ç‹€æ…‹ç›®éŒ„ (1å€‹ç›®éŒ„åŒ…å«):")
    print(f"      - optimizer.pt: 1 å€‹")
    print(f"      - train_state.json: 1 å€‹")
    print(f"      - random_states.pkl: 1 å€‹")
    print(f"      - lr_scheduler.pt: 1 å€‹")
    print(f"      - accelerateç›¸é—œæ–‡ä»¶: 2-3 å€‹")
    print(f"      - å…¶ä»–ç‹€æ…‹æ–‡ä»¶: 1-2 å€‹")
    print(f"      å°è¨ˆ: ç´„ 7-10 å€‹æ–‡ä»¶")
    
    print(f"   ğŸ“Š TensorBoard æ—¥èªŒ:")
    print(f"      - events.out.tfevents.* : 1 å€‹")
    print(f"      - å…¶ä»–å…ƒæ•¸æ“šæ–‡ä»¶: 0-2 å€‹")
    print(f"      å°è¨ˆ: ç´„ 1-3 å€‹æ–‡ä»¶")
    
    print(f"   ğŸ—„ï¸ å‚™ä»½æ–‡ä»¶:")
    print(f"      - è¨“ç·´å‰å‚™ä»½: 0-1 å€‹")
    
    print(f"   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print(f"   ğŸ“Š å…¸å‹ç¸½æ•¸: 10-20 å€‹æ–‡ä»¶")
    print(f"   ğŸ’¾ å…¸å‹å¤§å°: 50-200 MB")
    print("=" * 40)
    
    print(f"\nğŸ’¡ å½±éŸ¿æ–‡ä»¶æ•¸é‡çš„å› ç´ :")
    print(f"   â€¢ save_every_n_steps: è¨­å®šè¶Šå°ï¼Œæ¨¡å‹æ–‡ä»¶è¶Šå¤š")
    print(f"   â€¢ è¨“ç·´æ™‚é–“é•·çŸ­: æ—¥èªŒæ–‡ä»¶å¯èƒ½æ›´å¤š")
    print(f"   â€¢ æ˜¯å¦ç¹¼çºŒè¨“ç·´: å‚™ä»½æ–‡ä»¶æ•¸é‡")
    print(f"   â€¢ è¨“ç·´åƒæ•¸è¤‡é›œåº¦: ç‹€æ…‹æ–‡ä»¶å¤§å°")

def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description="LoRA è¨“ç·´çµæœæ–‡ä»¶è¨ˆæ•¸å™¨")
    parser.add_argument("--output_dir", "-o", default="lora_output",
                       help="LoRA è¼¸å‡ºç›®éŒ„è·¯å¾‘")
    parser.add_argument("--estimate", "-e", action="store_true",
                       help="åªé¡¯ç¤ºå…¸å‹ä¼°ç®—ï¼Œä¸æƒæå¯¦éš›æ–‡ä»¶")
    
    args = parser.parse_args()
    
    if args.estimate:
        estimate_typical_file_count()
    else:
        count_lora_output_files(args.output_dir)
        estimate_typical_file_count()

if __name__ == "__main__":
    main()
