#!/usr/bin/env python3
"""
å¿«é€ŸæŠ€è¡“æŒ‡æ¨™æŸ¥çœ‹å™¨
å¿«é€ŸæŸ¥çœ‹æœ€æ–°çš„ LoRA èª¿æ•™æŠ€è¡“æŒ‡æ¨™ï¼Œæ”¯æ´å³æ™‚ç›£æ§å’Œæ­·å²æ¯”è¼ƒ

ä½¿ç”¨æ–¹å¼ï¼š
python quick_metrics_viewer.py [é¸é …]

é¸é …ï¼š
--latest        æŸ¥çœ‹æœ€æ–°æŒ‡æ¨™
--history       æŸ¥çœ‹æ­·å²è¶¨å‹¢
--compare       æ¯”è¼ƒå¤šè¼ªçµæœ
--dashboard     ç”Ÿæˆå„€è¡¨æ¿
--monitor       é–‹å§‹å³æ™‚ç›£æ§
"""

import json
import os
import sys
import argparse
import datetime
from typing import Dict, List, Any, Optional
import glob

class QuickMetricsViewer:
    """å¿«é€ŸæŠ€è¡“æŒ‡æ¨™æŸ¥çœ‹å™¨"""
    
    def __init__(self, results_dir: str = "test_results"):
        self.results_dir = results_dir
        
    def get_latest_report(self) -> Optional[str]:
        """ç²å–æœ€æ–°å ±å‘Šè·¯å¾‘"""
        if not os.path.exists(self.results_dir):
            return None
        
        json_files = glob.glob(os.path.join(self.results_dir, "training_report_*.json"))
        if not json_files:
            return None
        
        # æŒ‰æ™‚é–“æ’åºï¼Œå–æœ€æ–°çš„
        json_files.sort(key=os.path.getmtime, reverse=True)
        return json_files[0]
    
    def load_report(self, report_path: str) -> Optional[Dict[str, Any]]:
        """è¼‰å…¥å ±å‘Š"""
        try:
            with open(report_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ è¼‰å…¥å ±å‘Šå¤±æ•—ï¼š{e}")
            return None
    
    def display_latest_metrics(self):
        """é¡¯ç¤ºæœ€æ–°æŠ€è¡“æŒ‡æ¨™"""
        latest_report = self.get_latest_report()
        if not latest_report:
            print("âŒ æ²’æœ‰æ‰¾åˆ°åˆ†æå ±å‘Š")
            return
        
        report = self.load_report(latest_report)
        if not report:
            return
        
        print("=" * 60)
        print("ğŸ¯ æœ€æ–° LoRA èª¿æ•™æŠ€è¡“æŒ‡æ¨™")
        print("=" * 60)
        
        # åŸºæœ¬è³‡è¨Š
        print(f"ğŸ“… åˆ†ææ™‚é–“ï¼š{report.get('analysis_time', 'N/A')}")
        print(f"ğŸ“ å ±å‘Šæª”æ¡ˆï¼š{os.path.basename(latest_report)}")
        print()
        
        # ä¸‰åŸºæº–é»è©•ä¼°
        if "benchmark_analysis" in report:
            self._display_benchmark_metrics(report["benchmark_analysis"])
        
        # LoRA èª¿å„ªæŒ‡æ¨™
        if "lora_tuning" in report:
            self._display_lora_tuning_metrics(report["lora_tuning"])
        
        # èª¿å„ªç›®æ¨™
        if "tuning_targets" in report:
            self._display_tuning_targets(report["tuning_targets"])
    
    def _display_benchmark_metrics(self, benchmark: Dict[str, Any]):
        """é¡¯ç¤ºåŸºæº–æŒ‡æ¨™"""
        print("ğŸ“Š ä¸‰åŸºæº–é»æ€§èƒ½è©•ä¼°")
        print("-" * 40)
        
        avg_metrics = benchmark.get("average_metrics", {})
        benchmark_comparison = benchmark.get("benchmark_comparison", {})
        
        # é¡¯ç¤ºå¹³å‡æŒ‡æ¨™
        print(f"ç¸½æå¤±ï¼š{avg_metrics.get('avg_total_loss', 'N/A'):.3f}")
        print(f"è¦–è¦ºç›¸ä¼¼åº¦ï¼š{avg_metrics.get('avg_visual_similarity', 'N/A'):.3f}")
        print(f"FashionCLIP ç›¸ä¼¼åº¦ï¼š{avg_metrics.get('avg_fashion_clip_similarity', 'N/A'):.3f}")
        print(f"è‰²å½©ç›¸ä¼¼åº¦ï¼š{avg_metrics.get('avg_color_similarity', 'N/A'):.3f}")
        print()
        
        # é¡¯ç¤ºèˆ‡åƒè€ƒå€¼æ¯”è¼ƒ
        print("ğŸ“ˆ èˆ‡åƒè€ƒå€¼æ¯”è¼ƒï¼š")
        for key, value in benchmark_comparison.items():
            if isinstance(value, (int, float)):
                status = "ğŸ“ˆ" if value > 0 else "ğŸ“‰" if value < 0 else "â¡ï¸"
                print(f"  {key}: {status} {value:+.3f}")
        print()
        
        # é¡¯ç¤ºæ€§èƒ½åˆ†å¸ƒ
        if "performance_distribution" in benchmark:
            dist = benchmark["performance_distribution"]
            total = sum(dist.values())
            print("ğŸ† æ€§èƒ½åˆ†å¸ƒï¼š")
            for level, count in dist.items():
                percentage = (count / total * 100) if total > 0 else 0
                print(f"  {level.capitalize()}: {count} ({percentage:.1f}%)")
        print()
    
    def _display_lora_tuning_metrics(self, lora_tuning: Dict[str, Any]):
        """é¡¯ç¤º LoRA èª¿å„ªæŒ‡æ¨™"""
        print("ğŸ¯ LoRA èª¿å„ªå°ˆæ¥­æŒ‡æ¨™")
        print("-" * 40)
        
        # è¨“ç·´æ•ˆç‡
        if "training_efficiency" in lora_tuning:
            eff = lora_tuning["training_efficiency"]
            print(f"è¨“ç·´æ•ˆç‡ï¼š{eff.get('grade', 'N/A').upper()} (åˆ†æ•¸: {eff.get('score', 'N/A'):.3f})")
            print(f"  æ•ˆç‡æ¯”ç‡ï¼š{eff.get('efficiency_ratio', 'N/A'):.3f}")
        
        # ç”Ÿæˆå“è³ª
        if "generation_quality" in lora_tuning:
            qual = lora_tuning["generation_quality"]
            print(f"ç”Ÿæˆå“è³ªï¼š{qual.get('grade', 'N/A').upper()} (åˆ†æ•¸: {qual.get('score', 'N/A'):.3f})")
            print(f"  å¹³å‡ SSIMï¼š{qual.get('average_ssim', 'N/A'):.3f}")
        
        # ç‰¹å¾µä¿æŒ
        if "feature_preservation" in lora_tuning:
            feat = lora_tuning["feature_preservation"]
            print(f"ç‰¹å¾µä¿æŒï¼š{feat.get('grade', 'N/A').upper()} (åˆ†æ•¸: {feat.get('score', 'N/A'):.3f})")
            print(f"  FashionCLIP ç›¸ä¼¼åº¦ï¼š{feat.get('fashion_clip_similarity', 'N/A'):.3f}")
        
        # æ•´é«”åˆ†æ•¸
        overall_score = lora_tuning.get("overall_tuning_score", 0)
        if overall_score >= 0.9:
            grade = "EXCELLENT âœ¨"
        elif overall_score >= 0.7:
            grade = "GOOD âœ…"
        elif overall_score >= 0.5:
            grade = "AVERAGE âš ï¸"
        else:
            grade = "POOR âŒ"
        
        print(f"æ•´é«”èª¿å„ªåˆ†æ•¸ï¼š{overall_score:.3f} ({grade})")
        print()
    
    def _display_tuning_targets(self, tuning_targets: Dict[str, Any]):
        """é¡¯ç¤ºèª¿å„ªç›®æ¨™"""
        print("ğŸ¯ ä¸‹ä¸€è¼ªèª¿å„ªç›®æ¨™")
        print("-" * 40)
        
        # ç•¶å‰è¡¨ç¾
        if "current_performance" in tuning_targets:
            current = tuning_targets["current_performance"]
            print("ğŸ“Š ç•¶å‰è¡¨ç¾ï¼š")
            for key, value in current.items():
                if isinstance(value, (int, float)):
                    print(f"  {key}: {value:.3f}")
        
        # ç›®æ¨™æŒ‡æ¨™
        if "target_metrics" in tuning_targets:
            targets = tuning_targets["target_metrics"]
            print("ğŸ¯ ç›®æ¨™æŒ‡æ¨™ï¼š")
            for key, value in targets.items():
                if isinstance(value, (int, float)):
                    print(f"  {key}: {value:.3f}")
        
        # åƒæ•¸å»ºè­°
        if "parameter_suggestions" in tuning_targets:
            params = tuning_targets["parameter_suggestions"]
            print("âš™ï¸ åƒæ•¸å»ºè­°ï¼š")
            for key, value in params.items():
                print(f"  {key}: {value}")
        print()
    
    def display_history(self, limit: int = 5):
        """é¡¯ç¤ºæ­·å²è¶¨å‹¢"""
        if not os.path.exists(self.results_dir):
            print("âŒ æ²’æœ‰æ‰¾åˆ°çµæœç›®éŒ„")
            return
        
        json_files = glob.glob(os.path.join(self.results_dir, "training_report_*.json"))
        if not json_files:
            print("âŒ æ²’æœ‰æ‰¾åˆ°æ­·å²å ±å‘Š")
            return
        
        # æŒ‰æ™‚é–“æ’åº
        json_files.sort(key=os.path.getmtime, reverse=True)
        json_files = json_files[:limit]
        
        print("=" * 60)
        print(f"ğŸ“ˆ æœ€è¿‘ {min(len(json_files), limit)} æ¬¡èª¿æ•™æ­·å²")
        print("=" * 60)
        
        for i, file_path in enumerate(json_files):
            report = self.load_report(file_path)
            if not report:
                continue
            
            print(f"\nç¬¬ {i+1} æ¬¡èª¿æ•™ï¼š{os.path.basename(file_path)}")
            print(f"æ™‚é–“ï¼š{report.get('analysis_time', 'N/A')}")
            
            # é—œéµæŒ‡æ¨™
            if "benchmark_analysis" in report:
                avg_metrics = report["benchmark_analysis"].get("average_metrics", {})
                print(f"ç¸½æå¤±ï¼š{avg_metrics.get('avg_total_loss', 'N/A'):.3f}")
                print(f"è¦–è¦ºç›¸ä¼¼åº¦ï¼š{avg_metrics.get('avg_visual_similarity', 'N/A'):.3f}")
                print(f"FashionCLIP ç›¸ä¼¼åº¦ï¼š{avg_metrics.get('avg_fashion_clip_similarity', 'N/A'):.3f}")
            
            if "lora_tuning" in report:
                overall_score = report["lora_tuning"].get("overall_tuning_score", 0)
                print(f"æ•´é«”åˆ†æ•¸ï¼š{overall_score:.3f}")
            
            print("-" * 30)
    
    def compare_latest_reports(self, count: int = 3):
        """æ¯”è¼ƒæœ€æ–°å¹¾æ¬¡çš„å ±å‘Š"""
        if not os.path.exists(self.results_dir):
            print("âŒ æ²’æœ‰æ‰¾åˆ°çµæœç›®éŒ„")
            return
        
        json_files = glob.glob(os.path.join(self.results_dir, "training_report_*.json"))
        if len(json_files) < 2:
            print("âŒ éœ€è¦è‡³å°‘ 2 å€‹å ±å‘Šæ‰èƒ½æ¯”è¼ƒ")
            return
        
        # æŒ‰æ™‚é–“æ’åº
        json_files.sort(key=os.path.getmtime, reverse=True)
        json_files = json_files[:count]
        
        print("=" * 60)
        print(f"ğŸ” æœ€è¿‘ {min(len(json_files), count)} æ¬¡èª¿æ•™æ¯”è¼ƒ")
        print("=" * 60)
        
        # è¼‰å…¥å ±å‘Š
        reports = []
        for file_path in json_files:
            report = self.load_report(file_path)
            if report:
                reports.append({
                    "file": os.path.basename(file_path),
                    "data": report
                })
        
        if len(reports) < 2:
            print("âŒ ç„¡æ³•è¼‰å…¥è¶³å¤ çš„å ±å‘Šé€²è¡Œæ¯”è¼ƒ")
            return
        
        # æ¯”è¼ƒé—œéµæŒ‡æ¨™
        print("ğŸ“Š é—œéµæŒ‡æ¨™æ¯”è¼ƒï¼š")
        print("-" * 40)
        
        metrics_to_compare = [
            ("ç¸½æå¤±", "benchmark_analysis.average_metrics.avg_total_loss"),
            ("è¦–è¦ºç›¸ä¼¼åº¦", "benchmark_analysis.average_metrics.avg_visual_similarity"),
            ("FashionCLIP ç›¸ä¼¼åº¦", "benchmark_analysis.average_metrics.avg_fashion_clip_similarity"),
            ("æ•´é«”åˆ†æ•¸", "lora_tuning.overall_tuning_score")
        ]
        
        for metric_name, metric_path in metrics_to_compare:
            print(f"\n{metric_name}ï¼š")
            values = []
            for report in reports:
                value = self._get_nested_value(report["data"], metric_path)
                if value is not None:
                    values.append(value)
                    print(f"  {report['file']}: {value:.3f}")
            
            # é¡¯ç¤ºæ”¹å–„æƒ…æ³
            if len(values) >= 2:
                if metric_name == "ç¸½æå¤±":
                    change = values[0] - values[1]  # æå¤±é™ä½æ˜¯å¥½çš„
                    status = "æ”¹å–„ ğŸ“ˆ" if change < 0 else "æƒ¡åŒ– ğŸ“‰" if change > 0 else "æŒå¹³ â¡ï¸"
                else:
                    change = values[0] - values[1]  # å…¶ä»–æŒ‡æ¨™æé«˜æ˜¯å¥½çš„
                    status = "æ”¹å–„ ğŸ“ˆ" if change > 0 else "æƒ¡åŒ– ğŸ“‰" if change < 0 else "æŒå¹³ â¡ï¸"
                
                print(f"  è®ŠåŒ–ï¼š{change:+.3f} ({status})")
    
    def _get_nested_value(self, data: Dict[str, Any], path: str) -> Optional[float]:
        """ç²å–åµŒå¥—å­—å…¸çš„å€¼"""
        keys = path.split(".")
        current = data
        
        for key in keys:
            if isinstance(current, dict) and key in current:
                current = current[key]
            else:
                return None
        
        return current if isinstance(current, (int, float)) else None
    
    def start_monitoring(self):
        """é–‹å§‹å³æ™‚ç›£æ§"""
        print("ğŸ” é–‹å§‹å³æ™‚ç›£æ§...")
        print("æŒ‰ Ctrl+C åœæ­¢ç›£æ§")
        
        try:
            import time
            from lora_tuning_monitor import LoRATuningMonitor
            
            monitor = LoRATuningMonitor(self.results_dir)
            
            while True:
                # æª¢æŸ¥æ˜¯å¦æœ‰æ–°å ±å‘Š
                report = monitor.load_latest_report()
                if report:
                    metrics = monitor.extract_metrics(report)
                    if metrics:
                        monitor.update_metrics(metrics)
                        
                        # ç”Ÿæˆå„€è¡¨æ¿
                        dashboard_path = os.path.join(self.results_dir, 
                                                    f"realtime_dashboard_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.png")
                        monitor.generate_dashboard(dashboard_path)
                
                time.sleep(30)  # æ¯30ç§’æª¢æŸ¥ä¸€æ¬¡
                
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ç›£æ§å·²åœæ­¢")
        except ImportError:
            print("âŒ ç›£æ§åŠŸèƒ½éœ€è¦ lora_tuning_monitor æ¨¡çµ„")

def main():
    parser = argparse.ArgumentParser(description="å¿«é€ŸæŠ€è¡“æŒ‡æ¨™æŸ¥çœ‹å™¨")
    parser.add_argument("--latest", action="store_true", help="æŸ¥çœ‹æœ€æ–°æŒ‡æ¨™")
    parser.add_argument("--history", action="store_true", help="æŸ¥çœ‹æ­·å²è¶¨å‹¢")
    parser.add_argument("--compare", action="store_true", help="æ¯”è¼ƒå¤šè¼ªçµæœ")
    parser.add_argument("--monitor", action="store_true", help="é–‹å§‹å³æ™‚ç›£æ§")
    parser.add_argument("--results-dir", default="test_results", help="çµæœç›®éŒ„è·¯å¾‘")
    parser.add_argument("--limit", type=int, default=5, help="æ­·å²è¨˜éŒ„é™åˆ¶æ•¸é‡")
    
    args = parser.parse_args()
    
    viewer = QuickMetricsViewer(args.results_dir)
    
    if args.latest:
        viewer.display_latest_metrics()
    elif args.history:
        viewer.display_history(args.limit)
    elif args.compare:
        viewer.compare_latest_reports(args.limit)
    elif args.monitor:
        viewer.start_monitoring()
    else:
        # é è¨­é¡¯ç¤ºæœ€æ–°æŒ‡æ¨™
        viewer.display_latest_metrics()

if __name__ == "__main__":
    main()
