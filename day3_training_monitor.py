#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Day 3: Training Monitor and Visualizer
è¨“ç·´ç›£æ§å’Œå¯è¦–åŒ–å·¥å…· - å¯¦æ™‚ç›£æ§è¨“ç·´é€²åº¦ã€æå¤±è®ŠåŒ–å’Œç”Ÿæˆå“è³ª
"""

import os
import json
import torch
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from matplotlib.animation import FuncAnimation
import numpy as np
from datetime import datetime, timedelta
import time
from PIL import Image
from collections import deque
import threading
import logging

# è¨­ç½®ä¸­æ–‡å­—é«”
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'SimHei']
plt.rcParams['axes.unicode_minus'] = False

# å˜—è©¦å°å…¥ seabornï¼Œå¦‚æœå¤±æ•—å‰‡ä½¿ç”¨é»˜èªæ¨£å¼
try:
    import seaborn as sns
    sns.set_style("whitegrid")
    HAS_SEABORN = True
except ImportError:
    print("âš ï¸  Seaborn æœªå®‰è£ï¼Œä½¿ç”¨ matplotlib é»˜èªæ¨£å¼")
    HAS_SEABORN = False

class TrainingMonitor:
    """è¨“ç·´ç›£æ§å™¨"""
    
    def __init__(self, checkpoint_dir="day3_finetuning_results/checkpoints", 
                 output_dir="day3_finetuning_results/monitoring"):
        self.checkpoint_dir = checkpoint_dir
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # ç›£æ§æ•¸æ“š
        self.losses = deque(maxlen=1000)  # æœ€è¿‘1000å€‹æå¤±å€¼
        self.timestamps = deque(maxlen=1000)
        self.epochs = deque(maxlen=1000)
        self.steps = deque(maxlen=1000)
        self.learning_rates = deque(maxlen=1000)
        
        # GPU ç›£æ§
        self.gpu_memory = deque(maxlen=100)
        self.gpu_utilization = deque(maxlen=100)
        
        # è¨“ç·´ç‹€æ…‹
        self.start_time = None
        self.current_epoch = 0
        self.total_epochs = 0
        self.is_training = False
        
        # æ—¥èªŒè¨­ç½®
        self.setup_logging()
        
    def setup_logging(self):
        """è¨­ç½®æ—¥èªŒ"""
        log_path = os.path.join(self.output_dir, "training_monitor.log")
        logging.basicConfig(
            filename=log_path,
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            encoding='utf-8'
        )
        self.logger = logging.getLogger(__name__)
    
    def start_monitoring(self, total_epochs=50):
        """é–‹å§‹ç›£æ§"""
        self.start_time = datetime.now()
        self.total_epochs = total_epochs
        self.is_training = True
        
        print("ğŸ” é–‹å§‹è¨“ç·´ç›£æ§...")
        self.logger.info(f"é–‹å§‹ç›£æ§ï¼Œé è¨ˆè¨“ç·´ {total_epochs} epochs")
    
    def update_training_metrics(self, epoch, step, loss, lr=None):
        """æ›´æ–°è¨“ç·´æŒ‡æ¨™"""
        current_time = datetime.now()
        
        self.losses.append(loss)
        self.timestamps.append(current_time)
        self.epochs.append(epoch)
        self.steps.append(step)
        
        if lr is not None:
            self.learning_rates.append(lr)
        
        self.current_epoch = epoch
        
        # è¨˜éŒ„åˆ°æ—¥èªŒ
        self.logger.info(f"Epoch {epoch}, Step {step}, Loss: {loss:.4f}")
    
    def update_gpu_metrics(self):
        """æ›´æ–° GPU æŒ‡æ¨™"""
        if torch.cuda.is_available():
            try:
                # GPU è¨˜æ†¶é«”ä½¿ç”¨ç‡
                memory_used = torch.cuda.memory_allocated() / 1024**3  # GB
                memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**3
                memory_percent = (memory_used / memory_total) * 100
                
                self.gpu_memory.append(memory_percent)
                
                # GPU åˆ©ç”¨ç‡ (ç°¡åŒ–ä¼°ç®—)
                utilization = min(100, memory_percent * 1.2)  # ç°¡åŒ–çš„åˆ©ç”¨ç‡ä¼°ç®—
                self.gpu_utilization.append(utilization)
                
            except Exception as e:
                self.logger.warning(f"GPU æŒ‡æ¨™æ›´æ–°å¤±æ•—: {e}")
    
    def calculate_eta(self):
        """è¨ˆç®—é ä¼°å‰©é¤˜æ™‚é–“"""
        if not self.start_time or self.current_epoch == 0:
            return "æœªçŸ¥"
        
        elapsed = datetime.now() - self.start_time
        progress = self.current_epoch / self.total_epochs
        
        if progress > 0:
            total_time = elapsed / progress
            remaining_time = total_time - elapsed
            
            # æ ¼å¼åŒ–æ™‚é–“
            hours = int(remaining_time.total_seconds() // 3600)
            minutes = int((remaining_time.total_seconds() % 3600) // 60)
            
            return f"{hours:02d}:{minutes:02d}"
        
        return "æœªçŸ¥"
    
    def generate_training_plots(self):
        """ç”Ÿæˆè¨“ç·´åœ–è¡¨"""
        if len(self.losses) < 2:
            return
        
        # å‰µå»ºåœ–è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('Stable Diffusion Fine-tuning è¨“ç·´ç›£æ§', fontsize=16, fontweight='bold')
        
        # 1. æå¤±æ›²ç·š
        ax1 = axes[0, 0]
        if len(self.losses) > 0:
            steps_array = np.array(list(self.steps))
            losses_array = np.array(list(self.losses))
            
            ax1.plot(steps_array, losses_array, 'b-', linewidth=1, alpha=0.7)
            
            # å¹³æ»‘æ›²ç·š
            if len(losses_array) > 10:
                from scipy.ndimage import uniform_filter1d
                smoothed = uniform_filter1d(losses_array, size=min(20, len(losses_array)//5))
                ax1.plot(steps_array, smoothed, 'r-', linewidth=2, label='å¹³æ»‘æ›²ç·š')
            
            ax1.set_title('è¨“ç·´æå¤±æ›²ç·š')
            ax1.set_xlabel('è¨“ç·´æ­¥æ•¸')
            ax1.set_ylabel('æå¤±å€¼')
            ax1.grid(True, alpha=0.3)
            ax1.legend()
        
        # 2. å­¸ç¿’ç‡è®ŠåŒ–
        ax2 = axes[0, 1]
        if len(self.learning_rates) > 0:
            steps_lr = np.array(list(self.steps)[-len(self.learning_rates):])
            lr_array = np.array(list(self.learning_rates))
            
            ax2.plot(steps_lr, lr_array, 'g-', linewidth=2)
            ax2.set_title('å­¸ç¿’ç‡è®ŠåŒ–')
            ax2.set_xlabel('è¨“ç·´æ­¥æ•¸')
            ax2.set_ylabel('å­¸ç¿’ç‡')
            ax2.grid(True, alpha=0.3)
            ax2.ticklabel_format(style='scientific', axis='y', scilimits=(0,0))
        
        # 3. GPU ä½¿ç”¨ç‡
        ax3 = axes[1, 0]
        if len(self.gpu_memory) > 0:
            time_points = np.arange(len(self.gpu_memory))
            memory_array = np.array(list(self.gpu_memory))
            util_array = np.array(list(self.gpu_utilization))
            
            ax3.plot(time_points, memory_array, 'orange', linewidth=2, label='è¨˜æ†¶é«”ä½¿ç”¨ç‡')
            ax3.plot(time_points, util_array, 'purple', linewidth=2, label='GPU åˆ©ç”¨ç‡')
            ax3.set_title('GPU ç›£æ§')
            ax3.set_xlabel('æ™‚é–“é»')
            ax3.set_ylabel('ä½¿ç”¨ç‡ (%)')
            ax3.set_ylim(0, 100)
            ax3.grid(True, alpha=0.3)
            ax3.legend()
        
        # 4. è¨“ç·´é€²åº¦
        ax4 = axes[1, 1]
        progress = (self.current_epoch / self.total_epochs) * 100 if self.total_epochs > 0 else 0
        
        # é€²åº¦æ¢
        ax4.barh(0, progress, height=0.3, color='lightblue', alpha=0.7)
        ax4.barh(0, 100-progress, height=0.3, left=progress, color='lightgray', alpha=0.3)
        
        ax4.set_xlim(0, 100)
        ax4.set_ylim(-0.5, 0.5)
        ax4.set_title(f'è¨“ç·´é€²åº¦: {progress:.1f}%')
        ax4.set_xlabel('å®Œæˆç™¾åˆ†æ¯”')
        ax4.text(50, 0, f'{self.current_epoch}/{self.total_epochs} epochs', 
                ha='center', va='center', fontweight='bold')
        
        # ç§»é™¤ y è»¸
        ax4.set_yticks([])
        
        # æ·»åŠ çµ±è¨ˆä¿¡æ¯
        if len(self.losses) > 0:
            current_loss = self.losses[-1]
            min_loss = min(self.losses)
            avg_loss = np.mean(list(self.losses))
            eta = self.calculate_eta()
            
            stats_text = f"""ç•¶å‰æå¤±: {current_loss:.4f}
æœ€ä½æå¤±: {min_loss:.4f}
å¹³å‡æå¤±: {avg_loss:.4f}
é ä¼°å‰©é¤˜: {eta}"""
            
            fig.text(0.02, 0.02, stats_text, fontsize=10, 
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray", alpha=0.8))
        
        plt.tight_layout()
        
        # ä¿å­˜åœ–è¡¨
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        plot_path = os.path.join(self.output_dir, f"training_monitor_{timestamp}.png")
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        return plot_path
    
    def generate_loss_comparison(self, checkpoints_data):
        """ç”Ÿæˆä¸åŒé…ç½®çš„æå¤±æ¯”è¼ƒåœ–"""
        plt.figure(figsize=(12, 8))
        
        colors = ['blue', 'red', 'green', 'orange', 'purple']
        
        for i, (config_name, data) in enumerate(checkpoints_data.items()):
            if 'losses' in data and len(data['losses']) > 0:
                steps = np.arange(len(data['losses']))
                plt.plot(steps, data['losses'], 
                        color=colors[i % len(colors)], 
                        linewidth=2, 
                        label=config_name,
                        alpha=0.8)
        
        plt.title('ä¸åŒé…ç½®è¨“ç·´æå¤±æ¯”è¼ƒ', fontsize=14, fontweight='bold')
        plt.xlabel('è¨“ç·´æ­¥æ•¸')
        plt.ylabel('æå¤±å€¼')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # ä¿å­˜æ¯”è¼ƒåœ–
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        comparison_path = os.path.join(self.output_dir, f"loss_comparison_{timestamp}.png")
        plt.savefig(comparison_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        return comparison_path
    
    def save_training_summary(self):
        """ä¿å­˜è¨“ç·´æ‘˜è¦"""
        if len(self.losses) == 0:
            return
        
        summary = {
            "training_start": self.start_time.isoformat() if self.start_time else None,
            "training_end": datetime.now().isoformat(),
            "total_epochs": self.total_epochs,
            "current_epoch": self.current_epoch,
            "total_steps": len(self.losses),
            "final_loss": float(self.losses[-1]),
            "min_loss": float(min(self.losses)),
            "avg_loss": float(np.mean(list(self.losses))),
            "loss_std": float(np.std(list(self.losses))),
            "training_duration": str(datetime.now() - self.start_time) if self.start_time else None
        }
        
        # ä¿å­˜åˆ° JSON
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        summary_path = os.path.join(self.output_dir, f"training_summary_{timestamp}.json")
        
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“Š è¨“ç·´æ‘˜è¦å·²ä¿å­˜: {summary_path}")
        return summary_path

class ValidationImageAnalyzer:
    """é©—è­‰åœ–ç‰‡åˆ†æå™¨"""
    
    def __init__(self, validation_dir="day3_finetuning_results/validation_images"):
        self.validation_dir = validation_dir
        self.analysis_results = {}
    
    def analyze_generated_images(self):
        """åˆ†æç”Ÿæˆçš„é©—è­‰åœ–ç‰‡"""
        if not os.path.exists(self.validation_dir):
            print(f"âš ï¸  é©—è­‰åœ–ç‰‡ç›®éŒ„ä¸å­˜åœ¨: {self.validation_dir}")
            return
        
        # æ‰¾åˆ°æ‰€æœ‰é©—è­‰åœ–ç‰‡
        validation_images = []
        for file in os.listdir(self.validation_dir):
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                validation_images.append(os.path.join(self.validation_dir, file))
        
        if not validation_images:
            print("âš ï¸  æ²’æœ‰æ‰¾åˆ°é©—è­‰åœ–ç‰‡")
            return
        
        print(f"ğŸ–¼ï¸  åˆ†æ {len(validation_images)} å¼µé©—è­‰åœ–ç‰‡...")
        
        # åˆ†ææ¯å¼µåœ–ç‰‡
        analysis_results = []
        
        for img_path in validation_images:
            try:
                image = Image.open(img_path)
                analysis = self.analyze_single_image(image, img_path)
                analysis_results.append(analysis)
                
            except Exception as e:
                print(f"âŒ åœ–ç‰‡åˆ†æå¤±æ•— {img_path}: {e}")
        
        # ç”Ÿæˆåˆ†æå ±å‘Š
        self.generate_analysis_report(analysis_results)
        
        return analysis_results
    
    def analyze_single_image(self, image, image_path):
        """åˆ†æå–®å¼µåœ–ç‰‡"""
        # åŸºæœ¬ä¿¡æ¯
        width, height = image.size
        
        # è½‰æ›ç‚º numpy æ•¸çµ„
        img_array = np.array(image)
        
        # é¡è‰²åˆ†æ
        if len(img_array.shape) == 3:
            # RGB åœ–ç‰‡
            r_mean = np.mean(img_array[:, :, 0])
            g_mean = np.mean(img_array[:, :, 1])
            b_mean = np.mean(img_array[:, :, 2])
            
            # äº®åº¦åˆ†æ
            brightness = np.mean(img_array)
            
            # å°æ¯”åº¦åˆ†æ (æ¨™æº–å·®)
            contrast = np.std(img_array)
            
            # é¡è‰²è±å¯Œåº¦ (é¡è‰²ç›´æ–¹åœ–çš„ç†µ)
            hist_r = np.histogram(img_array[:, :, 0], bins=256)[0]
            hist_g = np.histogram(img_array[:, :, 1], bins=256)[0]
            hist_b = np.histogram(img_array[:, :, 2], bins=256)[0]
            
            # è¨ˆç®—ç†µ
            def calculate_entropy(hist):
                hist = hist[hist > 0]  # ç§»é™¤é›¶å€¼
                prob = hist / hist.sum()
                return -np.sum(prob * np.log2(prob))
            
            color_entropy = (calculate_entropy(hist_r) + 
                           calculate_entropy(hist_g) + 
                           calculate_entropy(hist_b)) / 3
        else:
            # ç°åº¦åœ–ç‰‡
            r_mean = g_mean = b_mean = np.mean(img_array)
            brightness = np.mean(img_array)
            contrast = np.std(img_array)
            color_entropy = 0
        
        # é‚Šç·£æª¢æ¸¬ (Canny)
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY) if len(img_array.shape) == 3 else img_array
        edges = cv2.Canny(gray.astype(np.uint8), 50, 150)
        edge_density = np.sum(edges > 0) / (width * height)
        
        return {
            "image_path": os.path.basename(image_path),
            "size": [width, height],
            "color_means": [float(r_mean), float(g_mean), float(b_mean)],
            "brightness": float(brightness),
            "contrast": float(contrast),
            "color_entropy": float(color_entropy),
            "edge_density": float(edge_density),
            "analysis_time": datetime.now().isoformat()
        }
    
    def generate_analysis_report(self, analysis_results):
        """ç”Ÿæˆåˆ†æå ±å‘Š"""
        if not analysis_results:
            return
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # å‰µå»ºåˆ†æåœ–è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('é©—è­‰åœ–ç‰‡å“è³ªåˆ†æ', fontsize=16, fontweight='bold')
        
        # æå–æ•¸æ“š
        brightness_values = [r["brightness"] for r in analysis_results]
        contrast_values = [r["contrast"] for r in analysis_results]
        entropy_values = [r["color_entropy"] for r in analysis_results]
        edge_values = [r["edge_density"] for r in analysis_results]
        
        # 1. äº®åº¦åˆ†å¸ƒ
        axes[0, 0].hist(brightness_values, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        axes[0, 0].set_title('äº®åº¦åˆ†å¸ƒ')
        axes[0, 0].set_xlabel('äº®åº¦å€¼')
        axes[0, 0].set_ylabel('é »ç‡')
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. å°æ¯”åº¦åˆ†å¸ƒ
        axes[0, 1].hist(contrast_values, bins=20, alpha=0.7, color='lightgreen', edgecolor='black')
        axes[0, 1].set_title('å°æ¯”åº¦åˆ†å¸ƒ')
        axes[0, 1].set_xlabel('å°æ¯”åº¦å€¼')
        axes[0, 1].set_ylabel('é »ç‡')
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. é¡è‰²è±å¯Œåº¦åˆ†å¸ƒ
        axes[1, 0].hist(entropy_values, bins=20, alpha=0.7, color='lightcoral', edgecolor='black')
        axes[1, 0].set_title('é¡è‰²è±å¯Œåº¦åˆ†å¸ƒ')
        axes[1, 0].set_xlabel('ç†µå€¼')
        axes[1, 0].set_ylabel('é »ç‡')
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. é‚Šç·£å¯†åº¦åˆ†å¸ƒ
        axes[1, 1].hist(edge_values, bins=20, alpha=0.7, color='gold', edgecolor='black')
        axes[1, 1].set_title('é‚Šç·£å¯†åº¦åˆ†å¸ƒ')
        axes[1, 1].set_xlabel('é‚Šç·£å¯†åº¦')
        axes[1, 1].set_ylabel('é »ç‡')
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜åœ–è¡¨
        chart_path = os.path.join(os.path.dirname(self.validation_dir), 
                                 f"validation_analysis_{timestamp}.png")
        plt.savefig(chart_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        # ä¿å­˜ JSON å ±å‘Š
        report_path = os.path.join(os.path.dirname(self.validation_dir), 
                                  f"validation_report_{timestamp}.json")
        
        report = {
            "analysis_time": datetime.now().isoformat(),
            "total_images": len(analysis_results),
            "statistics": {
                "brightness": {
                    "mean": float(np.mean(brightness_values)),
                    "std": float(np.std(brightness_values)),
                    "min": float(np.min(brightness_values)),
                    "max": float(np.max(brightness_values))
                },
                "contrast": {
                    "mean": float(np.mean(contrast_values)),
                    "std": float(np.std(contrast_values)),
                    "min": float(np.min(contrast_values)),
                    "max": float(np.max(contrast_values))
                },
                "color_entropy": {
                    "mean": float(np.mean(entropy_values)),
                    "std": float(np.std(entropy_values)),
                    "min": float(np.min(entropy_values)),
                    "max": float(np.max(entropy_values))
                },
                "edge_density": {
                    "mean": float(np.mean(edge_values)),
                    "std": float(np.std(edge_values)),
                    "min": float(np.min(edge_values)),
                    "max": float(np.max(edge_values))
                }
            },
            "individual_results": analysis_results
        }
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“Š é©—è­‰åˆ†æå ±å‘Šå·²ä¿å­˜: {report_path}")
        print(f"ğŸ“ˆ åˆ†æåœ–è¡¨å·²ä¿å­˜: {chart_path}")

def main():
    """ä¸»å‡½æ•¸ - ç›£æ§å·¥å…·æ¼”ç¤º"""
    print("ğŸ” è¨“ç·´ç›£æ§å’Œå¯è¦–åŒ–å·¥å…·")
    print("=" * 50)
    
    # å‰µå»ºç›£æ§å™¨
    monitor = TrainingMonitor()
    analyzer = ValidationImageAnalyzer()
    
    # æ¨¡æ“¬ä¸€äº›è¨“ç·´æ•¸æ“š
    print("ğŸ“Š ç”Ÿæˆæ¨¡æ“¬è¨“ç·´æ•¸æ“š...")
    monitor.start_monitoring(total_epochs=20)
    
    # æ¨¡æ“¬è¨“ç·´éç¨‹
    for epoch in range(5):
        for step in range(10):
            # æ¨¡æ“¬æå¤±å€¼
            loss = 0.8 * np.exp(-step * 0.1) + 0.1 + np.random.normal(0, 0.05)
            lr = 1e-4 * (0.95 ** epoch)
            
            monitor.update_training_metrics(epoch, step, loss, lr)
            monitor.update_gpu_metrics()
    
    # ç”Ÿæˆç›£æ§åœ–è¡¨
    plot_path = monitor.generate_training_plots()
    print(f"ğŸ“ˆ ç›£æ§åœ–è¡¨å·²ç”Ÿæˆ: {plot_path}")
    
    # ä¿å­˜è¨“ç·´æ‘˜è¦
    summary_path = monitor.save_training_summary()
    
    # åˆ†æé©—è­‰åœ–ç‰‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    print("\nğŸ–¼ï¸  åˆ†æé©—è­‰åœ–ç‰‡...")
    analyzer.analyze_generated_images()

if __name__ == "__main__":
    # å®‰è£å¿…éœ€çš„åŒ…
    try:
        import scipy
    except ImportError:
        print("âš ï¸  éœ€è¦å®‰è£ scipy: pip install scipy")
    
    try:
        import cv2
    except ImportError:
        print("âš ï¸  éœ€è¦å®‰è£ opencv: pip install opencv-python")
    
    main()
