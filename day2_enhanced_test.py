#!/usr/bin/env python3
"""
å¢å¼·ç‰ˆç¬¬2å¤©æ¸¬è©¦ï¼šCLIP vs FashionCLIP æ¯”è¼ƒ
ç›®æ¨™ï¼šæ¯”è¼ƒé€šç”¨ CLIP å’Œå°ˆæ¥­ FashionCLIP åœ¨æ™‚å°šåœ–ç‰‡åˆ†æä¸Šçš„è¡¨ç¾
"""

import requests
import json
import base64
import os
from datetime import datetime
from PIL import Image
import numpy as np

class EnhancedDay2Tester:
    def __init__(self):
        self.api_url = "http://localhost:7860"
        self.output_dir = "day2_enhanced_results"
        os.makedirs(self.output_dir, exist_ok=True)
        
    def install_requirements(self):
        """æª¢æŸ¥ä¸¦å®‰è£å¿…è¦çš„å¥—ä»¶"""
        print("ğŸ” æª¢æŸ¥æ¨¡å‹ä¾è³´...")
        
        try:
            import torch
            import transformers
            print("âœ… åŸºç¤å¥—ä»¶å·²å®‰è£")
        except ImportError as e:
            print(f"âŒ ç¼ºå°‘åŸºç¤å¥—ä»¶: {e}")
            return False
            
        # æª¢æŸ¥ FashionCLIP
        try:
            import clip
            print("âœ… CLIP å¥—ä»¶å¯ç”¨")
        except ImportError:
            print("âš ï¸ CLIP å¥—ä»¶æœªå®‰è£ï¼Œå°‡ä½¿ç”¨ transformers ç‰ˆæœ¬")
            
        return True
    
    def load_standard_clip(self):
        """è¼‰å…¥æ¨™æº– CLIP æ¨¡å‹ - é‡å°ä½ çš„ç³»çµ±å„ªåŒ– (å®‰å…¨ç‰ˆ)"""
        try:
            from transformers import CLIPProcessor, CLIPModel
            import torch
            
            device = "cuda" if torch.cuda.is_available() else "cpu"
            print(f"ğŸ“¥ å®‰å…¨è¼‰å…¥æ¨™æº– CLIP (è¨­å‚™: {device})...")
            
            # å„ªåŒ–è¼‰å…¥æ–¹æ¡ˆ - é‡å° 4GB VRAM ä½¿ç”¨ float16
            if device == "cuda":
                model = CLIPModel.from_pretrained(
                    "openai/clip-vit-base-patch32",
                    torch_dtype=torch.float16,  # GPU ä½¿ç”¨ float16 ç¯€çœ VRAM
                    low_cpu_mem_usage=True,
                    trust_remote_code=False
                )
            else:
                model = CLIPModel.from_pretrained(
                    "openai/clip-vit-base-patch32",
                    torch_dtype=torch.float32,  # CPU ä½¿ç”¨ float32
                    low_cpu_mem_usage=True,
                    trust_remote_code=False
                )
                
            processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
            model.to(device)
            
            print("âœ… æ¨™æº– CLIP æ¨¡å‹å®‰å…¨è¼‰å…¥æˆåŠŸ")
            return model, processor, "standard_clip"
            
        except Exception as e:
            print(f"âŒ æ¨™æº– CLIP æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            
            # å‚™ç”¨æ–¹æ¡ˆï¼šæ ¹æ“šè¨­å‚™é¸æ“‡ç²¾åº¦
            try:
                print("ğŸ”„ å˜—è©¦å‚™ç”¨è¼‰å…¥æ–¹æ¡ˆ...")
                if device == "cuda":
                    model = CLIPModel.from_pretrained(
                        "openai/clip-vit-base-patch32",
                        torch_dtype=torch.float16,  # GPU ä½¿ç”¨ float16
                        low_cpu_mem_usage=True
                    )
                else:
                    model = CLIPModel.from_pretrained(
                        "openai/clip-vit-base-patch32",
                        torch_dtype=torch.float32,  # CPU ä½¿ç”¨ float32
                        low_cpu_mem_usage=True
                    )
                processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
                model.to(device)
                print("âœ… å‚™ç”¨æ–¹æ¡ˆè¼‰å…¥æˆåŠŸ")
                return model, processor, "standard_clip"
            except Exception as e2:
                print(f"âŒ å‚™ç”¨æ–¹æ¡ˆä¹Ÿå¤±æ•—: {e2}")
                return None, None, None
    
    def load_fashion_clip(self):
        """è¼‰å…¥ FashionCLIP æ¨¡å‹ - é‡å°ä½ çš„ RTX 3050 Ti å„ªåŒ–"""
        try:
            from transformers import CLIPModel, CLIPProcessor
            import torch
            
            # æ ¹æ“šç³»çµ±åˆ†ææ¨è–¦çš„å°ˆæ¥­æ™‚å°šæ¨¡å‹
            fashion_models = [
                "patrickjohncyh/fashion-clip",  # ä¸»è¦æ¨è–¦ï¼šå°ˆæ¥­æ™‚å°šæ¨¡å‹
                "openai/clip-vit-base-patch32"  # å‚™ç”¨æ¨™æº–æ¨¡å‹
            ]
            
            # æª¢æŸ¥ GPU å¯ç”¨æ€§ä¸¦è¨­ç½®è¨­å‚™
            device = "cuda" if torch.cuda.is_available() else "cpu"
            print(f"ğŸ® ä½¿ç”¨è¨­å‚™: {device}")
            
            for model_name in fashion_models:
                try:
                    print(f"ğŸ“¥ æ­£åœ¨è¼‰å…¥ {model_name}...")
                    
                    # å„ªåŒ–è¼‰å…¥æ–¹æ¡ˆ - é‡å° 4GB VRAM ä½¿ç”¨ float16
                    if device == "cuda":
                        model = CLIPModel.from_pretrained(
                            model_name,
                            torch_dtype=torch.float16,  # GPU ä½¿ç”¨ float16 ç¯€çœ VRAM
                            low_cpu_mem_usage=True,
                            trust_remote_code=False
                        )
                    else:
                        model = CLIPModel.from_pretrained(
                            model_name,
                            torch_dtype=torch.float32,  # CPU ä½¿ç”¨ float32
                            low_cpu_mem_usage=True,
                            trust_remote_code=False
                        )
                    
                    processor = CLIPProcessor.from_pretrained(model_name)
                    model.to(device)
                    
                    print(f"âœ… FashionCLIP æ¨¡å‹è¼‰å…¥æˆåŠŸ: {model_name}")
                    print(f"   è¨­å‚™: {device}")
                    print(f"   ç²¾åº¦: {'float16' if device == 'cuda' else 'float32'}")  # æ ¹æ“šè¨­å‚™é¡¯ç¤ºç²¾åº¦
                    
                    return model, processor, "fashion_clip"
                    
                except Exception as e:
                    print(f"âš ï¸ è¼‰å…¥ {model_name} å¤±æ•—: {e}")
                    continue
                    
            print("âš ï¸ å°ˆæ¥­ FashionCLIP ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨™æº– CLIP")
            return self.load_standard_clip()
            
        except Exception as e:
            print(f"âŒ FashionCLIP è¼‰å…¥å¤±æ•—: {e}")
            return None, None, None
    
    def analyze_with_clip(self, image_path, model, processor, model_type):
        """ä½¿ç”¨ CLIP åˆ†æåœ–ç‰‡"""
        try:
            image = Image.open(image_path).convert("RGB")
            
            # æ™‚å°šç›¸é—œæ¨™ç±¤
            if model_type == "fashion_clip":
                fashion_labels = [
                    "elegant evening dress", "casual streetwear", "formal business suit",
                    "vintage retro clothing", "bohemian flowing dress", "modern minimalist outfit",
                    "luxury designer fashion", "sporty athletic wear", "romantic feminine style",
                    "edgy punk fashion", "classic timeless style", "trendy contemporary look",
                    "silk fabric", "cotton material", "leather texture", "denim style",
                    "floral pattern", "solid color", "striped design", "polka dots"
                ]
            else:
                fashion_labels = [
                    "elegant dress", "casual outfit", "formal wear", "vintage style",
                    "modern fashion", "luxury clothing", "street style", "business attire",
                    "evening gown", "summer dress", "winter coat", "bohemian style",
                    "minimalist fashion", "colorful outfit", "black clothing", "white clothing"
                ]
            
            # ä½¿ç”¨æ¨¡å‹åˆ†æ - é‡å° 4GB VRAM å„ªåŒ–ç²¾åº¦è™•ç†
            import torch
            device = next(model.parameters()).device  # ç²å–æ¨¡å‹æ‰€åœ¨è¨­å‚™
            model_dtype = next(model.parameters()).dtype  # ç²å–æ¨¡å‹ç²¾åº¦
            
            inputs = processor(text=fashion_labels, images=image, return_tensors="pt", padding=True)
            # å°‡è¼¸å…¥ç§»åˆ°æ­£ç¢ºè¨­å‚™
            inputs = {k: v.to(device) for k, v in inputs.items()}
            
            # ç¢ºä¿è¼¸å…¥ç²¾åº¦èˆ‡æ¨¡å‹åŒ¹é…
            if model_dtype == torch.float16:
                # å¦‚æœæ¨¡å‹æ˜¯ float16ï¼Œå°‡è¼¸å…¥è½‰æ›ç‚º float16
                for key in inputs:
                    if inputs[key].dtype == torch.float32:
                        inputs[key] = inputs[key].half()
            
            with torch.no_grad():
                outputs = model(**inputs)
                logits_per_image = outputs.logits_per_image
                probs = logits_per_image.softmax(dim=1)
            
            # ç²å–å‰5å€‹æœ€ç›¸é—œçš„æ¨™ç±¤
            top_indices = probs[0].topk(5).indices
            top_labels = [fashion_labels[i] for i in top_indices]
            top_scores = [probs[0][i].item() for i in top_indices]
            
            return {
                "success": True,
                "model_type": model_type,
                "top_labels": top_labels,
                "scores": top_scores,
                "confidence": max(top_scores)
            }
            
        except Exception as e:
            return {
                "success": False,
                "model_type": model_type,
                "error": str(e)
            }
    
    def generate_prompt_from_analysis(self, analysis_results):
        """åŸºæ–¼åˆ†æçµæœç”Ÿæˆæç¤ºè©"""
        all_prompts = {}
        
        for model_type, result in analysis_results.items():
            if result["success"]:
                top_labels = result["top_labels"]
                confidence = result["confidence"]
                
                # æ ¹æ“šç½®ä¿¡åº¦èª¿æ•´æç¤ºè©å¼·åº¦
                if confidence > 0.7:
                    intensity = "highly detailed, professional"
                elif confidence > 0.5:
                    intensity = "detailed, well-crafted"
                else:
                    intensity = "stylized, artistic"
                
                # æ§‹å»ºæç¤ºè©
                base_prompt = ", ".join(top_labels[:3])
                enhanced_prompt = f"{base_prompt}, {intensity}, high fashion photography, studio lighting"
                
                all_prompts[model_type] = {
                    "prompt": enhanced_prompt,
                    "confidence": confidence,
                    "base_labels": top_labels[:3]
                }
            else:
                all_prompts[model_type] = {
                    "prompt": "elegant fashion, high quality, professional photography",
                    "confidence": 0.0,
                    "error": result.get("error", "Unknown error")
                }
        
        return all_prompts
    
    def check_api_connection(self):
        """æª¢æŸ¥ API é€£æ¥ç‹€æ…‹ - æ”¯æŒå¤šç¨®ç«¯é»"""
        print("ğŸ” æª¢æŸ¥ WebUI API é€£æ¥...")
        
        # å˜—è©¦ä¸åŒçš„åŸºç¤ URL
        base_urls = [
            "http://localhost:7860",
            "http://127.0.0.1:7860",
            "http://0.0.0.0:7860"
        ]
        
        # å˜—è©¦ä¸åŒçš„ API ç«¯é»
        api_endpoints = [
            "/sdapi/v1/options",
            "/api/v1/options",
            "/sdapi/v1/cmd-flags",
            "/sdapi/v1/sd-models"
        ]
        
        for base_url in base_urls:
            for endpoint in api_endpoints:
                try:
                    full_url = f"{base_url}{endpoint}"
                    response = requests.get(full_url, timeout=5)
                    
                    if response.status_code == 200:
                        print(f"âœ… API é€£æ¥æˆåŠŸ: {full_url}")
                        self.api_url = base_url  # æ›´æ–°å·¥ä½œçš„åŸºç¤ URL
                        return True
                    
                except requests.exceptions.ConnectionError:
                    continue
                except Exception:
                    continue
        
        # æª¢æŸ¥ä¸»é æ˜¯å¦å¯è¨ªå•
        for base_url in base_urls:
            try:
                response = requests.get(base_url, timeout=5)
                if response.status_code == 200:
                    print(f"âš ï¸ WebUI åœ¨é‹è¡Œ ({base_url}) ä½† API ä¸å¯ç”¨")
                    print("   å¯èƒ½çš„åŸå› :")
                    print("   1. API æ¨¡å¼æœªå•Ÿç”¨ (ç¼ºå°‘ --api åƒæ•¸)")
                    print("   2. WebUI ç‰ˆæœ¬å¤ªèˆŠ")
                    print("   3. API ç«¯é»è·¯å¾‘ä¸åŒ")
                    return False
            except:
                continue
        
        print("âŒ ç„¡æ³•é€£æ¥åˆ° WebUIï¼Œè«‹ç¢ºèª:")
        print("   1. WebUI å·²å•Ÿå‹•")
        print("   2. ä½¿ç”¨äº† --api åƒæ•¸")
        print("   3. ç«¯å£ 7860 æœªè¢«å…¶ä»–ç¨‹åºä½”ç”¨")
        return False

    def test_model_comparison(self):
        """æ¯”è¼ƒ CLIP å’Œ FashionCLIP çš„è¡¨ç¾ - ä½¿ç”¨ Day1 å·²ç”Ÿæˆçš„åœ–ç‰‡"""
        print("ğŸ” é–‹å§‹æ¨¡å‹æ¯”è¼ƒæ¸¬è©¦...")
        
        # æª¢æŸ¥ Day1 ç”Ÿæˆçš„åœ–ç‰‡
        day1_output_dir = "day1_results"
        if not os.path.exists(day1_output_dir):
            print("âŒ æ‰¾ä¸åˆ° Day1 ç”Ÿæˆçš„åœ–ç‰‡")
            print("ğŸ’¡ è«‹å…ˆé‹è¡Œ Day1 æ¸¬è©¦ç”Ÿæˆåœ–ç‰‡")
            return []
        
        # æ‰¾åˆ°æ‰€æœ‰ Day1 ç”Ÿæˆçš„åœ–ç‰‡
        day1_images = []
        for file in os.listdir(day1_output_dir):
            if file.endswith(('.png', '.jpg', '.jpeg')):
                day1_images.append(os.path.join(day1_output_dir, file))
        
        if not day1_images:
            print("âŒ Day1 è³‡æ–™å¤¾ä¸­æ²’æœ‰æ‰¾åˆ°åœ–ç‰‡")
            print("ğŸ’¡ è«‹ç¢ºèª Day1 æ¸¬è©¦å·²æˆåŠŸåŸ·è¡Œ")
            return []
        
        print(f"âœ… æ‰¾åˆ° {len(day1_images)} å¼µ Day1 ç”Ÿæˆçš„åœ–ç‰‡")
        
        # è¼‰å…¥å…©ç¨®æ¨¡å‹
        standard_clip = self.load_standard_clip()
        fashion_clip = self.load_fashion_clip()
        
        models = {}
        if standard_clip[0] is not None:
            models["standard_clip"] = standard_clip
        if fashion_clip[0] is not None and fashion_clip[2] != "standard_clip":
            models["fashion_clip"] = fashion_clip
        
        if not models:
            print("âŒ ç„¡æ³•è¼‰å…¥ä»»ä½• CLIP æ¨¡å‹")
            return []
        
        results = []
        
        # ä½¿ç”¨å‰ 3 å¼µåœ–ç‰‡é€²è¡Œæ¸¬è©¦ï¼ˆæˆ–æ‰€æœ‰åœ–ç‰‡å¦‚æœå°‘æ–¼ 3 å¼µï¼‰
        test_images = day1_images[:3]
        
        for i, image_path in enumerate(test_images):
            print(f"\nğŸ¨ æ¸¬è©¦ {i+1}/{len(test_images)}: {os.path.basename(image_path)}")
            
            # ç”¨ä¸åŒæ¨¡å‹åˆ†æåœ–ç‰‡
            analysis_results = {}
            for model_name, (model, processor, model_type) in models.items():
                print(f"   ğŸ“Š ä½¿ç”¨ {model_type} åˆ†æä¸­...")
                analysis = self.analyze_with_clip(image_path, model, processor, model_type)
                analysis_results[model_type] = analysis
                
                if analysis["success"]:
                    print(f"      âœ… ç½®ä¿¡åº¦: {analysis['confidence']:.3f}")
                    print(f"      ğŸ·ï¸ å‰3æ¨™ç±¤: {', '.join(analysis['top_labels'][:3])}")
                else:
                    print(f"      âŒ åˆ†æå¤±æ•—: {analysis.get('error', 'Unknown error')}")
            
            # ç”ŸæˆåŸºæ–¼åˆ†æçš„æç¤ºè©ï¼ˆåƒ…ç”¨æ–¼æ¯”è¼ƒï¼Œä¸ç”Ÿæˆåœ–ç‰‡ï¼‰
            generated_prompts = self.generate_prompt_from_analysis(analysis_results)
            
            # é¡¯ç¤ºä¸åŒæ¨¡å‹ç”Ÿæˆçš„æç¤ºè©å·®ç•°
            print(f"   ğŸ“ æç¤ºè©æ¯”è¼ƒ:")
            for model_type, prompt_info in generated_prompts.items():
                if prompt_info.get("prompt"):
                    print(f"      {model_type}: {prompt_info['prompt'][:100]}...")
            
            results.append({
                "image_path": image_path,
                "analysis_results": analysis_results,
                "generated_prompts": generated_prompts,
                "success": True
            })
            
            print(f"âœ… æ¸¬è©¦ {i+1} å®Œæˆ")
        
        return results
    
    def run_enhanced_day2_tests(self):
        """é‹è¡Œå¢å¼·ç‰ˆç¬¬2å¤©æ¸¬è©¦"""
        print("=" * 60)
        print("å¢å¼·ç‰ˆç¬¬2å¤©æ¸¬è©¦ï¼šCLIP vs FashionCLIP æ¯”è¼ƒ")
        print("ç›®æ¨™ï¼šä½¿ç”¨ Day1 ç”Ÿæˆçš„åœ–ç‰‡æ¯”è¼ƒä¸åŒ CLIP æ¨¡å‹çš„åˆ†æèƒ½åŠ›")
        print("=" * 60)
        
        # æª¢æŸ¥ç’°å¢ƒ
        if not self.install_requirements():
            print("âŒ ç’°å¢ƒæª¢æŸ¥å¤±æ•—")
            return False
        
        # é‹è¡Œæ¯”è¼ƒæ¸¬è©¦
        results = self.test_model_comparison()
        successful = sum(1 for r in results if r["success"])
        
        print(f"\nå¢å¼·ç‰ˆç¬¬2å¤©æ¸¬è©¦å®Œæˆï¼š{successful}/{len(results)} å€‹æ¸¬è©¦æˆåŠŸ")
        
        # åˆ†æä¸åŒæ¨¡å‹çš„è¡¨ç¾
        self.analyze_model_performance(results)
        
        # ç”Ÿæˆå ±å‘Š
        report = {
            "day": 2,
            "test_type": "enhanced_clip_comparison",
            "timestamp": datetime.now().isoformat(),
            "tests_run": len(results),
            "tests_successful": successful,
            "success_rate": successful / len(results) if results else 0,
            "results": results,
            "model_comparison": self.get_model_comparison_summary(results)
        }
        
        # ä¿å­˜ JSON å ±å‘Š
        with open(os.path.join(self.output_dir, "day2_enhanced_report.json"), "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # ç”Ÿæˆæ˜“è®€çš„ HTML å’Œ Markdown å ±å‘Š
        html_path, md_path = self.generate_readable_report(results, report)
        
        print(f"\nğŸ“Š å ±å‘Šå·²ç”Ÿæˆ:")
        print(f"   ğŸ“„ JSON å ±å‘Š: {os.path.join(self.output_dir, 'day2_enhanced_report.json')}")
        print(f"   ğŸŒ HTML å ±å‘Š: {html_path}")
        print(f"   ğŸ“ Markdown å ±å‘Š: {md_path}")
        print(f"\nğŸ’¡ å»ºè­°ç€è¦½ HTML å ±å‘Šä»¥ç²å¾—æœ€ä½³é–±è®€é«”é©—ï¼")
        
        # ç”Ÿæˆæ˜“è®€å ±å‘Š
        html_report, md_report = self.generate_readable_report(results, report)
        print(f"ğŸ“„ æ˜“è®€å ±å‘Šå·²ç”Ÿæˆ:\n- HTML: {html_report}\n- Markdown: {md_report}")
        
        return True
    
    def analyze_model_performance(self, results):
        """åˆ†æä¸åŒæ¨¡å‹çš„è¡¨ç¾"""
        print("\n" + "=" * 60)
        print("ğŸ“Š æ¨¡å‹è¡¨ç¾æ¯”è¼ƒ")
        print("=" * 60)
        
        model_stats = {}
        
        for result in results:
            if result["success"]:
                for model_type, analysis in result["analysis_results"].items():
                    if model_type not in model_stats:
                        model_stats[model_type] = {
                            "total_tests": 0,
                            "successful_analyses": 0,
                            "avg_confidence": 0,
                            "confidences": []
                        }
                    
                    model_stats[model_type]["total_tests"] += 1
                    if analysis["success"]:
                        model_stats[model_type]["successful_analyses"] += 1
                        model_stats[model_type]["confidences"].append(analysis["confidence"])
        
        # è¨ˆç®—å¹³å‡ç½®ä¿¡åº¦
        for model_type, stats in model_stats.items():
            if stats["confidences"]:
                stats["avg_confidence"] = sum(stats["confidences"]) / len(stats["confidences"])
        
        # é¡¯ç¤ºæ¯”è¼ƒçµæœ
        for model_type, stats in model_stats.items():
            print(f"\nğŸ¤– {model_type.upper()}:")
            print(f"   æˆåŠŸç‡: {stats['successful_analyses']}/{stats['total_tests']}")
            print(f"   å¹³å‡ç½®ä¿¡åº¦: {stats['avg_confidence']:.3f}")
            
            if model_type == "fashion_clip":
                print("   ğŸ‘— å°ˆæ¥­æ™‚å°šæ¨¡å‹ - é æœŸåœ¨æ™‚å°šç´°ç¯€è­˜åˆ¥ä¸Šè¡¨ç¾æ›´å¥½")
            else:
                print("   ğŸ” é€šç”¨æ¨¡å‹ - ç©©å®šå¯é çš„åŸºæº–è¡¨ç¾")
    
    def get_model_comparison_summary(self, results):
        """ç²å–æ¨¡å‹æ¯”è¼ƒæ‘˜è¦"""
        summary = {
            "models_tested": [],
            "recommendation": "",
            "performance_analysis": {}
        }
        
        # å¾çµæœä¸­æå–æ¨¡å‹é¡å‹
        for result in results:
            if result["success"]:
                for model_type in result["analysis_results"].keys():
                    if model_type not in summary["models_tested"]:
                        summary["models_tested"].append(model_type)
        
        # åŸºæ–¼æ¸¬è©¦çµæœçµ¦å‡ºå»ºè­°
        if "fashion_clip" in summary["models_tested"]:
            summary["recommendation"] = "å»ºè­°ä½¿ç”¨ FashionCLIP é€²è¡Œæ™‚å°šç›¸é—œçš„åœ–ç‰‡åˆ†æï¼Œå®ƒå°æœé£¾ç´°ç¯€çš„ç†è§£æ›´åŠ ç²¾ç¢ºã€‚"
        else:
            summary["recommendation"] = "ç›®å‰ä½¿ç”¨æ¨™æº– CLIPï¼Œè¡¨ç¾ç©©å®šã€‚å¦‚éœ€æ›´å°ˆæ¥­çš„æ™‚å°šåˆ†æï¼Œå»ºè­°è€ƒæ…® FashionCLIPã€‚"
        
        return summary

    def generate_readable_report(self, results, report):
        """ç”Ÿæˆæ˜“è®€çš„ HTML å’Œ Markdown å ±å‘Š"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # ç”Ÿæˆ HTML å ±å‘Š
        html_content = f"""
<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Day 2 CLIP vs FashionCLIP æ¯”è¼ƒå ±å‘Š</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }}
        .header {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            border-radius: 10px;
            text-align: center;
            margin-bottom: 30px;
        }}
        .summary {{
            background: white;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        .model-comparison {{
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-bottom: 30px;
        }}
        .model-card {{
            background: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        .model-card.standard {{
            border-left: 5px solid #4CAF50;
        }}
        .model-card.fashion {{
            border-left: 5px solid #FF9800;
        }}
        .test-result {{
            background: white;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        .comparison-table {{
            width: 100%;
            border-collapse: collapse;
            margin-top: 15px;
        }}
        .comparison-table th, .comparison-table td {{
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }}
        .comparison-table th {{
            background-color: #f8f9fa;
            font-weight: bold;
        }}
        .confidence {{
            font-weight: bold;
            color: #2196F3;
        }}
        .labels {{
            background-color: #e3f2fd;
            padding: 8px;
            border-radius: 5px;
            font-size: 0.9em;
        }}
        .prompt {{
            background-color: #f3e5f5;
            padding: 10px;
            border-radius: 5px;
            font-family: monospace;
            font-size: 0.85em;
            margin-top: 10px;
        }}
        .stats {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin-top: 20px;
        }}
        .stat-box {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 15px;
            border-radius: 8px;
            text-align: center;
        }}
        .stat-number {{
            font-size: 2em;
            font-weight: bold;
        }}
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸ¨ Day 2: CLIP vs FashionCLIP æ¯”è¼ƒå ±å‘Š</h1>
        <p>æ¸¬è©¦æ™‚é–“: {timestamp}</p>
    </div>

    <div class="summary">
        <h2>ğŸ“Š æ¸¬è©¦æ‘˜è¦</h2>
        <div class="stats">
            <div class="stat-box">
                <div class="stat-number">{report['tests_run']}</div>
                <div>ç¸½æ¸¬è©¦æ•¸</div>
            </div>
            <div class="stat-box">
                <div class="stat-number">{report['tests_successful']}</div>
                <div>æˆåŠŸæ¸¬è©¦</div>
            </div>
            <div class="stat-box">
                <div class="stat-number">{report['success_rate']:.1%}</div>
                <div>æˆåŠŸç‡</div>
            </div>
        </div>
    </div>

    <div class="model-comparison">"""
        
        # æ·»åŠ æ¨¡å‹æ¯”è¼ƒçµ±è¨ˆ
        model_stats = {}
        for result in results:
            if result["success"]:
                for model_type, analysis in result["analysis_results"].items():
                    if model_type not in model_stats:
                        model_stats[model_type] = {
                            "total_tests": 0,
                            "successful_analyses": 0,
                            "confidences": []
                        }
                    model_stats[model_type]["total_tests"] += 1
                    if analysis["success"]:
                        model_stats[model_type]["successful_analyses"] += 1
                        model_stats[model_type]["confidences"].append(analysis["confidence"])
        
        for model_type, stats in model_stats.items():
            avg_confidence = sum(stats["confidences"]) / len(stats["confidences"]) if stats["confidences"] else 0
            card_class = "standard" if model_type == "standard_clip" else "fashion"
            model_name = "æ¨™æº– CLIP" if model_type == "standard_clip" else "FashionCLIP"
            icon = "ğŸ”" if model_type == "standard_clip" else "ğŸ‘—"
            
            html_content += f"""
        <div class="model-card {card_class}">
            <h3>{icon} {model_name}</h3>
            <p><strong>æˆåŠŸç‡:</strong> {stats['successful_analyses']}/{stats['total_tests']} ({stats['successful_analyses']/stats['total_tests']:.1%})</p>
            <p><strong>å¹³å‡ç½®ä¿¡åº¦:</strong> <span class="confidence">{avg_confidence:.3f}</span></p>
            <p><strong>ç‰¹é»:</strong> {'ç©©å®šå¯é çš„åŸºæº–è¡¨ç¾' if model_type == 'standard_clip' else 'å°ˆæ¥­æ™‚å°šç´°ç¯€è­˜åˆ¥'}</p>
        </div>"""

        html_content += """
    </div>

    <h2>ğŸ” è©³ç´°æ¸¬è©¦çµæœ</h2>"""

        # æ·»åŠ æ¯å€‹æ¸¬è©¦çš„è©³ç´°çµæœ
        for i, result in enumerate(results):
            if result["success"]:
                image_name = os.path.basename(result["image_path"])
                html_content += f"""
    <div class="test-result">
        <h3>æ¸¬è©¦ {i+1}: {image_name}</h3>
        <table class="comparison-table">
            <thead>
                <tr>
                    <th>æ¨¡å‹</th>
                    <th>ç½®ä¿¡åº¦</th>
                    <th>å‰3å€‹æ¨™ç±¤</th>
                    <th>ç”Ÿæˆçš„æç¤ºè©</th>
                </tr>
            </thead>
            <tbody>"""
                
                for model_type, analysis in result["analysis_results"].items():
                    model_name = "æ¨™æº– CLIP" if model_type == "standard_clip" else "FashionCLIP"
                    if analysis["success"]:
                        confidence = analysis["confidence"]
                        labels = ", ".join(analysis["top_labels"][:3])
                        prompt = result["generated_prompts"][model_type]["prompt"]
                        html_content += f"""
                <tr>
                    <td><strong>{model_name}</strong></td>
                    <td><span class="confidence">{confidence:.3f}</span></td>
                    <td><div class="labels">{labels}</div></td>
                    <td><div class="prompt">{prompt}</div></td>
                </tr>"""
                    else:
                        html_content += f"""
                <tr>
                    <td><strong>{model_name}</strong></td>
                    <td>âŒ å¤±æ•—</td>
                    <td colspan="2">{analysis.get('error', 'Unknown error')}</td>
                </tr>"""
                
                html_content += """
            </tbody>
        </table>
    </div>"""

        html_content += f"""
    <div class="summary">
        <h2>ğŸ’¡ å»ºè­°</h2>
        <p>{report['model_comparison']['recommendation']}</p>
    </div>

</body>
</html>"""

        # ä¿å­˜ HTML å ±å‘Š
        html_path = os.path.join(self.output_dir, "day2_comparison_report.html")
        with open(html_path, "w", encoding="utf-8") as f:
            f.write(html_content)
        
        # ç”Ÿæˆ Markdown å ±å‘Š
        md_content = f"""# ğŸ¨ Day 2: CLIP vs FashionCLIP æ¯”è¼ƒå ±å‘Š

**æ¸¬è©¦æ™‚é–“:** {timestamp}

## ğŸ“Š æ¸¬è©¦æ‘˜è¦

- **ç¸½æ¸¬è©¦æ•¸:** {report['tests_run']}
- **æˆåŠŸæ¸¬è©¦:** {report['tests_successful']}
- **æˆåŠŸç‡:** {report['success_rate']:.1%}

## ğŸ¤– æ¨¡å‹è¡¨ç¾æ¯”è¼ƒ

"""
        
        for model_type, stats in model_stats.items():
            avg_confidence = sum(stats["confidences"]) / len(stats["confidences"]) if stats["confidences"] else 0
            model_name = "æ¨™æº– CLIP" if model_type == "standard_clip" else "FashionCLIP"
            icon = "ğŸ”" if model_type == "standard_clip" else "ğŸ‘—"
            
            md_content += f"""### {icon} {model_name}

- **æˆåŠŸç‡:** {stats['successful_analyses']}/{stats['total_tests']} ({stats['successful_analyses']/stats['total_tests']:.1%})
- **å¹³å‡ç½®ä¿¡åº¦:** {avg_confidence:.3f}
- **ç‰¹é»:** {'ç©©å®šå¯é çš„åŸºæº–è¡¨ç¾' if model_type == 'standard_clip' else 'å°ˆæ¥­æ™‚å°šç´°ç¯€è­˜åˆ¥'}

"""

        md_content += "## ğŸ” è©³ç´°æ¸¬è©¦çµæœ\n\n"
        
        for i, result in enumerate(results):
            if result["success"]:
                image_name = os.path.basename(result["image_path"])
                md_content += f"### æ¸¬è©¦ {i+1}: {image_name}\n\n"
                
                for model_type, analysis in result["analysis_results"].items():
                    model_name = "æ¨™æº– CLIP" if model_type == "standard_clip" else "FashionCLIP"
                    if analysis["success"]:
                        confidence = analysis["confidence"]
                        labels = ", ".join(analysis["top_labels"][:3])
                        prompt = result["generated_prompts"][model_type]["prompt"]
                        md_content += f"""**{model_name}:**
- ç½®ä¿¡åº¦: {confidence:.3f}
- å‰3æ¨™ç±¤: {labels}
- ç”Ÿæˆæç¤ºè©: `{prompt}`

"""
                    else:
                        md_content += f"**{model_name}:** âŒ åˆ†æå¤±æ•— - {analysis.get('error', 'Unknown error')}\n\n"

        md_content += f"""## ğŸ’¡ å»ºè­°

{report['model_comparison']['recommendation']}

---

*å ±å‘Šç”Ÿæˆæ™‚é–“: {timestamp}*
"""

        # ä¿å­˜ Markdown å ±å‘Š
        md_path = os.path.join(self.output_dir, "day2_comparison_report.md")
        with open(md_path, "w", encoding="utf-8") as f:
            f.write(md_content)
        
        return html_path, md_path

if __name__ == "__main__":
    tester = EnhancedDay2Tester()
    tester.run_enhanced_day2_tests()
