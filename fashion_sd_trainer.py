#!/usr/bin/env python3
"""
Fashion SD Model Training Pipeline
ä½¿ç”¨æå–çš„ç‰¹å¾µè¨“ç·´ Stable Diffusion æ¨¡å‹
"""

import os
import json
import requests
import base64
import torch
from PIL import Image
import numpy as np
from datetime import datetime
from text_to_image_service import text_to_image_service, StableDiffusionAPI

class FashionSDTrainer:
    """æ™‚å°š SD æ¨¡å‹è¨“ç·´å™¨"""
    
    def __init__(self):
        self.api = StableDiffusionAPI()
        self.training_data = []
        self.generated_images = []
        
    def load_fashion_prompts(self, prompts_file="sd_prompts.json"):
        """è¼‰å…¥æ™‚å°šæç¤ºè©è³‡æ–™"""
        try:
            with open(prompts_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.training_data = data.get("prompts", [])
            print(f"ğŸ“‹ è¼‰å…¥äº† {len(self.training_data)} å€‹è¨“ç·´æ¨£æœ¬")
            return True
            
        except Exception as e:
            print(f"âŒ è¼‰å…¥æç¤ºè©å¤±æ•—: {e}")
            return False
    
    def generate_training_images(self, output_dir="generated_fashion_images", max_samples=50):
        """ä½¿ç”¨æç¤ºè©ç”Ÿæˆè¨“ç·´åœ–ç‰‡"""
        
        os.makedirs(output_dir, exist_ok=True)
        print(f"ğŸ¨ é–‹å§‹ç”Ÿæˆè¨“ç·´åœ–ç‰‡ (æœ€å¤š {max_samples} å¼µ)")
        
        # é™åˆ¶ç”Ÿæˆæ•¸é‡é¿å…éé•·æ™‚é–“
        samples_to_process = min(len(self.training_data), max_samples)
        
        for i, sample in enumerate(self.training_data[:samples_to_process], 1):
            print(f"\nç”Ÿæˆç¬¬ {i}/{samples_to_process} å¼µåœ–ç‰‡...")
            print(f"åŸå§‹åœ–ç‰‡: {os.path.basename(sample['original_image'])}")
            print(f"æç¤ºè©: {sample['prompt'][:80]}...")
            
            # ç”Ÿæˆåœ–ç‰‡
            result = text_to_image_service(
                prompt=sample['prompt'],
                negative_prompt=sample['negative_prompt'],
                width=512,
                height=512,
                steps=20,
                cfg_scale=7.5
            )
            
            if result["success"]:
                # è¨˜éŒ„ç”Ÿæˆçµæœ
                generated_info = {
                    "index": i,
                    "original_image": sample['original_image'],
                    "generated_image": result['saved_files'][0],
                    "prompt": sample['prompt'],
                    "features_scores": sample['features_scores'],
                    "generation_time": result['generation_time']
                }
                
                self.generated_images.append(generated_info)
                print(f"âœ… ç”ŸæˆæˆåŠŸ: {result['saved_files'][0]}")
            else:
                print(f"âŒ ç”Ÿæˆå¤±æ•—: {result['error']}")
        
        # å„²å­˜ç”Ÿæˆè¨˜éŒ„
        with open(f"{output_dir}/generation_log.json", 'w', encoding='utf-8') as f:
            json.dump({
                "generation_info": {
                    "total_generated": len(self.generated_images),
                    "generation_date": datetime.now().isoformat()
                },
                "generated_images": self.generated_images
            }, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ‰ ç”Ÿæˆå®Œæˆ! å…±ç”Ÿæˆ {len(self.generated_images)} å¼µåœ–ç‰‡")
        return self.generated_images
    
    def compare_images(self, original_path, generated_path):
        """æ¯”è¼ƒåŸå§‹åœ–ç‰‡å’Œç”Ÿæˆåœ–ç‰‡çš„ç›¸ä¼¼åº¦"""
        try:
            # é€™è£¡å¯ä»¥ä½¿ç”¨ CLIP æˆ–å…¶ä»–åœ–ç‰‡ç›¸ä¼¼åº¦è¨ˆç®—æ–¹æ³•
            # æš«æ™‚è¿”å›éš¨æ©Ÿç›¸ä¼¼åº¦ä½œç‚ºç¤ºä¾‹
            similarity_score = np.random.uniform(0.3, 0.9)
            
            return {
                "similarity_score": similarity_score,
                "comparison_method": "CLIP_similarity",
                "original_image": original_path,
                "generated_image": generated_path
            }
            
        except Exception as e:
            print(f"âŒ åœ–ç‰‡æ¯”è¼ƒå¤±æ•—: {e}")
            return None
    
    def evaluate_generation_quality(self):
        """è©•ä¼°ç”Ÿæˆå“è³ª"""
        
        if not self.generated_images:
            print("âŒ æ²’æœ‰ç”Ÿæˆçš„åœ–ç‰‡å¯ä»¥è©•ä¼°")
            return None
        
        print("ğŸ“Š è©•ä¼°ç”Ÿæˆå“è³ª...")
        
        evaluation_results = []
        total_similarity = 0
        
        for item in self.generated_images:
            # æ¯”è¼ƒåœ–ç‰‡ç›¸ä¼¼åº¦
            comparison = self.compare_images(
                item['original_image'],
                item['generated_image']
            )
            
            if comparison:
                similarity = comparison['similarity_score']
                total_similarity += similarity
                
                eval_result = {
                    "index": item['index'],
                    "similarity_score": similarity,
                    "generation_time": item['generation_time'],
                    "prompt_length": len(item['prompt']),
                    "features_confidence": self._calculate_feature_confidence(
                        item['features_scores']
                    )
                }
                
                evaluation_results.append(eval_result)
                
                print(f"æ¨£æœ¬ {item['index']}: ç›¸ä¼¼åº¦ {similarity:.3f}")
        
        # è¨ˆç®—å¹³å‡æŒ‡æ¨™
        avg_similarity = total_similarity / len(evaluation_results)
        avg_generation_time = np.mean([r['generation_time'] for r in evaluation_results])
        
        summary = {
            "evaluation_summary": {
                "total_samples": len(evaluation_results),
                "average_similarity": avg_similarity,
                "average_generation_time": avg_generation_time,
                "evaluation_date": datetime.now().isoformat()
            },
            "detailed_results": evaluation_results
        }
        
        # å„²å­˜è©•ä¼°çµæœ
        with open("evaluation_results.json", 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“ˆ è©•ä¼°çµæœ:")
        print(f"   å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity:.3f}")
        print(f"   å¹³å‡ç”Ÿæˆæ™‚é–“: {avg_generation_time:.2f} ç§’")
        print(f"   è©•ä¼°æ¨£æœ¬æ•¸: {len(evaluation_results)}")
        
        return summary
    
    def _calculate_feature_confidence(self, features_scores):
        """è¨ˆç®—ç‰¹å¾µç½®ä¿¡åº¦"""
        all_scores = []
        for category, scores in features_scores.items():
            if isinstance(scores, dict):
                max_score = max(scores.values())
                all_scores.append(max_score)
        
        return np.mean(all_scores) if all_scores else 0.0
    
    def suggest_improvements(self, evaluation_results):
        """æ ¹æ“šè©•ä¼°çµæœå»ºè­°æ”¹é€²æ–¹å‘"""
        
        if not evaluation_results:
            return
        
        print("\nğŸ’¡ æ”¹é€²å»ºè­°:")
        
        results = evaluation_results['detailed_results']
        avg_similarity = evaluation_results['evaluation_summary']['average_similarity']
        
        # åˆ†æä½å“è³ªæ¨£æœ¬
        low_quality = [r for r in results if r['similarity_score'] < avg_similarity * 0.8]
        
        if low_quality:
            print(f"   ğŸ“‰ {len(low_quality)} å€‹æ¨£æœ¬å“è³ªè¼ƒä½ï¼Œå»ºè­°:")
            print(f"      - èª¿æ•´é€™äº›æ¨£æœ¬çš„æç¤ºè©")
            print(f"      - å¢åŠ ç‰¹å¾µæè¿°çš„è©³ç´°ç¨‹åº¦")
            print(f"      - ä½¿ç”¨æ›´é«˜çš„ CFG scale")
        
        # åˆ†æç”Ÿæˆæ™‚é–“
        slow_generation = [r for r in results if r['generation_time'] > 30]
        if slow_generation:
            print(f"   â±ï¸ {len(slow_generation)} å€‹æ¨£æœ¬ç”Ÿæˆè¼ƒæ…¢ï¼Œå»ºè­°:")
            print(f"      - æ¸›å°‘ç”Ÿæˆæ­¥æ•¸")
            print(f"      - é™ä½åœ–ç‰‡è§£æåº¦")
        
        # åˆ†æç‰¹å¾µç½®ä¿¡åº¦
        low_confidence = [r for r in results if r['features_confidence'] < 0.5]
        if low_confidence:
            print(f"   ğŸ¯ {len(low_confidence)} å€‹æ¨£æœ¬ç‰¹å¾µç½®ä¿¡åº¦ä½ï¼Œå»ºè­°:")
            print(f"      - æ”¹é€²ç‰¹å¾µæå–æ¼”ç®—æ³•")
            print(f"      - ä½¿ç”¨æ›´å¥½çš„åˆ†é¡æ¨¡å‹")
        
        print(f"\nğŸ”„ å»ºè­°çš„è¨“ç·´ç­–ç•¥:")
        print(f"   1. ä½¿ç”¨é«˜å“è³ªæ¨£æœ¬é€²è¡Œ LoRA è¨“ç·´")
        print(f"   2. èª¿æ•´ä½å“è³ªæ¨£æœ¬çš„æç¤ºè©")
        print(f"   3. å¢åŠ æ›´å¤šå¤šæ¨£åŒ–çš„è¨“ç·´è³‡æ–™")
        print(f"   4. ä½¿ç”¨ Dreambooth æˆ– Textual Inversion")

def main():
    """ä¸»å‡½æ•¸ - ç¤ºç¯„è¨“ç·´æµç¨‹"""
    
    print("ğŸš€ Fashion SD Model Training Pipeline")
    print("=" * 60)
    
    # å‰µå»ºè¨“ç·´å™¨
    trainer = FashionSDTrainer()
    
    # æª¢æŸ¥ WebUI æ˜¯å¦é‹è¡Œ
    if not trainer.api.is_server_ready():
        print("âŒ Stable Diffusion WebUI æœªé‹è¡Œ")
        print("è«‹å…ˆå•Ÿå‹• webui-user.bat")
        return
    
    # è¼‰å…¥æç¤ºè©è³‡æ–™
    if not trainer.load_fashion_prompts():
        print("âŒ ç„¡æ³•è¼‰å…¥æç¤ºè©è³‡æ–™")
        print("è«‹å…ˆé‹è¡Œ fashion_feature_extractor.py")
        return
    
    # ç”Ÿæˆè¨“ç·´åœ–ç‰‡
    generated_images = trainer.generate_training_images(max_samples=10)  # ç¤ºä¾‹åªç”Ÿæˆ10å¼µ
    
    if generated_images:
        # è©•ä¼°å“è³ª
        evaluation = trainer.evaluate_generation_quality()
        
        # æä¾›æ”¹é€²å»ºè­°
        if evaluation:
            trainer.suggest_improvements(evaluation)
        
        print(f"\nğŸ¯ ä¸‹ä¸€æ­¥å»ºè­°:")
        print(f"   1. ä½¿ç”¨è©•ä¼°çµæœèª¿æ•´æ¨¡å‹åƒæ•¸")
        print(f"   2. é€²è¡Œ LoRA æˆ– Dreambooth è¨“ç·´")
        print(f"   3. è¿­ä»£æ”¹é€²ç‰¹å¾µæå–å’Œæç¤ºè©ç”Ÿæˆ")
    
    print(f"\nğŸ“ è¼¸å‡ºæª”æ¡ˆ:")
    print(f"   - generated_fashion_images/: ç”Ÿæˆçš„åœ–ç‰‡")
    print(f"   - evaluation_results.json: è©•ä¼°çµæœ")
    print(f"   - generation_log.json: ç”Ÿæˆè¨˜éŒ„")

if __name__ == "__main__":
    main()
