{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b8977f9",
   "metadata": {},
   "source": [
    "# ğŸ¨ Day 3: Fashion AI Training - Google Colab ç‰ˆæœ¬\n",
    "\n",
    "## ğŸ“‹ æ¦‚è¿°\n",
    "é€™å€‹ Notebook æä¾›äº†åœ¨ Google Colab ä¸Šé€²è¡Œ Stable Diffusion v1.5 æ™‚å°šå¾®èª¿çš„å®Œæ•´æµç¨‹ã€‚\n",
    "\n",
    "### âœ¨ ç‰¹è‰²åŠŸèƒ½:\n",
    "- ğŸ”§ è‡ªå‹•åµæ¸¬ä¸¦å„ªåŒ– GPU é…ç½® (T4/V100/A100)\n",
    "- ğŸ’¾ LoRA é«˜æ•ˆå¾®èª¿ (ç¯€çœè¨˜æ†¶é«”)\n",
    "- ğŸ¯ FashionCLIP æ™ºèƒ½ç‰¹å¾µæå–\n",
    "- ğŸ“Š å¯¦æ™‚è¨“ç·´ç›£æ§\n",
    "- ğŸ’½ è‡ªå‹• Google Drive åŒæ­¥\n",
    "- ğŸ“¦ ä¸€éµä¸‹è¼‰è¨“ç·´çµæœ\n",
    "\n",
    "### ğŸ”§ ç³»çµ±éœ€æ±‚:\n",
    "- Google Colab Pro (æ¨è–¦ï¼Œä½†å…è²»ç‰ˆä¹Ÿå¯ç”¨)\n",
    "- GPU é‹è¡Œæ™‚ (T4/V100/A100)\n",
    "- ç´„ 2-5GB Google Drive ç©ºé–“"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef1ed38",
   "metadata": {},
   "source": [
    "## ğŸš€ æ­¥é©Ÿ 1: ç’°å¢ƒè¨­ç½®å’Œæª¢æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d308d13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£å¿…è¦å¥—ä»¶\n",
    "!pip install -q diffusers[torch]==0.21.4 transformers==4.35.2\n",
    "!pip install -q accelerate==0.24.1 peft==0.6.2\n",
    "!pip install -q xformers --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q matplotlib seaborn\n",
    "\n",
    "print(\"âœ… å¥—ä»¶å®‰è£å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0ebd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# æª¢æŸ¥ GPU ç‹€æ…‹\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name()\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"ğŸ”§ GPU: {gpu_name}\")\n",
    "    print(f\"ğŸ’¾ VRAM: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    # è‡ªå‹•é…ç½®å»ºè­°\n",
    "    if \"T4\" in gpu_name:\n",
    "        print(\"ğŸ¯ å»ºè­°ä½¿ç”¨ LoRA rank=4, batch_size=1\")\n",
    "    elif \"V100\" in gpu_name:\n",
    "        print(\"ğŸ¯ å»ºè­°ä½¿ç”¨ LoRA rank=8, batch_size=2\")\n",
    "    elif \"A100\" in gpu_name:\n",
    "        print(\"ğŸ¯ å»ºè­°ä½¿ç”¨ LoRA rank=16, batch_size=4\")\n",
    "else:\n",
    "    print(\"âŒ æ²’æœ‰å¯ç”¨çš„ GPUï¼Œè«‹ç¢ºèªé‹è¡Œæ™‚è¨­ç½®\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13417b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ›è¼‰ Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# å‰µå»ºå·¥ä½œç›®éŒ„\n",
    "work_dir = \"/content/drive/MyDrive/fashion_ai_training\"\n",
    "os.makedirs(work_dir, exist_ok=True)\n",
    "os.chdir(work_dir)\n",
    "\n",
    "print(f\"ğŸ“ å·¥ä½œç›®éŒ„: {work_dir}\")\n",
    "print(f\"ğŸ“ ç•¶å‰ä½ç½®: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2920d8a0",
   "metadata": {},
   "source": [
    "## ğŸ“¥ æ­¥é©Ÿ 2: ä¸‹è¼‰ä¸»è¦è¨“ç·´è…³æœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a43d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‰µå»ºä¸»è¦è¨“ç·´è…³æœ¬ (ç›´æ¥åœ¨ Colab ä¸­å®šç¾©)\n",
    "script_content = '''\n",
    "# é€™è£¡æœƒåŒ…å«å®Œæ•´çš„ day3_colab_finetuning.py å…§å®¹\n",
    "# (ç”±æ–¼å…§å®¹éé•·ï¼Œå¯¦éš›ä½¿ç”¨æ™‚å»ºè­°ç›´æ¥é‹è¡Œä¸‹é¢çš„ wget å‘½ä»¤ä¸‹è¼‰)\n",
    "'''\n",
    "\n",
    "# æˆ–è€…å¾ GitHub ä¸‹è¼‰ (å¦‚æœæ‚¨å°‡ä»£ç¢¼ä¸Šå‚³åˆ° GitHub)\n",
    "# !wget -O day3_colab_finetuning.py \"æ‚¨çš„GitHubåŸå§‹æ–‡ä»¶é€£çµ\"\n",
    "\n",
    "# æˆ–è€…ç›´æ¥è²¼ä¸Šå®Œæ•´ä»£ç¢¼\n",
    "with open('day3_colab_finetuning.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(open('/content/day3_colab_finetuning.py').read())\n",
    "\n",
    "print(\"âœ… ä¸»è¦è…³æœ¬å·²æº–å‚™\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370408ff",
   "metadata": {},
   "source": [
    "## ğŸ“¤ æ­¥é©Ÿ 3: ä¸Šå‚³è¨“ç·´åœ–ç‰‡\n",
    "\n",
    "è«‹ä¸Šå‚³æ‚¨è¦ç”¨æ–¼è¨“ç·´çš„æ™‚å°šåœ–ç‰‡ (å»ºè­° 10-50 å¼µ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac52ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "# ä¸Šå‚³åœ–ç‰‡æª”æ¡ˆ\n",
    "print(\"ğŸ“¤ è«‹é¸æ“‡ä¸¦ä¸Šå‚³è¨“ç·´åœ–ç‰‡...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# æ•´ç†ä¸Šå‚³çš„åœ–ç‰‡\n",
    "upload_dir = \"uploaded_images\"\n",
    "os.makedirs(upload_dir, exist_ok=True)\n",
    "\n",
    "image_files = []\n",
    "for filename, content in uploaded.items():\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "        file_path = os.path.join(upload_dir, filename)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(content)\n",
    "        image_files.append(file_path)\n",
    "        print(f\"âœ… {filename}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ç¸½å…±ä¸Šå‚³ {len(image_files)} å¼µåœ–ç‰‡\")\n",
    "\n",
    "if len(image_files) == 0:\n",
    "    print(\"âŒ æ²’æœ‰æœ‰æ•ˆçš„åœ–ç‰‡æª”æ¡ˆï¼Œè«‹é‡æ–°ä¸Šå‚³\")\n",
    "else:\n",
    "    print(\"âœ… åœ–ç‰‡ä¸Šå‚³å®Œæˆï¼Œå¯ä»¥é–‹å§‹è¨“ç·´\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeebedf",
   "metadata": {},
   "source": [
    "## âš¡ æ­¥é©Ÿ 4: å¿«é€Ÿé–‹å§‹è¨“ç·´ (ä¸€éµåŸ·è¡Œ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdcaa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿«é€Ÿè¨“ç·´æ¨¡å¼ - è‡ªå‹•åŒ–åŸ·è¡Œæ‰€æœ‰æ­¥é©Ÿ\n",
    "import sys\n",
    "sys.path.append('/content')\n",
    "\n",
    "from day3_colab_finetuning import FashionSDFineTuner\n",
    "\n",
    "# åˆå§‹åŒ–è¨“ç·´å™¨ (è‡ªå‹•å„ªåŒ–é…ç½®)\n",
    "trainer = FashionSDFineTuner()\n",
    "\n",
    "# ä½¿ç”¨ä¸Šå‚³çš„åœ–ç‰‡\n",
    "if 'image_files' in locals() and image_files:\n",
    "    print(f\"ğŸ–¼ï¸ ä½¿ç”¨ {len(image_files)} å¼µä¸Šå‚³çš„åœ–ç‰‡\")\n",
    "    \n",
    "    # æå–ç‰¹å¾µç”Ÿæˆæè¿°\n",
    "    print(\"\\nğŸ” æ­£åœ¨æå–åœ–ç‰‡ç‰¹å¾µ...\")\n",
    "    captions = trainer.extract_features_from_images(image_files)\n",
    "    \n",
    "    # æº–å‚™æ•¸æ“šé›†\n",
    "    print(\"\\nğŸ“Š æº–å‚™è¨“ç·´æ•¸æ“š...\")\n",
    "    dataloader = trainer.prepare_dataset(image_files, captions)\n",
    "    \n",
    "    # é–‹å§‹è¨“ç·´\n",
    "    print(\"\\nğŸš€ é–‹å§‹å¾®èª¿è¨“ç·´...\")\n",
    "    print(\"â° é è¨ˆè¨“ç·´æ™‚é–“: 30-60 åˆ†é˜ (å–æ±ºæ–¼ GPU å’Œåœ–ç‰‡æ•¸é‡)\")\n",
    "    \n",
    "    trainer.train(dataloader)\n",
    "    \n",
    "    print(\"\\nğŸ‰ è¨“ç·´å®Œæˆï¼\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ è«‹å…ˆä¸Šå‚³è¨“ç·´åœ–ç‰‡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721351c0",
   "metadata": {},
   "source": [
    "## ğŸ”§ æ­¥é©Ÿ 5: é€²éšé…ç½® (å¯é¸)\n",
    "\n",
    "å¦‚æœæ‚¨æƒ³è‡ªå®šç¾©è¨“ç·´åƒæ•¸ï¼Œå¯ä»¥ä½¿ç”¨é€™å€‹éƒ¨åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae455d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è‡ªå®šç¾©è¨“ç·´é…ç½®\n",
    "custom_config = {\n",
    "    \"num_epochs\": 30,           # è¨“ç·´è¼ªæ•¸\n",
    "    \"learning_rate\": 1e-4,      # å­¸ç¿’ç‡\n",
    "    \"lora_rank\": 8,             # LoRA rank (è¶Šé«˜è¶Šè©³ç´°ä½†éœ€æ›´å¤šè¨˜æ†¶é«”)\n",
    "    \"train_batch_size\": 1,      # æ‰¹æ¬¡å¤§å°\n",
    "    \"gradient_accumulation_steps\": 4,  # æ¢¯åº¦ç´¯ç©\n",
    "    \"save_steps\": 50,           # ä¿å­˜é »ç‡\n",
    "    \"validation_steps\": 25      # é©—è­‰é »ç‡\n",
    "}\n",
    "\n",
    "print(\"âš™ï¸ è‡ªå®šç¾©é…ç½®:\")\n",
    "for key, value in custom_config.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "# ä½¿ç”¨è‡ªå®šç¾©é…ç½®åˆå§‹åŒ–è¨“ç·´å™¨\n",
    "# trainer_custom = FashionSDFineTuner(config=custom_config)\n",
    "print(\"\\nğŸ’¡ å¦‚éœ€ä½¿ç”¨è‡ªå®šç¾©é…ç½®ï¼Œè«‹å–æ¶ˆè¨»é‡‹ä¸Šé¢çš„ä»£ç¢¼è¡Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5678e9",
   "metadata": {},
   "source": [
    "## ğŸ“Š æ­¥é©Ÿ 6: è¨“ç·´ç›£æ§\n",
    "\n",
    "æª¢æŸ¥è¨“ç·´é€²åº¦å’Œçµæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fc9a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æª¢æŸ¥è¨“ç·´çµæœ\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "# é¡¯ç¤ºè¨“ç·´é€²åº¦åœ–è¡¨\n",
    "if os.path.exists(\"models/training_progress.png\"):\n",
    "    img = Image.open(\"models/training_progress.png\")\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Training Progress\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"ğŸ“Š è¨“ç·´åœ–è¡¨å°šæœªç”Ÿæˆ\")\n",
    "\n",
    "# é¡¯ç¤ºé©—è­‰åœ–ç‰‡\n",
    "validation_images = glob.glob(\"models/validation/*.png\")\n",
    "if validation_images:\n",
    "    print(f\"ğŸ–¼ï¸ æ‰¾åˆ° {len(validation_images)} å¼µé©—è­‰åœ–ç‰‡\")\n",
    "    \n",
    "    # é¡¯ç¤ºæœ€æ–°çš„å¹¾å¼µ\n",
    "    latest_images = sorted(validation_images)[-6:]  # æœ€æ–° 6 å¼µ\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, img_path in enumerate(latest_images):\n",
    "        if i < 6:\n",
    "            img = Image.open(img_path)\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(os.path.basename(img_path))\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"ğŸ–¼ï¸ é©—è­‰åœ–ç‰‡å°šæœªç”Ÿæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d8e244",
   "metadata": {},
   "source": [
    "## ğŸ¨ æ­¥é©Ÿ 7: æ¸¬è©¦è¨“ç·´å¥½çš„æ¨¡å‹\n",
    "\n",
    "ä½¿ç”¨è¨“ç·´å¥½çš„æ¨¡å‹ç”Ÿæˆæ–°çš„æ™‚å°šåœ–ç‰‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83179a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline, DDPMScheduler\n",
    "from peft import PeftModel\n",
    "\n",
    "# è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹\n",
    "def load_trained_model():\n",
    "    try:\n",
    "        # è¼‰å…¥åŸºç¤æ¨¡å‹\n",
    "        pipeline = StableDiffusionPipeline.from_pretrained(\n",
    "            \"runwayml/stable-diffusion-v1-5\",\n",
    "            torch_dtype=torch.float16,\n",
    "            safety_checker=None,\n",
    "            requires_safety_checker=False\n",
    "        )\n",
    "        \n",
    "        # è¼‰å…¥ LoRA æ¬Šé‡\n",
    "        if os.path.exists(\"models/final_model\"):\n",
    "            pipeline.unet = PeftModel.from_pretrained(\n",
    "                pipeline.unet, \n",
    "                \"models/final_model\"\n",
    "            )\n",
    "            print(\"âœ… LoRA æ¬Šé‡è¼‰å…¥æˆåŠŸ\")\n",
    "        else:\n",
    "            print(\"âš ï¸ æ‰¾ä¸åˆ°è¨“ç·´å¥½çš„æ¨¡å‹ï¼Œä½¿ç”¨åŸå§‹æ¨¡å‹\")\n",
    "        \n",
    "        pipeline = pipeline.to(\"cuda\")\n",
    "        return pipeline\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}\")\n",
    "        return None\n",
    "\n",
    "# è¼‰å…¥æ¨¡å‹\n",
    "pipeline = load_trained_model()\n",
    "\n",
    "if pipeline:\n",
    "    # æ¸¬è©¦æç¤ºè©\n",
    "    test_prompts = [\n",
    "        \"a woman wearing an elegant black dress\",\n",
    "        \"a man in casual blue shirt and jeans\",\n",
    "        \"person in formal business suit\",\n",
    "        \"stylish outfit with modern fashion\"\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ¨ ç”Ÿæˆæ¸¬è©¦åœ–ç‰‡...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, prompt in enumerate(test_prompts):\n",
    "        print(f\"   ç”Ÿæˆ: {prompt}\")\n",
    "        \n",
    "        image = pipeline(\n",
    "            prompt,\n",
    "            num_inference_steps=20,\n",
    "            guidance_scale=7.5,\n",
    "            width=512,\n",
    "            height=512\n",
    "        ).images[0]\n",
    "        \n",
    "        axes[i].imshow(image)\n",
    "        axes[i].set_title(prompt[:30] + \"...\" if len(prompt) > 30 else prompt)\n",
    "        axes[i].axis('off')\n",
    "        \n",
    "        # ä¿å­˜åœ–ç‰‡\n",
    "        os.makedirs(\"generated_tests\", exist_ok=True)\n",
    "        image.save(f\"generated_tests/test_{i+1}.png\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ… æ¸¬è©¦åœ–ç‰‡ç”Ÿæˆå®Œæˆ\")\n",
    "else:\n",
    "    print(\"âŒ ç„¡æ³•è¼‰å…¥æ¨¡å‹é€²è¡Œæ¸¬è©¦\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a151257a",
   "metadata": {},
   "source": [
    "## ğŸ“¦ æ­¥é©Ÿ 8: ä¸‹è¼‰è¨“ç·´çµæœ\n",
    "\n",
    "æ‰“åŒ…ä¸¦ä¸‹è¼‰æ‰€æœ‰è¨“ç·´çµæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e763165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "# å‰µå»ºä¸‹è¼‰åŒ…\n",
    "def create_download_package():\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    package_name = f\"fashion_ai_model_{timestamp}.zip\"\n",
    "    \n",
    "    print(f\"ğŸ“¦ å‰µå»ºä¸‹è¼‰åŒ…: {package_name}\")\n",
    "    \n",
    "    with zipfile.ZipFile(package_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        # æ¨¡å‹æª”æ¡ˆ\n",
    "        if os.path.exists(\"models/final_model\"):\n",
    "            for root, dirs, files in os.walk(\"models/final_model\"):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    arcname = os.path.relpath(file_path, \"models\")\n",
    "                    zipf.write(file_path, f\"model/{arcname}\")\n",
    "            print(\"   âœ… æ¨¡å‹æª”æ¡ˆå·²æ·»åŠ \")\n",
    "        \n",
    "        # è¨“ç·´åœ–è¡¨\n",
    "        if os.path.exists(\"models/training_progress.png\"):\n",
    "            zipf.write(\"models/training_progress.png\", \"training_progress.png\")\n",
    "            print(\"   âœ… è¨“ç·´åœ–è¡¨å·²æ·»åŠ \")\n",
    "        \n",
    "        # é©—è­‰åœ–ç‰‡\n",
    "        validation_dir = \"models/validation\"\n",
    "        if os.path.exists(validation_dir):\n",
    "            for file in os.listdir(validation_dir):\n",
    "                file_path = os.path.join(validation_dir, file)\n",
    "                zipf.write(file_path, f\"validation/{file}\")\n",
    "            print(\"   âœ… é©—è­‰åœ–ç‰‡å·²æ·»åŠ \")\n",
    "        \n",
    "        # æ¸¬è©¦ç”Ÿæˆåœ–ç‰‡\n",
    "        if os.path.exists(\"generated_tests\"):\n",
    "            for file in os.listdir(\"generated_tests\"):\n",
    "                file_path = os.path.join(\"generated_tests\", file)\n",
    "                zipf.write(file_path, f\"test_generations/{file}\")\n",
    "            print(\"   âœ… æ¸¬è©¦åœ–ç‰‡å·²æ·»åŠ \")\n",
    "        \n",
    "        # ä½¿ç”¨èªªæ˜\n",
    "        readme_content = f\"\"\"\n",
    "# Fashion AI è¨“ç·´çµæœ\n",
    "\n",
    "è¨“ç·´æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "GPU: {torch.cuda.get_device_name() if torch.cuda.is_available() else 'CPU'}\n",
    "\n",
    "## æª”æ¡ˆèªªæ˜:\n",
    "- model/ : LoRA æ¬Šé‡æª”æ¡ˆ\n",
    "- validation/ : è¨“ç·´éç¨‹ä¸­çš„é©—è­‰åœ–ç‰‡\n",
    "- test_generations/ : æœ€çµ‚æ¸¬è©¦ç”Ÿæˆçš„åœ–ç‰‡\n",
    "- training_progress.png : è¨“ç·´æå¤±æ›²ç·š\n",
    "\n",
    "## ä½¿ç”¨æ–¹æ³•:\n",
    "1. å®‰è£ diffusers, transformers, peft\n",
    "2. è¼‰å…¥åŸºç¤ SD v1.5 æ¨¡å‹\n",
    "3. ä½¿ç”¨ PeftModel.from_pretrained() è¼‰å…¥ LoRA æ¬Šé‡\n",
    "4. å³å¯é–‹å§‹ç”Ÿæˆæ™‚å°šåœ–ç‰‡\n",
    "\"\"\"\n",
    "        \n",
    "        zipf.writestr(\"README.md\", readme_content)\n",
    "        print(\"   âœ… èªªæ˜æ–‡ä»¶å·²æ·»åŠ \")\n",
    "    \n",
    "    return package_name\n",
    "\n",
    "# å‰µå»ºä¸¦ä¸‹è¼‰\n",
    "package_name = create_download_package()\n",
    "print(f\"\\nğŸ“¦ æ‰“åŒ…å®Œæˆ: {package_name}\")\n",
    "\n",
    "# ä¸‹è¼‰æª”æ¡ˆ\n",
    "files.download(package_name)\n",
    "print(\"âœ… ä¸‹è¼‰é–‹å§‹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31765ecf",
   "metadata": {},
   "source": [
    "## ğŸ§¹ æ­¥é©Ÿ 9: æ¸…ç† (å¯é¸)\n",
    "\n",
    "æ¸…ç†æš«å­˜æª”æ¡ˆä»¥ç¯€çœ Google Drive ç©ºé–“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4622dce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# è©¢å•æ˜¯å¦æ¸…ç†\n",
    "cleanup = input(\"æ˜¯å¦æ¸…ç†æš«å­˜æª”æ¡ˆä»¥ç¯€çœç©ºé–“? (y/N): \").lower().strip()\n",
    "\n",
    "if cleanup == 'y' or cleanup == 'yes':\n",
    "    print(\"ğŸ§¹ æ¸…ç†ä¸­...\")\n",
    "    \n",
    "    # æ¸…ç†é …ç›®\n",
    "    cleanup_items = [\n",
    "        \"uploaded_images\",  # åŸå§‹ä¸Šå‚³åœ–ç‰‡\n",
    "        \"/content/cache\",   # æ¨¡å‹å¿«å–\n",
    "        \"models/checkpoint-*\",  # ä¸­é–“æª¢æŸ¥é»\n",
    "    ]\n",
    "    \n",
    "    for item in cleanup_items:\n",
    "        if os.path.exists(item):\n",
    "            if os.path.isdir(item):\n",
    "                shutil.rmtree(item)\n",
    "                print(f\"   ğŸ—‘ï¸ å·²åˆªé™¤ç›®éŒ„: {item}\")\n",
    "            else:\n",
    "                os.remove(item)\n",
    "                print(f\"   ğŸ—‘ï¸ å·²åˆªé™¤æª”æ¡ˆ: {item}\")\n",
    "    \n",
    "    # æ¸…ç† GPU è¨˜æ†¶é«”\n",
    "    if 'pipeline' in locals():\n",
    "        del pipeline\n",
    "    if 'trainer' in locals():\n",
    "        del trainer\n",
    "    \n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"âœ… æ¸…ç†å®Œæˆ\")\n",
    "else:\n",
    "    print(\"ğŸ—‚ï¸ ä¿ç•™æ‰€æœ‰æª”æ¡ˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e3cbf5",
   "metadata": {},
   "source": [
    "## ğŸ‰ ç¸½çµ\n",
    "\n",
    "æ­å–œï¼æ‚¨å·²ç¶“æˆåŠŸå®Œæˆäº† Stable Diffusion v1.5 çš„æ™‚å°šå¾®èª¿è¨“ç·´ã€‚\n",
    "\n",
    "### âœ… å®Œæˆçš„å·¥ä½œ:\n",
    "1. ğŸ”§ è‡ªå‹•é…ç½® Colab ç’°å¢ƒ\n",
    "2. ğŸ“¤ ä¸Šå‚³ä¸¦è™•ç†è¨“ç·´åœ–ç‰‡\n",
    "3. ğŸ¯ ä½¿ç”¨ FashionCLIP æå–ç‰¹å¾µ\n",
    "4. ğŸš€ åŸ·è¡Œ LoRA å¾®èª¿è¨“ç·´\n",
    "5. ğŸ“Š ç›£æ§è¨“ç·´é€²åº¦\n",
    "6. ğŸ¨ æ¸¬è©¦ç”Ÿæˆæ•ˆæœ\n",
    "7. ğŸ“¦ ä¸‹è¼‰å®Œæ•´çµæœ\n",
    "\n",
    "### ğŸ’¡ å¾ŒçºŒä½¿ç”¨:\n",
    "- ä¸‹è¼‰çš„æ¨¡å‹å¯ä»¥åœ¨æœ¬åœ°ä½¿ç”¨\n",
    "- æ”¯æ´å„ç¨® Stable Diffusion ç•Œé¢\n",
    "- å¯ä»¥é€²ä¸€æ­¥å¾®èª¿æˆ–èˆ‡å…¶ä»– LoRA åˆä½µ\n",
    "\n",
    "### ğŸ†˜ å¦‚æœé‡åˆ°å•é¡Œ:\n",
    "1. æª¢æŸ¥ GPU è¨˜æ†¶é«”æ˜¯å¦è¶³å¤ \n",
    "2. ç¢ºèªæ‰€æœ‰å¥—ä»¶ç‰ˆæœ¬ç›¸å®¹\n",
    "3. é‡æ–°å•Ÿå‹•é‹è¡Œæ™‚ä¸¦é‡æ–°åŸ·è¡Œ\n",
    "4. èª¿æ•´æ‰¹æ¬¡å¤§å°æˆ– LoRA rank\n",
    "\n",
    "æ„Ÿè¬ä½¿ç”¨ Fashion AI Training Suite! ğŸ¨âœ¨"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
