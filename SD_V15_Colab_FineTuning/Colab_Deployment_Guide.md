# Google Colab å¿«é€Ÿéƒ¨ç½²æŒ‡å—

## ğŸš€ ä¸€éµéƒ¨ç½²åˆ° Colab

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ä½ çš„ç”¨æˆ¶å/ä½ çš„å€‰åº«/blob/main/Day3_Fashion_AI_Colab.ipynb)

## ğŸ“‹ éƒ¨ç½²æ­¥é©Ÿ

### 1. æº–å‚™å·¥ä½œ
1. ç¢ºä¿æœ‰ Google å¸³è™Ÿ
2. é–‹å•Ÿ Google Colab (colab.research.google.com)
3. æº–å‚™ 10-50 å¼µæ™‚å°šåœ–ç‰‡ (JPG/PNG æ ¼å¼)

### 2. ä¸Šå‚³ Notebook
æœ‰ä¸‰ç¨®æ–¹å¼ä¸Šå‚³æˆ‘å€‘çš„ Notebookï¼š

#### æ–¹å¼ A: ç›´æ¥ä¸Šå‚³æª”æ¡ˆ
1. ä¸‹è¼‰ `Day3_Fashion_AI_Colab.ipynb`
2. åœ¨ Colab ä¸­é¸æ“‡ã€Œæª”æ¡ˆã€â†’ã€Œä¸Šå‚³ç­†è¨˜æœ¬ã€
3. é¸æ“‡ä¸‹è¼‰çš„ `.ipynb` æª”æ¡ˆ

#### æ–¹å¼ B: å¾ GitHub è¼‰å…¥ (æ¨è–¦)
1. å°‡ä»£ç¢¼ä¸Šå‚³åˆ°æ‚¨çš„ GitHub å€‰åº«
2. åœ¨ Colab ä¸­é¸æ“‡ã€Œæª”æ¡ˆã€â†’ã€Œåœ¨ GitHub ä¸­é–‹å•Ÿã€
3. è¼¸å…¥å€‰åº« URL

#### æ–¹å¼ C: å¾ Google Drive è¼‰å…¥
1. å°‡ `.ipynb` æª”æ¡ˆä¸Šå‚³åˆ° Google Drive
2. åœ¨ Colab ä¸­é¸æ“‡ã€Œæª”æ¡ˆã€â†’ã€Œåœ¨ Drive ä¸­é–‹å•Ÿã€

### 3. è¨­ç½® GPU é‹è¡Œæ™‚
1. åœ¨ Colab ä¸­é»æ“Šã€ŒåŸ·è¡Œéšæ®µã€â†’ã€Œè®Šæ›´åŸ·è¡Œéšæ®µé¡å‹ã€
2. ã€Œç¡¬é«”åŠ é€Ÿå™¨ã€é¸æ“‡ã€ŒGPUã€
3. å»ºè­°é¸æ“‡ã€Œé«˜ RAMã€(å¦‚æœæœ‰ Colab Pro)

### 4. åŸ·è¡Œè¨“ç·´
æŒ‰ç…§ Notebook ä¸­çš„æ­¥é©Ÿé †åºåŸ·è¡Œï¼š
1. å®‰è£ä¾è³´å¥—ä»¶
2. æª¢æŸ¥ GPU ç‹€æ…‹
3. æ›è¼‰ Google Drive
4. ä¸Šå‚³è¨“ç·´åœ–ç‰‡
5. é–‹å§‹è‡ªå‹•è¨“ç·´
6. ä¸‹è¼‰çµæœ

## âš™ï¸ é…ç½®é¸é …

### GPU é¡å‹å„ªåŒ–
| GPU é¡å‹ | VRAM | å»ºè­°é…ç½® |
|----------|------|----------|
| T4 | 16GB | LoRA rank=4, batch_size=1 |
| V100 | 16GB | LoRA rank=8, batch_size=2 |
| A100 | 40GB | LoRA rank=16, batch_size=4 |

### è¨“ç·´åƒæ•¸èª¿æ•´
```python
# åœ¨ Notebook ä¸­å¯ä»¥èª¿æ•´é€™äº›åƒæ•¸
config = {
    "num_epochs": 20,        # è¨“ç·´è¼ªæ•¸ (10-50)
    "learning_rate": 1e-4,   # å­¸ç¿’ç‡
    "lora_rank": 8,          # LoRA è¤‡é›œåº¦ (4-16)
    "batch_size": 1,         # æ‰¹æ¬¡å¤§å°
    "save_steps": 50         # ä¿å­˜é »ç‡
}
```

## ğŸ“Š é æœŸçµæœ

### è¨“ç·´æ™‚é–“
- **T4 GPU**: ç´„ 30-60 åˆ†é˜ (20 epochs, 20 å¼µåœ–ç‰‡)
- **V100 GPU**: ç´„ 20-40 åˆ†é˜
- **A100 GPU**: ç´„ 10-20 åˆ†é˜

### è¼¸å‡ºæª”æ¡ˆ
è¨“ç·´å®Œæˆå¾Œæœƒè‡ªå‹•æ‰“åŒ…ä¸‹è¼‰ï¼š
```
fashion_ai_model_YYYYMMDD_HHMMSS.zip
â”œâ”€â”€ model/                    # LoRA æ¬Šé‡æª”æ¡ˆ
â”œâ”€â”€ validation/               # é©—è­‰åœ–ç‰‡
â”œâ”€â”€ test_generations/         # æ¸¬è©¦ç”Ÿæˆåœ–ç‰‡
â”œâ”€â”€ training_progress.png     # è¨“ç·´æ›²ç·š
â””â”€â”€ README.md                # ä½¿ç”¨èªªæ˜
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

#### 1. è¨˜æ†¶é«”ä¸è¶³ (CUDA OOM)
```python
# è§£æ±ºæ–¹æ¡ˆï¼šæ¸›å°‘æ‰¹æ¬¡å¤§å°å’Œ LoRA rank
config = {
    "train_batch_size": 1,
    "gradient_accumulation_steps": 8,
    "lora_rank": 4
}
```

#### 2. å¥—ä»¶å®‰è£å¤±æ•—
```bash
# åœ¨ Colab ä¸­åŸ·è¡Œ
!pip install --upgrade pip
!pip install -q diffusers==0.21.4 transformers==4.35.2
```

#### 3. æ¨¡å‹ä¸‹è¼‰å¤±æ•—
```python
# è¨­ç½®é›¢ç·šæ¨¡å¼æˆ–ä½¿ç”¨é¡åƒ
import os
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
```

#### 4. Google Drive æ›è¼‰å¤±æ•—
```python
# é‡æ–°åŸ·è¡Œæ›è¼‰
from google.colab import drive
drive.mount('/content/drive', force_remount=True)
```

### æ•ˆèƒ½å„ªåŒ–å»ºè­°

#### 1. åœ–ç‰‡é è™•ç†
- å»ºè­°åœ–ç‰‡å°ºå¯¸ï¼š512x512 æˆ– 768x768
- æª”æ¡ˆæ ¼å¼ï¼šJPG (è¼ƒå°) æˆ– PNG (é«˜å“è³ª)
- æ•¸é‡ï¼š20-50 å¼µ (å“è³ªæ¯”æ•¸é‡é‡è¦)

#### 2. è¨“ç·´å„ªåŒ–
```python
# å•Ÿç”¨æ··åˆç²¾åº¦å’Œ xformers (å¦‚æœå¯ç”¨)
config = {
    "mixed_precision": "fp16",
    "use_xformers": True,
    "gradient_checkpointing": True
}
```

#### 3. è¨˜æ†¶é«”ç®¡ç†
```python
# å®šæœŸæ¸…ç†è¨˜æ†¶é«”
import gc
gc.collect()
torch.cuda.empty_cache()
```

## ğŸ’¡ é€²éšä½¿ç”¨

### 1. å¤šæ¨£æœ¬æ¸¬è©¦
```python
# åœ¨è¨“ç·´å®Œæˆå¾Œæ¸¬è©¦ä¸åŒæç¤ºè©
test_prompts = [
    "elegant woman in evening dress",
    "casual man in street fashion",
    "business professional outfit",
    "vintage style clothing"
]
```

### 2. èˆ‡å…¶ä»– LoRA åˆä½µ
```python
# å¯ä»¥å°‡è¨“ç·´å¥½çš„ LoRA èˆ‡å…¶ä»– LoRA åˆä½µä½¿ç”¨
from peft import PeftModel

# è¼‰å…¥å¤šå€‹ LoRA
model = base_model
model = PeftModel.from_pretrained(model, "fashion_lora")
model = PeftModel.from_pretrained(model, "style_lora")
```

### 3. æ‰¹æ¬¡ç”Ÿæˆ
```python
# æ‰¹æ¬¡ç”Ÿæˆå¤šå¼µåœ–ç‰‡é€²è¡Œæ¯”è¼ƒ
for i in range(5):
    image = pipeline(prompt, seed=i).images[0]
    image.save(f"generated_{i}.png")
```

## ğŸ“š é¡å¤–è³‡æº

### å­¸ç¿’è³‡æ–™
- [Diffusers æ–‡æª”](https://huggingface.co/docs/diffusers)
- [LoRA è«–æ–‡](https://arxiv.org/abs/2106.09685)
- [Stable Diffusion åŸç†](https://arxiv.org/abs/2112.10752)

### ç¤¾ç¾¤å’Œæ”¯æ´
- [Hugging Face è«–å£‡](https://discuss.huggingface.co/)
- [r/MachineLearning](https://www.reddit.com/r/MachineLearning/)
- [Discord AI ç¤¾ç¾¤](https://discord.gg/hugging-face)

## ğŸ¯ æˆåŠŸæ¡ˆä¾‹

### å…¸å‹è¨“ç·´æ•ˆæœ
ç¶“é 20-30 epochs çš„è¨“ç·´ï¼Œæ‚¨å¯ä»¥æœŸæœ›ï¼š
- ğŸ¨ ç”Ÿæˆç¬¦åˆæ‚¨è¨“ç·´æ•¸æ“šé¢¨æ ¼çš„æ™‚å°šåœ–ç‰‡
- ğŸ‘” æ›´å¥½çš„æœè£ç´°ç¯€å’Œè³ªæ„Ÿ
- ğŸ­ ä¿æŒäººç‰©å§¿æ…‹çš„è‡ªç„¶æ€§
- ğŸŒˆ æ”¹å–„è‰²å½©æ­é…å’Œæ•´é«”ç¾æ„Ÿ

### æœ€ä½³å¯¦è¸
1. **åœ–ç‰‡æº–å‚™**: é¸æ“‡é«˜å“è³ªã€å¤šæ¨£åŒ–çš„æ™‚å°šåœ–ç‰‡
2. **åƒæ•¸èª¿æ•´**: æ ¹æ“š GPU é¡å‹èª¿æ•´é…ç½®
3. **ç›£æ§è¨“ç·´**: è§€å¯Ÿæå¤±æ›²ç·šï¼Œé©æ™‚èª¿æ•´
4. **æ¸¬è©¦é©—è­‰**: ä½¿ç”¨å¤šæ¨£åŒ–çš„æç¤ºè©æ¸¬è©¦æ•ˆæœ

---

**æ³¨æ„**: é€™å€‹ Colab ç‰ˆæœ¬å°ˆç‚ºè§£æ±ºæœ¬åœ° GPU è¨˜æ†¶é«”ä¸è¶³çš„å•é¡Œè€Œè¨­è¨ˆã€‚å³ä½¿æ‚¨çš„ç­†é›»åªæœ‰ 4GB VRAMï¼Œä¹Ÿå¯ä»¥åœ¨ Colab çš„ T4 GPU (16GB) ä¸Šé †åˆ©å®Œæˆè¨“ç·´ï¼
