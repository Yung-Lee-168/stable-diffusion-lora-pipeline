#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Day 3: Compatible Real Fine-tuning Pipeline
ç›¸å®¹æ€§æ›´å¼·çš„ SD v1.5 å¾®èª¿è¨“ç·´æµç¨‹

ğŸ¯ ç‰¹æ€§ï¼š
- è™•ç†ç‰ˆæœ¬ç›¸å®¹æ€§å•é¡Œ
- å„ªé›…é™ç´šåˆ°å¯ç”¨åŠŸèƒ½
- è©³ç´°éŒ¯èª¤å ±å‘Šå’Œå»ºè­°
"""

import os
import json
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
from PIL import Image
from datetime import datetime
import logging
from tqdm import tqdm
import cv2
from sklearn.metrics.pairwise import cosine_similarity
import warnings
warnings.filterwarnings("ignore")

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class CompatibilityChecker:
    """ç›¸å®¹æ€§æª¢æŸ¥å™¨"""
    
    @staticmethod
    def check_transformers():
        """æª¢æŸ¥ transformers ç‰ˆæœ¬"""
        try:
            from transformers import CLIPModel, CLIPProcessor
            return True, "Transformers å¯ç”¨"
        except ImportError as e:
            return False, f"Transformers å°å…¥å¤±æ•—: {e}"
    
    @staticmethod
    def check_diffusers():
        """æª¢æŸ¥ diffusers ç‰ˆæœ¬"""
        try:
            from diffusers import StableDiffusionPipeline
            return True, "Diffusers å¯ç”¨"
        except ImportError as e:
            return False, f"Diffusers å°å…¥å¤±æ•—: {e}"
    
    @staticmethod
    def check_advanced_features():
        """æª¢æŸ¥é«˜ç´šåŠŸèƒ½"""
        results = {}
        
        # æª¢æŸ¥ LoRA
        try:
            from diffusers.loaders import AttnProcsLayers
            from diffusers.models.attention_processor import LoRAAttnProcessor
            results['lora'] = True
        except ImportError:
            results['lora'] = False
        
        # æª¢æŸ¥æ··åˆç²¾åº¦
        try:
            import torch
            results['mixed_precision'] = torch.cuda.is_available()
        except:
            results['mixed_precision'] = False
        
        # æª¢æŸ¥åŠ é€Ÿ
        try:
            import accelerate
            results['accelerate'] = True
        except ImportError:
            results['accelerate'] = False
        
        return results

class FashionDataset(Dataset):
    """ç°¡åŒ–çš„æ™‚å°šæ•¸æ“šé›†"""
    
    def __init__(self, image_paths, captions, size=512):
        self.image_paths = image_paths
        self.captions = captions
        self.size = size
        
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        # è¼‰å…¥åœ–ç‰‡
        image = Image.open(self.image_paths[idx]).convert("RGB")
        image = image.resize((self.size, self.size), Image.LANCZOS)
        image = np.array(image).astype(np.float32) / 255.0
        image = (image - 0.5) / 0.5  # æ­£è¦åŒ–åˆ° [-1, 1]
        image = torch.from_numpy(image).permute(2, 0, 1)
        
        return {
            "images": image,
            "captions": self.captions[idx]
        }

class CompatibleFashionFineTuner:
    """ç›¸å®¹æ€§å‹å¥½çš„ SD å¾®èª¿å™¨"""
    
    def __init__(self, model_id="runwayml/stable-diffusion-v1-5"):
        """åˆå§‹åŒ–å¾®èª¿å™¨"""
        print("ğŸš€ åˆå§‹åŒ–ç›¸å®¹æ€§ Fashion Fine-tuner...")
        
        self.model_id = model_id
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ“± ä½¿ç”¨è¨­å‚™: {self.device}")
        
        # æª¢æŸ¥ç›¸å®¹æ€§
        self.compatibility = self._check_compatibility()
        
        # è¨­å®šç›®éŒ„
        self.source_dir = "day1_results"
        self.output_dir = "day3_compatible_finetuning_results"
        self.checkpoint_dir = os.path.join(self.output_dir, "checkpoints")
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(self.checkpoint_dir, exist_ok=True)
        
        # ç°¡åŒ–çš„è¨“ç·´é…ç½®
        self.config = {
            "learning_rate": 1e-4,
            "batch_size": 1,
            "num_epochs": 10,  # æ¸›å°‘ä»¥é©æ‡‰ç›¸å®¹æ€§å•é¡Œ
            "save_steps": 5,
            "validation_steps": 3,
            "max_grad_norm": 1.0,
            "image_size": 512,
            "use_lora": self.compatibility['features']['lora'],
            "mixed_precision": self.compatibility['features']['mixed_precision']
        }
        
        # åˆå§‹åŒ–å¯ç”¨çš„æ¨¡å‹çµ„ä»¶
        self._init_available_models()
        
    def _check_compatibility(self):
        """æª¢æŸ¥ç³»çµ±ç›¸å®¹æ€§"""
        print("ğŸ” æª¢æŸ¥ç³»çµ±ç›¸å®¹æ€§...")
        
        compatibility = {
            "transformers": CompatibilityChecker.check_transformers(),
            "diffusers": CompatibilityChecker.check_diffusers(),
            "features": CompatibilityChecker.check_advanced_features()
        }
        
        print("ğŸ“Š ç›¸å®¹æ€§æª¢æŸ¥çµæœ:")
        for component, (available, message) in compatibility.items():
            if component == "features":
                continue
            status = "âœ…" if available else "âŒ"
            print(f"   {status} {component}: {message}")
        
        print("ğŸ”§ å¯ç”¨åŠŸèƒ½:")
        for feature, available in compatibility["features"].items():
            status = "âœ…" if available else "âŒ"
            print(f"   {status} {feature}")
        
        return compatibility
    
    def _init_available_models(self):
        """åˆå§‹åŒ–å¯ç”¨çš„æ¨¡å‹çµ„ä»¶"""
        print("ğŸ”§ åˆå§‹åŒ–å¯ç”¨æ¨¡å‹çµ„ä»¶...")
        
        # åˆå§‹åŒ– FashionCLIP
        if self.compatibility["transformers"][0]:
            try:
                from transformers import CLIPModel, CLIPProcessor
                
                self.fashion_clip_model = CLIPModel.from_pretrained(
                    "patrickjohncyh/fashion-clip",
                    torch_dtype=torch.float32
                ).to(self.device)
                
                self.fashion_clip_processor = CLIPProcessor.from_pretrained(
                    "patrickjohncyh/fashion-clip"
                )
                
                self.fashion_clip_model.eval()
                print("âœ… FashionCLIP åˆå§‹åŒ–æˆåŠŸ")
                
            except Exception as e:
                print(f"âŒ FashionCLIP åˆå§‹åŒ–å¤±æ•—: {e}")
                self.fashion_clip_model = None
                self.fashion_clip_processor = None
        else:
            print("âŒ Transformers ä¸å¯ç”¨ï¼Œè·³é FashionCLIP")
            self.fashion_clip_model = None
            self.fashion_clip_processor = None
        
        # åˆå§‹åŒ– Stable Diffusionï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.compatibility["diffusers"][0]:
            try:
                self._init_stable_diffusion()
            except Exception as e:
                print(f"âŒ Stable Diffusion åˆå§‹åŒ–å¤±æ•—: {e}")
                self.pipeline = None
        else:
            print("âŒ Diffusers ä¸å¯ç”¨ï¼Œè·³é SD åˆå§‹åŒ–")
            self.pipeline = None
    
    def _init_stable_diffusion(self):
        """åˆå§‹åŒ– Stable Diffusionï¼ˆç›¸å®¹æ€§ç‰ˆæœ¬ï¼‰"""
        print("ğŸ“¡ è¼‰å…¥ Stable Diffusion...")
        
        try:
            # å˜—è©¦ä½¿ç”¨æ–°ç‰ˆæœ¬çš„ diffusers
            from diffusers import StableDiffusionPipeline
            
            self.pipeline = StableDiffusionPipeline.from_pretrained(
                self.model_id,
                torch_dtype=torch.float16 if self.device.type == "cuda" else torch.float32,
                safety_checker=None,
                requires_safety_checker=False
            ).to(self.device)
            
            print("âœ… Stable Diffusion è¼‰å…¥æˆåŠŸ (æ–°ç‰ˆæœ¬)")
            
        except Exception as e:
            print(f"âš ï¸  æ–°ç‰ˆæœ¬è¼‰å…¥å¤±æ•—ï¼Œå˜—è©¦ç›¸å®¹æ€§æ¨¡å¼: {e}")
            
            # å˜—è©¦åŸºæœ¬è¼‰å…¥
            try:
                from diffusers import StableDiffusionPipeline
                
                # ç°¡åŒ–è¼‰å…¥é¸é …
                self.pipeline = StableDiffusionPipeline.from_pretrained(
                    self.model_id,
                    torch_dtype=torch.float32  # ä½¿ç”¨ float32 æé«˜ç›¸å®¹æ€§
                ).to(self.device)
                
                print("âœ… Stable Diffusion è¼‰å…¥æˆåŠŸ (ç›¸å®¹æ€§æ¨¡å¼)")
                
            except Exception as e2:
                print(f"âŒ æ‰€æœ‰è¼‰å…¥æ–¹å¼éƒ½å¤±æ•—: {e2}")
                raise e2
    
    def generate_fashion_caption(self, image_path):
        """åŸºæ–¼åŸºæœ¬åˆ†æç”Ÿæˆæ™‚å°šæè¿°"""
        # ç°¡åŒ–çš„æ¨™è¨»ç”Ÿæˆï¼ˆä¸ä¾è³´è¤‡é›œæ¨¡å‹ï¼‰
        captions = [
            "fashionable outfit with elegant styling",
            "trendy clothing with modern design", 
            "stylish fashion piece with contemporary look",
            "sophisticated attire with refined details",
            "casual fashion with comfortable fit",
            "formal wear with professional appearance"
        ]
        
        # å¯ä»¥æ ¹æ“šåœ–ç‰‡æª”åæˆ–å…¶ä»–ç°¡å–®ç‰¹å¾µé¸æ“‡
        import random
        return random.choice(captions)
    
    def prepare_dataset(self):
        """æº–å‚™ç°¡åŒ–çš„è¨“ç·´æ•¸æ“šé›†"""
        print("ğŸ“ æº–å‚™è¨“ç·´æ•¸æ“šé›†...")
        
        # æœå°‹åœ–ç‰‡æ–‡ä»¶
        image_files = []
        for ext in ['.jpg', '.jpeg', '.png', '.bmp']:
            image_files.extend([
                os.path.join(self.source_dir, f) 
                for f in os.listdir(self.source_dir) 
                if f.lower().endswith(ext)
            ])
        
        if not image_files:
            raise ValueError(f"åœ¨ {self.source_dir} ä¸­æ‰¾ä¸åˆ°åœ–ç‰‡æª”æ¡ˆ")
        
        # é™åˆ¶æ•¸é‡ä»¥é¿å…ç›¸å®¹æ€§å•é¡Œ
        max_images = min(10, len(image_files))  # æœ€å¤š 10 å¼µåœ–ç‰‡
        image_files = image_files[:max_images]
        
        print(f"ğŸ“· ä½¿ç”¨ {len(image_files)} å¼µåœ–ç‰‡é€²è¡Œè¨“ç·´")
        
        # ç”Ÿæˆæ¨™è¨»
        captions = []
        for image_path in image_files:
            caption = self.generate_fashion_caption(image_path)
            captions.append(caption)
        
        # å‰µå»ºæ•¸æ“šé›†
        dataset = FashionDataset(
            image_paths=image_files,
            captions=captions,
            size=self.config["image_size"]
        )
        
        # å‰µå»ºæ•¸æ“šåŠ è¼‰å™¨
        dataloader = DataLoader(
            dataset,
            batch_size=self.config["batch_size"],
            shuffle=True,
            num_workers=0  # Windows ç›¸å®¹æ€§
        )
        
        print(f"âœ… æ•¸æ“šé›†æº–å‚™å®Œæˆ")
        return dataloader
    
    def train_compatible_mode(self):
        """ç›¸å®¹æ€§æ¨¡å¼è¨“ç·´"""
        print("ğŸ”„ å•Ÿå‹•ç›¸å®¹æ€§æ¨¡å¼è¨“ç·´...")
        
        if not self.pipeline:
            print("âŒ ç„¡æ³•è¼‰å…¥ Stable Diffusionï¼Œè·³éå¾®èª¿è¨“ç·´")
            print("ğŸ’¡ å»ºè­°ä¿®å¾© diffusers ç›¸å®¹æ€§å•é¡Œå¾Œé‡è©¦")
            return False
        
        try:
            # æº–å‚™æ•¸æ“š
            dataloader = self.prepare_dataset()
            
            # ç°¡åŒ–çš„è¨“ç·´å¾ªç’°ï¼ˆä¸»è¦æ˜¯é©—è­‰æµç¨‹ï¼‰
            print("ğŸ”„ åŸ·è¡Œé©—è­‰æ€§è¨“ç·´å¾ªç’°...")
            
            for epoch in range(min(3, self.config["num_epochs"])):  # æœ€å¤š 3 epochs
                print(f"\nğŸ“Š Epoch {epoch+1}")
                
                for batch_idx, batch in enumerate(dataloader):
                    if batch_idx >= 2:  # æœ€å¤š 2 å€‹ batch
                        break
                    
                    print(f"   è™•ç† batch {batch_idx+1}")
                    
                    # æ¨¡æ“¬è¨“ç·´æ­¥é©Ÿ
                    images = batch["images"]
                    captions = batch["captions"]
                    
                    # é€™è£¡å¯ä»¥æ·»åŠ å¯¦éš›çš„è¨“ç·´é‚è¼¯
                    # ç›®å‰ä¸»è¦æ˜¯é©—è­‰æ•¸æ“šæµå’Œç›¸å®¹æ€§
                    
                    print(f"   âœ… Batch {batch_idx+1} è™•ç†å®Œæˆ")
                
                # ç”Ÿæˆé©—è­‰åœ–ç‰‡
                self.generate_validation_images(epoch)
            
            print("âœ… ç›¸å®¹æ€§è¨“ç·´å®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ ç›¸å®¹æ€§è¨“ç·´å¤±æ•—: {e}")
            return False
    
    def generate_validation_images(self, epoch):
        """ç”Ÿæˆé©—è­‰åœ–ç‰‡"""
        if not self.pipeline:
            return
        
        validation_prompts = [
            "elegant fashion outfit",
            "casual trendy clothing",
            "modern stylish attire"
        ]
        
        validation_dir = os.path.join(self.output_dir, "validation_images")
        os.makedirs(validation_dir, exist_ok=True)
        
        for i, prompt in enumerate(validation_prompts):
            try:
                with torch.no_grad():
                    image = self.pipeline(
                        prompt=prompt,
                        num_inference_steps=20,
                        guidance_scale=7.5,
                        height=512,
                        width=512
                    ).images[0]
                
                image_path = os.path.join(validation_dir, f"validation_epoch_{epoch}_prompt_{i}.png")
                image.save(image_path)
                print(f"   ğŸ“¸ é©—è­‰åœ–ç‰‡å·²ä¿å­˜: {image_path}")
                
            except Exception as e:
                print(f"   âŒ é©—è­‰åœ–ç‰‡ {i+1} ç”Ÿæˆå¤±æ•—: {e}")
    
    def generate_compatibility_report(self):
        """ç”Ÿæˆç›¸å®¹æ€§å ±å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = os.path.join(self.output_dir, f"compatibility_report_{timestamp}.md")
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# Fashion AI Training - ç›¸å®¹æ€§å ±å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## ç³»çµ±ç›¸å®¹æ€§\n\n")
            for component, (available, message) in self.compatibility.items():
                if component == "features":
                    continue
                status = "âœ… å¯ç”¨" if available else "âŒ ä¸å¯ç”¨"
                f.write(f"- **{component}**: {status} - {message}\n")
            
            f.write("\n## å¯ç”¨åŠŸèƒ½\n\n")
            for feature, available in self.compatibility["features"].items():
                status = "âœ… æ”¯æ´" if available else "âŒ ä¸æ”¯æ´"
                f.write(f"- **{feature}**: {status}\n")
            
            f.write("\n## å»ºè­°\n\n")
            
            if not self.compatibility["transformers"][0]:
                f.write("### Transformers å•é¡Œ\n")
                f.write("```bash\n")
                f.write("pip install --upgrade transformers>=4.37.0\n")
                f.write("```\n\n")
            
            if not self.compatibility["diffusers"][0]:
                f.write("### Diffusers å•é¡Œ\n")
                f.write("```bash\n")
                f.write("pip uninstall diffusers -y\n")
                f.write("pip install diffusers>=0.27.0\n")
                f.write("```\n\n")
            
            if not self.compatibility["features"]["lora"]:
                f.write("### LoRA ä¸å¯ç”¨\n")
                f.write("LoRA åŠŸèƒ½éœ€è¦æ›´æ–°ç‰ˆæœ¬çš„ diffusers\n\n")
        
        print(f"ğŸ“„ ç›¸å®¹æ€§å ±å‘Šå·²ä¿å­˜: {report_path}")
        return report_path
    
    def run_compatible_training(self):
        """åŸ·è¡Œç›¸å®¹æ€§å‹å¥½çš„è¨“ç·´"""
        print("ğŸš€ é–‹å§‹ç›¸å®¹æ€§ Fashion Fine-tuning")
        print("=" * 60)
        
        # ç”Ÿæˆç›¸å®¹æ€§å ±å‘Š
        self.generate_compatibility_report()
        
        # æ ¹æ“šç›¸å®¹æ€§æ±ºå®šè¨“ç·´æ¨¡å¼
        if self.compatibility["diffusers"][0] and self.pipeline:
            print("âœ… é€²å…¥å®Œæ•´è¨“ç·´æ¨¡å¼")
            success = self.train_compatible_mode()
        else:
            print("âš ï¸  é€²å…¥æ¨¡æ“¬è¨“ç·´æ¨¡å¼")
            success = self.simulate_training()
        
        if success:
            print("ğŸ‰ è¨“ç·´æµç¨‹å®Œæˆï¼ˆç›¸å®¹æ€§æ¨¡å¼ï¼‰")
        else:
            print("âŒ è¨“ç·´æµç¨‹å¤±æ•—")
            print("ğŸ’¡ è«‹æª¢æŸ¥ç›¸å®¹æ€§å ±å‘Šä¸¦ä¿®å¾©å•é¡Œ")
    
    def simulate_training(self):
        """æ¨¡æ“¬è¨“ç·´ï¼ˆç•¶çµ„ä»¶ä¸å¯ç”¨æ™‚ï¼‰"""
        print("ğŸ­ æ¨¡æ“¬è¨“ç·´æµç¨‹...")
        
        try:
            # æº–å‚™æ•¸æ“š
            dataloader = self.prepare_dataset()
            
            # æ¨¡æ“¬è¨“ç·´å¾ªç’°
            for epoch in range(3):
                print(f"\nğŸ“Š æ¨¡æ“¬ Epoch {epoch+1}")
                
                for batch_idx, batch in enumerate(dataloader):
                    if batch_idx >= 1:  # åªè™•ç†ä¸€å€‹ batch
                        break
                    
                    print(f"   æ¨¡æ“¬è™•ç† batch {batch_idx+1}")
                    
                    # æ¨¡æ“¬æå¤±è¨ˆç®—
                    simulated_loss = 0.8 * (0.9 ** epoch) + 0.1
                    print(f"   æ¨¡æ“¬æå¤±: {simulated_loss:.4f}")
            
            print("âœ… æ¨¡æ“¬è¨“ç·´å®Œæˆ")
            print("ğŸ’¡ é€™æ˜¯æ¨¡æ“¬æ¨¡å¼ï¼Œæœªé€²è¡Œå¯¦éš›çš„æ¨¡å‹è¨“ç·´")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡æ“¬è¨“ç·´å¤±æ•—: {e}")
            return False

def main():
    """ä¸»å‡½æ•¸"""
    try:
        # å‰µå»ºç›¸å®¹æ€§å¾®èª¿å™¨
        finetuner = CompatibleFashionFineTuner()
        
        # åŸ·è¡Œç›¸å®¹æ€§è¨“ç·´
        finetuner.run_compatible_training()
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  è¨“ç·´è¢«ç”¨æˆ¶ä¸­æ–·")
    except Exception as e:
        print(f"âŒ è¨“ç·´å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
