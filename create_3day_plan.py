#!/usr/bin/env python3
"""
3å¤©å¿«é€Ÿå¯è¡Œæ€§æ¸¬è©¦è¨ˆåŠƒ
Day 1: åŸºç¤è¨­ç½®å’Œæ‰‹å‹•æ¸¬è©¦
Day 2: è‡ªå‹•åŒ– Pipeline
Day 3: è©•ä¼°å’Œç¸½çµ
"""

import os
import json
from datetime import datetime

def create_3day_plan():
    """å‰µå»º3å¤©æ¸¬è©¦è¨ˆåŠƒ"""
    
    plan = {
        "project_timeline": "3 Days Feasibility Test",
        "start_date": datetime.now().isoformat(),
        
        "day_1": {
            "title": "åŸºç¤è¨­ç½®å’Œæ¦‚å¿µé©—è­‰",
            "duration": "8 å°æ™‚",
            "goals": [
                "ç’°å¢ƒè¨­ç½®å®Œæˆ",
                "æ‰‹å‹•æ¸¬è©¦ 5-10 å¼µåœ–ç‰‡",
                "é©—è­‰åŸºæœ¬ pipeline å¯è¡Œæ€§"
            ],
            "tasks": [
                {
                    "task": "ç’°å¢ƒæº–å‚™",
                    "time": "1 å°æ™‚",
                    "details": "å®‰è£ CLIPã€è¨­ç½®è³‡æ–™å¤¾ã€æº–å‚™æ¸¬è©¦åœ–ç‰‡"
                },
                {
                    "task": "æ‰‹å‹•ç‰¹å¾µæ¨™è¨»",
                    "time": "2 å°æ™‚", 
                    "details": "ç‚º 10 å¼µæ™‚å°šåœ–ç‰‡æ‰‹å‹•æ¨™è¨»ç‰¹å¾µ"
                },
                {
                    "task": "æç¤ºè©ç”Ÿæˆæ¸¬è©¦",
                    "time": "2 å°æ™‚",
                    "details": "æ ¹æ“šç‰¹å¾µç”Ÿæˆ SD æç¤ºè©ï¼Œæ¸¬è©¦ç”Ÿæˆæ•ˆæœ"
                },
                {
                    "task": "åˆæ­¥æ¯”è¼ƒ",
                    "time": "2 å°æ™‚",
                    "details": "è‚‰çœ¼æ¯”è¼ƒåŸåœ–å’Œç”Ÿæˆåœ–ï¼Œè¨˜éŒ„è§€å¯Ÿ"
                },
                {
                    "task": "å•é¡Œè­˜åˆ¥",
                    "time": "1 å°æ™‚",
                    "details": "è¨˜éŒ„é‡åˆ°çš„å•é¡Œå’Œæ”¹é€²æ–¹å‘"
                }
            ]
        },
        
        "day_2": {
            "title": "è‡ªå‹•åŒ–æµç¨‹å¯¦ä½œ",
            "duration": "8 å°æ™‚",
            "goals": [
                "CLIP ç‰¹å¾µæå–è‡ªå‹•åŒ–",
                "æ‰¹æ¬¡ç”Ÿæˆæ¸¬è©¦",
                "å»ºç«‹è©•ä¼°æŒ‡æ¨™"
            ],
            "tasks": [
                {
                    "task": "å¯¦ä½œç°¡åŒ–ç‰ˆ CLIP ç‰¹å¾µæå–",
                    "time": "3 å°æ™‚",
                    "details": "ä½¿ç”¨ CLIP è‡ªå‹•åˆ†æåœ–ç‰‡ç‰¹å¾µ"
                },
                {
                    "task": "æ‰¹æ¬¡ç”Ÿæˆ pipeline",
                    "time": "2 å°æ™‚",
                    "details": "è‡ªå‹•åŒ–ç”Ÿæˆ 20-30 å¼µåœ–ç‰‡"
                },
                {
                    "task": "å»ºç«‹è©•ä¼°æ–¹æ³•",
                    "time": "2 å°æ™‚",
                    "details": "CLIP ç›¸ä¼¼åº¦è¨ˆç®—ã€äººå·¥è©•åˆ†è¡¨"
                },
                {
                    "task": "è³‡æ–™è¨˜éŒ„",
                    "time": "1 å°æ™‚",
                    "details": "æ•´ç†å¯¦é©—è³‡æ–™å’Œçµæœ"
                }
            ]
        },
        
        "day_3": {
            "title": "è©•ä¼°å’Œçµè«–",
            "duration": "6 å°æ™‚",
            "goals": [
                "é‡åŒ–è©•ä¼°çµæœ",
                "è­˜åˆ¥æ”¹é€²æ–¹å‘",
                "åˆ¶å®šå¾ŒçºŒè¨ˆåŠƒ"
            ],
            "tasks": [
                {
                    "task": "é‡åŒ–åˆ†æ",
                    "time": "2 å°æ™‚",
                    "details": "è¨ˆç®—ç›¸ä¼¼åº¦ã€çµ±è¨ˆæˆåŠŸç‡"
                },
                {
                    "task": "å®šæ€§è©•ä¼°",
                    "time": "2 å°æ™‚",
                    "details": "åˆ†æå¤±æ•—æ¡ˆä¾‹ã€è­˜åˆ¥å•é¡Œæ¨¡å¼"
                },
                {
                    "task": "å¯è¡Œæ€§å ±å‘Š",
                    "time": "1.5 å°æ™‚",
                    "details": "æ’°å¯«æ¸¬è©¦å ±å‘Šå’Œå»ºè­°"
                },
                {
                    "task": "å¾ŒçºŒè¨ˆåŠƒ",
                    "time": "0.5 å°æ™‚",
                    "details": "åˆ¶å®šå®Œæ•´å¯¦ä½œè¨ˆåŠƒ"
                }
            ]
        },
        
        "success_criteria": {
            "minimum_viable": [
                "èƒ½å¤ æå–åŸºæœ¬æœè£ç‰¹å¾µ",
                "ç”Ÿæˆçš„åœ–ç‰‡èˆ‡åŸåœ–æœ‰ç›¸ä¼¼çš„æœè£é¡å‹",
                "è‡³å°‘ 30% çš„ç”Ÿæˆåœ–ç‰‡åœ¨è¦–è¦ºä¸Šç›¸é—œ"
            ],
            "ideal_outcome": [
                "ç‰¹å¾µæå–æº–ç¢ºåº¦ > 70%",
                "ç”Ÿæˆåœ–ç‰‡é¢¨æ ¼ä¸€è‡´æ€§ > 60%", 
                "æ•´å€‹ pipeline å¯ä»¥è‡ªå‹•é‹è¡Œ"
            ]
        },
        
        "risk_mitigation": {
            "time_shortage": "å°ˆæ³¨æ ¸å¿ƒåŠŸèƒ½ï¼Œè·³éç¾åŒ–",
            "technical_issues": "æº–å‚™å‚™ç”¨æ–¹æ¡ˆï¼ˆæ‰‹å‹•æ¨™è¨»ï¼‰",
            "quality_issues": "é™ä½æœŸæœ›ï¼Œå°ˆæ³¨å¯è¡Œæ€§é©—è­‰"
        }
    }
    
    return plan

def create_day1_script():
    """Day 1: å¿«é€Ÿæ¦‚å¿µé©—è­‰è…³æœ¬"""
    
    script_content = '''#!/usr/bin/env python3
"""
Day 1: å¿«é€Ÿæ¦‚å¿µé©—è­‰
ä½¿ç”¨æœ€ç°¡å–®çš„æ–¹æ³•æ¸¬è©¦å¯è¡Œæ€§
"""

import os
import json
import requests
import base64
from datetime import datetime
from text_to_image_service import text_to_image_service

class QuickFashionTest:
    """å¿«é€Ÿæ™‚å°šæ¸¬è©¦"""
    
    def __init__(self):
        self.test_data = []
        
    def manual_feature_annotation(self, image_path):
        """æ‰‹å‹•ç‰¹å¾µæ¨™è¨» (Day 1 å¿«é€Ÿæ–¹æ³•)"""
        
        print(f"\\nğŸ“¸ åˆ†æåœ–ç‰‡: {os.path.basename(image_path)}")
        print("è«‹æ ¹æ“šåœ–ç‰‡å…§å®¹å›ç­”ä»¥ä¸‹å•é¡Œ:")
        
        # ç°¡åŒ–çš„æ‰‹å‹•æ¨™è¨»
        features = {}
        
        # æ€§åˆ¥
        gender = input("æ€§åˆ¥ (male/female/unisex): ").strip().lower()
        features["gender"] = gender if gender in ["male", "female", "unisex"] else "unisex"
        
        # ä¸Šè¡£
        top = input("ä¸Šè¡£é¡å‹ (shirt/t-shirt/jacket/sweater/other): ").strip().lower()
        features["top"] = top if top else "shirt"
        
        # ä¸‹èº«
        bottom = input("ä¸‹èº«é¡å‹ (jeans/trousers/skirt/dress/shorts/other): ").strip().lower()
        features["bottom"] = bottom if bottom else "jeans"
        
        # é¢¨æ ¼
        style = input("é¢¨æ ¼ (casual/formal/sporty/elegant/other): ").strip().lower()
        features["style"] = style if style else "casual"
        
        # é¡è‰²
        colors = input("ä¸»è¦é¡è‰² (å¤šå€‹ç”¨é€—è™Ÿåˆ†éš”): ").strip()
        features["colors"] = colors if colors else "neutral"
        
        return features
    
    def generate_prompt_from_features(self, features):
        """å¾ç‰¹å¾µç”Ÿæˆæç¤ºè©"""
        
        prompt_parts = []
        
        # æ§‹å»ºåŸºæœ¬æè¿°
        if features.get("gender") == "female":
            prompt_parts.append("woman")
        elif features.get("gender") == "male":
            prompt_parts.append("man")
        else:
            prompt_parts.append("person")
        
        # æ·»åŠ æœè£
        if features.get("top"):
            prompt_parts.append(f"wearing {features['top']}")
        
        if features.get("bottom"):
            prompt_parts.append(f"and {features['bottom']}")
        
        # æ·»åŠ é¢¨æ ¼
        if features.get("style"):
            prompt_parts.append(f"{features['style']} style")
        
        # æ·»åŠ é¡è‰²
        if features.get("colors"):
            prompt_parts.append(f"{features['colors']} colors")
        
        # çµ„åˆæç¤ºè©
        main_prompt = " ".join(prompt_parts)
        main_prompt += ", fashion photography, high quality, detailed, studio lighting"
        
        negative_prompt = "blurry, low quality, distorted, deformed, multiple people"
        
        return main_prompt, negative_prompt
    
    def test_single_image(self, image_path):
        """æ¸¬è©¦å–®å¼µåœ–ç‰‡"""
        
        print(f"\\n{'='*60}")
        print(f"æ¸¬è©¦åœ–ç‰‡: {image_path}")
        print(f"{'='*60}")
        
        # 1. æ‰‹å‹•ç‰¹å¾µæ¨™è¨»
        features = self.manual_feature_annotation(image_path)
        
        # 2. ç”Ÿæˆæç¤ºè©
        prompt, negative_prompt = self.generate_prompt_from_features(features)
        print(f"\\nç”Ÿæˆçš„æç¤ºè©: {prompt}")
        
        # 3. ç”Ÿæˆåœ–ç‰‡
        print("\\nğŸ¨ ç”Ÿæˆåœ–ç‰‡...")
        result = text_to_image_service(
            prompt=prompt,
            negative_prompt=negative_prompt,
            width=512,
            height=512,
            steps=20
        )
        
        # 4. è¨˜éŒ„çµæœ
        test_record = {
            "original_image": image_path,
            "features": features,
            "prompt": prompt,
            "negative_prompt": negative_prompt,
            "timestamp": datetime.now().isoformat()
        }
        
        if result["success"]:
            test_record["generated_image"] = result["saved_files"][0]
            test_record["generation_time"] = result["generation_time"]
            test_record["status"] = "success"
            print(f"âœ… ç”ŸæˆæˆåŠŸ: {result['saved_files'][0]}")
        else:
            test_record["error"] = result["error"]
            test_record["status"] = "failed"
            print(f"âŒ ç”Ÿæˆå¤±æ•—: {result['error']}")
        
        self.test_data.append(test_record)
        
        # 5. äººå·¥è©•ä¼°
        if result["success"]:
            print("\\nğŸ‘€ è«‹æ‰“é–‹ç”Ÿæˆçš„åœ–ç‰‡é€²è¡Œæ¯”è¼ƒ")
            similarity = input("ç›¸ä¼¼åº¦è©•åˆ† (1-10, 10æœ€ç›¸ä¼¼): ").strip()
            try:
                test_record["human_similarity_score"] = int(similarity)
            except:
                test_record["human_similarity_score"] = 5
        
        return test_record
    
    def run_day1_test(self, test_images_dir="test_images"):
        """åŸ·è¡Œ Day 1 æ¸¬è©¦"""
        
        print("ğŸš€ Day 1: å¿«é€Ÿå¯è¡Œæ€§æ¸¬è©¦")
        print("=" * 60)
        
        # æª¢æŸ¥æ¸¬è©¦åœ–ç‰‡
        if not os.path.exists(test_images_dir):
            os.makedirs(test_images_dir)
            print(f"âš ï¸ è«‹å°‡ 5-10 å¼µæ™‚å°šåœ–ç‰‡æ”¾å…¥ {test_images_dir}/ ç›®éŒ„")
            return
        
        image_files = [f for f in os.listdir(test_images_dir) 
                      if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        
        if not image_files:
            print(f"âš ï¸ åœ¨ {test_images_dir}/ ä¸­æ²’æœ‰æ‰¾åˆ°åœ–ç‰‡æª”æ¡ˆ")
            return
        
        print(f"ğŸ“‹ æ‰¾åˆ° {len(image_files)} å¼µæ¸¬è©¦åœ–ç‰‡")
        
        # æ¸¬è©¦æ¯å¼µåœ–ç‰‡
        for i, image_file in enumerate(image_files, 1):
            image_path = os.path.join(test_images_dir, image_file)
            print(f"\\nğŸ“Š é€²åº¦: {i}/{len(image_files)}")
            
            try:
                self.test_single_image(image_path)
            except KeyboardInterrupt:
                print("\\nâ¹ï¸ æ¸¬è©¦ä¸­æ–·")
                break
            except Exception as e:
                print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        
        # å„²å­˜çµæœ
        self.save_day1_results()
    
    def save_day1_results(self):
        """å„²å­˜ Day 1 çµæœ"""
        
        results = {
            "test_info": {
                "test_date": datetime.now().isoformat(),
                "test_type": "Day 1 Manual Feasibility Test",
                "total_samples": len(self.test_data)
            },
            "results": self.test_data
        }
        
        with open("day1_test_results.json", 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        # ç°¡å–®çµ±è¨ˆ
        successful = [r for r in self.test_data if r.get("status") == "success"]
        if successful:
            avg_similarity = sum(r.get("human_similarity_score", 0) for r in successful) / len(successful)
            avg_time = sum(r.get("generation_time", 0) for r in successful) / len(successful)
            
            print(f"\\nğŸ“Š Day 1 æ¸¬è©¦ç¸½çµ:")
            print(f"   ç¸½æ¸¬è©¦æ•¸: {len(self.test_data)}")
            print(f"   æˆåŠŸç”Ÿæˆ: {len(successful)}")
            print(f"   æˆåŠŸç‡: {len(successful)/len(self.test_data)*100:.1f}%")
            print(f"   å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity:.1f}/10")
            print(f"   å¹³å‡ç”Ÿæˆæ™‚é–“: {avg_time:.1f} ç§’")
            
            if avg_similarity >= 6:
                print("\\nğŸ‰ åˆæ­¥çµæœè‰¯å¥½ï¼Œå»ºè­°ç¹¼çºŒ Day 2 æ¸¬è©¦")
            else:
                print("\\nâš ï¸ éœ€è¦æ”¹é€²æç¤ºè©ç”Ÿæˆæ–¹æ³•")
        
        print(f"\\nğŸ’¾ çµæœå·²ä¿å­˜: day1_test_results.json")

def main():
    """Day 1 ä¸»ç¨‹å¼"""
    
    tester = QuickFashionTest()
    tester.run_day1_test()

if __name__ == "__main__":
    main()
'''
    
    return script_content

def create_day2_script():
    """Day 2: è‡ªå‹•åŒ–æ¸¬è©¦è…³æœ¬"""
    
    script_content = '''#!/usr/bin/env python3
"""
Day 2: è‡ªå‹•åŒ–ç‰¹å¾µæå–å’Œæ‰¹æ¬¡æ¸¬è©¦
"""

import os
import json
import torch
import clip
import requests
from PIL import Image
from datetime import datetime
from text_to_image_service import text_to_image_service

class AutomatedFashionTest:
    """è‡ªå‹•åŒ–æ™‚å°šæ¸¬è©¦"""
    
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model, self.preprocess = clip.load("ViT-B/32", device=self.device)
        self.test_results = []
        
        # ç°¡åŒ–çš„ç‰¹å¾µè©å½™
        self.feature_vocabulary = {
            "clothing_type": ["dress", "shirt", "t-shirt", "jacket", "sweater", "jeans", "trousers", "skirt"],
            "style": ["casual", "formal", "sporty", "elegant", "vintage"],
            "color": ["black", "white", "blue", "red", "green", "brown", "gray", "colorful"]
        }
    
    def extract_features_auto(self, image_path):
        """è‡ªå‹•ç‰¹å¾µæå–"""
        
        try:
            image = Image.open(image_path).convert('RGB')
            image_input = self.preprocess(image).unsqueeze(0).to(self.device)
            
            features = {}
            
            # å°æ¯å€‹ç‰¹å¾µé¡åˆ¥è¨ˆç®—ç›¸ä¼¼åº¦
            for category, words in self.feature_vocabulary.items():
                text_prompts = [f"a photo of {word} clothing" for word in words]
                text_inputs = clip.tokenize(text_prompts).to(self.device)
                
                with torch.no_grad():
                    image_features = self.model.encode_image(image_input)
                    text_features = self.model.encode_text(text_inputs)
                    
                    similarities = torch.cosine_similarity(image_features, text_features, dim=1)
                    
                    # å–æœ€é«˜åˆ†çš„ç‰¹å¾µ
                    best_idx = similarities.argmax().item()
                    best_score = similarities[best_idx].item()
                    
                    features[category] = {
                        "value": words[best_idx],
                        "confidence": best_score
                    }
            
            return features
            
        except Exception as e:
            print(f"âŒ ç‰¹å¾µæå–å¤±æ•—: {e}")
            return None
    
    def generate_prompt_auto(self, features):
        """è‡ªå‹•ç”Ÿæˆæç¤ºè©"""
        
        prompt_parts = ["person wearing"]
        
        # æ·»åŠ æœè£é¡å‹
        clothing = features.get("clothing_type", {})
        if clothing.get("confidence", 0) > 0.3:
            prompt_parts.append(clothing["value"])
        
        # æ·»åŠ é¢¨æ ¼
        style = features.get("style", {})
        if style.get("confidence", 0) > 0.3:
            prompt_parts.append(f"{style['value']} style")
        
        # æ·»åŠ é¡è‰²
        color = features.get("color", {})
        if color.get("confidence", 0) > 0.3:
            prompt_parts.append(f"{color['value']} color")
        
        prompt = " ".join(prompt_parts)
        prompt += ", fashion photography, high quality, detailed"
        
        negative_prompt = "blurry, low quality, distorted, multiple people"
        
        return prompt, negative_prompt
    
    def calculate_clip_similarity(self, image1_path, image2_path):
        """è¨ˆç®—å…©å¼µåœ–ç‰‡çš„ CLIP ç›¸ä¼¼åº¦"""
        
        try:
            # è¼‰å…¥åœ–ç‰‡
            image1 = Image.open(image1_path).convert('RGB')
            image2 = Image.open(image2_path).convert('RGB')
            
            # é è™•ç†
            image1_input = self.preprocess(image1).unsqueeze(0).to(self.device)
            image2_input = self.preprocess(image2).unsqueeze(0).to(self.device)
            
            # è¨ˆç®—ç‰¹å¾µ
            with torch.no_grad():
                features1 = self.model.encode_image(image1_input)
                features2 = self.model.encode_image(image2_input)
                
                # è¨ˆç®—ç›¸ä¼¼åº¦
                similarity = torch.cosine_similarity(features1, features2, dim=1)
                return similarity.item()
                
        except Exception as e:
            print(f"âŒ ç›¸ä¼¼åº¦è¨ˆç®—å¤±æ•—: {e}")
            return 0.0
    
    def test_image_automated(self, image_path):
        """è‡ªå‹•åŒ–æ¸¬è©¦å–®å¼µåœ–ç‰‡"""
        
        print(f"\\nğŸ” è‡ªå‹•åˆ†æ: {os.path.basename(image_path)}")
        
        # 1. è‡ªå‹•ç‰¹å¾µæå–
        features = self.extract_features_auto(image_path)
        if not features:
            return None
        
        print("ğŸ“Š æå–çš„ç‰¹å¾µ:")
        for category, data in features.items():
            print(f"   {category}: {data['value']} (ä¿¡å¿ƒåº¦: {data['confidence']:.3f})")
        
        # 2. ç”Ÿæˆæç¤ºè©
        prompt, negative_prompt = self.generate_prompt_auto(features)
        print(f"\\nğŸ“ ç”Ÿæˆçš„æç¤ºè©: {prompt}")
        
        # 3. ç”Ÿæˆåœ–ç‰‡
        result = text_to_image_service(
            prompt=prompt,
            negative_prompt=negative_prompt,
            width=512,
            height=512,
            steps=20
        )
        
        test_record = {
            "original_image": image_path,
            "features": features,
            "prompt": prompt,
            "timestamp": datetime.now().isoformat()
        }
        
        if result["success"]:
            generated_path = result["saved_files"][0]
            test_record["generated_image"] = generated_path
            test_record["generation_time"] = result["generation_time"]
            
            # 4. è¨ˆç®—ç›¸ä¼¼åº¦
            similarity = self.calculate_clip_similarity(image_path, generated_path)
            test_record["clip_similarity"] = similarity
            test_record["status"] = "success"
            
            print(f"âœ… ç”ŸæˆæˆåŠŸ: {generated_path}")
            print(f"ğŸ¯ CLIP ç›¸ä¼¼åº¦: {similarity:.3f}")
        else:
            test_record["error"] = result["error"]
            test_record["status"] = "failed"
            print(f"âŒ ç”Ÿæˆå¤±æ•—: {result['error']}")
        
        return test_record
    
    def run_day2_test(self, test_images_dir="test_images"):
        """åŸ·è¡Œ Day 2 è‡ªå‹•åŒ–æ¸¬è©¦"""
        
        print("ğŸ¤– Day 2: è‡ªå‹•åŒ–ç‰¹å¾µæå–æ¸¬è©¦")
        print("=" * 60)
        
        image_files = [f for f in os.listdir(test_images_dir) 
                      if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        
        if not image_files:
            print(f"âš ï¸ åœ¨ {test_images_dir}/ ä¸­æ²’æœ‰æ‰¾åˆ°åœ–ç‰‡")
            return
        
        print(f"ğŸ“‹ è™•ç† {len(image_files)} å¼µåœ–ç‰‡")
        
        for i, image_file in enumerate(image_files, 1):
            image_path = os.path.join(test_images_dir, image_file)
            print(f"\\nğŸ“Š é€²åº¦: {i}/{len(image_files)}")
            
            try:
                result = self.test_image_automated(image_path)
                if result:
                    self.test_results.append(result)
            except Exception as e:
                print(f"âŒ è™•ç†å¤±æ•—: {e}")
        
        self.save_day2_results()
    
    def save_day2_results(self):
        """å„²å­˜ Day 2 çµæœ"""
        
        results = {
            "test_info": {
                "test_date": datetime.now().isoformat(),
                "test_type": "Day 2 Automated Feature Extraction",
                "total_samples": len(self.test_results)
            },
            "results": self.test_results
        }
        
        with open("day2_test_results.json", 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        # çµ±è¨ˆåˆ†æ
        successful = [r for r in self.test_results if r.get("status") == "success"]
        
        if successful:
            similarities = [r["clip_similarity"] for r in successful]
            avg_similarity = sum(similarities) / len(similarities)
            
            # ç‰¹å¾µä¿¡å¿ƒåº¦çµ±è¨ˆ
            confidence_scores = []
            for r in successful:
                for feature_data in r["features"].values():
                    confidence_scores.append(feature_data["confidence"])
            
            avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0
            
            print(f"\\nğŸ“Š Day 2 æ¸¬è©¦ç¸½çµ:")
            print(f"   ç¸½æ¸¬è©¦æ•¸: {len(self.test_results)}")
            print(f"   æˆåŠŸç”Ÿæˆ: {len(successful)}")
            print(f"   å¹³å‡ CLIP ç›¸ä¼¼åº¦: {avg_similarity:.3f}")
            print(f"   å¹³å‡ç‰¹å¾µä¿¡å¿ƒåº¦: {avg_confidence:.3f}")
            
            good_results = len([s for s in similarities if s > 0.6])
            print(f"   é«˜ç›¸ä¼¼åº¦æ¨£æœ¬ (>0.6): {good_results}/{len(successful)}")
            
            if avg_similarity > 0.5:
                print("\\nğŸ‰ è‡ªå‹•åŒ–æ–¹æ³•é¡¯ç¤ºè‰¯å¥½æ½›åŠ›")
            else:
                print("\\nâš ï¸ éœ€è¦æ”¹é€²ç‰¹å¾µæå–æˆ–æç¤ºè©ç”Ÿæˆ")
        
        print(f"\\nğŸ’¾ çµæœå·²ä¿å­˜: day2_test_results.json")

def main():
    """Day 2 ä¸»ç¨‹å¼"""
    
    tester = AutomatedFashionTest()
    tester.run_day2_test()

if __name__ == "__main__":
    main()
'''
    
    return script_content

def main():
    """å»ºç«‹3å¤©æ¸¬è©¦è¨ˆåŠƒ"""
    
    print("âš¡ 3å¤©å¿«é€Ÿå¯è¡Œæ€§æ¸¬è©¦è¨ˆåŠƒ")
    print("=" * 60)
    
    # å‰µå»ºè¨ˆåŠƒ
    plan = create_3day_plan()
    
    # å„²å­˜è¨ˆåŠƒ
    with open("3day_feasibility_plan.json", 'w', encoding='utf-8') as f:
        json.dump(plan, f, indent=2, ensure_ascii=False)
    
    # å‰µå»º Day 1 è…³æœ¬
    day1_script = create_day1_script()
    with open("day1_quick_test.py", 'w', encoding='utf-8') as f:
        f.write(day1_script)
    
    # å‰µå»º Day 2 è…³æœ¬
    day2_script = create_day2_script()
    with open("day2_automated_test.py", 'w', encoding='utf-8') as f:
        f.write(day2_script)
    
    # é¡¯ç¤ºè¨ˆåŠƒ
    print("ğŸ“‹ æ¸¬è©¦è¨ˆåŠƒæ¦‚è¦½:")
    for day_key in ["day_1", "day_2", "day_3"]:
        day_info = plan[day_key]
        print(f"\\n{day_info['title']} ({day_info['duration']}):")
        for goal in day_info['goals']:
            print(f"   ğŸ¯ {goal}")
    
    print(f"\\nğŸ“ å·²å‰µå»ºæª”æ¡ˆ:")
    print(f"   ğŸ“„ 3day_feasibility_plan.json - è©³ç´°è¨ˆåŠƒ")
    print(f"   ğŸ day1_quick_test.py - Day 1 æ¸¬è©¦è…³æœ¬")
    print(f"   ğŸ day2_automated_test.py - Day 2 æ¸¬è©¦è…³æœ¬")
    
    print(f"\\nğŸš€ ç«‹å³é–‹å§‹:")
    print(f"   1. å‰µå»º test_images/ è³‡æ–™å¤¾")
    print(f"   2. æ”¾å…¥ 5-10 å¼µæ™‚å°šåœ–ç‰‡")
    print(f"   3. åŸ·è¡Œ: python day1_quick_test.py")
    
    print(f"\\nâš ï¸ æˆåŠŸæ¨™æº–:")
    for criteria in plan["success_criteria"]["minimum_viable"]:
        print(f"   âœ“ {criteria}")

if __name__ == "__main__":
    main()
