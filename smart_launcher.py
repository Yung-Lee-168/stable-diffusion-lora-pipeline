#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Day 3 Fashion AI Training - æ™ºèƒ½å•Ÿå‹•å™¨
è‡ªå‹•æª¢æ¸¬ç¡¬é«”ä¸¦æ¨è–¦æœ€é©åˆçš„è¨“ç·´æ–¹å¼
"""

import torch
import os
import sys

def check_system_capabilities():
    """æª¢æ¸¬ç³»çµ±èƒ½åŠ›"""
    print("ğŸ” æª¢æ¸¬ç³»çµ±é…ç½®...")
    
    capabilities = {
        "has_gpu": False,
        "gpu_name": "",
        "gpu_memory_gb": 0,
        "recommended_mode": "colab"
    }
    
    if torch.cuda.is_available():
        capabilities["has_gpu"] = True
        capabilities["gpu_name"] = torch.cuda.get_device_name()
        capabilities["gpu_memory_gb"] = torch.cuda.get_device_properties(0).total_memory / 1e9
        
        print(f"âœ… GPU: {capabilities['gpu_name']}")
        print(f"ğŸ’¾ VRAM: {capabilities['gpu_memory_gb']:.1f} GB")
        
        # æ ¹æ“š GPU è¨˜æ†¶é«”æ¨è–¦æ¨¡å¼
        if capabilities["gpu_memory_gb"] >= 16:
            capabilities["recommended_mode"] = "local_advanced"
        elif capabilities["gpu_memory_gb"] >= 8:
            capabilities["recommended_mode"] = "local_basic"
        elif capabilities["gpu_memory_gb"] >= 6:
            capabilities["recommended_mode"] = "local_minimal"
        else:
            capabilities["recommended_mode"] = "colab"
    else:
        print("âŒ æ²’æœ‰æª¢æ¸¬åˆ° GPU")
        capabilities["recommended_mode"] = "colab"
    
    return capabilities

def show_recommendations(capabilities):
    """é¡¯ç¤ºå»ºè­°"""
    print("\nğŸ¯ å»ºè­°çš„è¨“ç·´æ–¹å¼:")
    print("=" * 50)
    
    if capabilities["recommended_mode"] == "colab":
        print("ğŸŒ **Google Colab ç‰ˆæœ¬** (å¼·çƒˆæ¨è–¦)")
        print("   åŸå› : GPU è¨˜æ†¶é«”ä¸è¶³æˆ–æ²’æœ‰ GPU")
        print("   å„ªå‹¢: å…è²» 16GB+ GPU, è‡ªå‹•é…ç½®, ç©©å®šå¯é ")
        print("   æ­¥é©Ÿ: ä¸Šå‚³ Day3_Fashion_AI_Colab.ipynb åˆ° Colab")
        
    elif capabilities["recommended_mode"] == "local_minimal":
        print("âš¡ **æœ¬åœ°æœ€å°é…ç½®**")
        print("   é©ç”¨: æ‚¨çš„é…ç½®åŸºæœ¬æ»¿è¶³è¦æ±‚")
        print("   å»ºè­°: LoRA rank=4, batch_size=1")
        print("   å‚™é¸: å¦‚æœä»æœ‰å•é¡Œï¼Œå»ºè­°ä½¿ç”¨ Colab")
        
    elif capabilities["recommended_mode"] == "local_basic":
        print("ğŸ”§ **æœ¬åœ°æ¨™æº–é…ç½®**")
        print("   é©ç”¨: æ‚¨çš„é…ç½®è‰¯å¥½")
        print("   å»ºè­°: LoRA rank=8, batch_size=2")
        
    elif capabilities["recommended_mode"] == "local_advanced":
        print("ğŸš€ **æœ¬åœ°é«˜ç´šé…ç½®**")
        print("   é©ç”¨: æ‚¨æ“æœ‰é«˜ç«¯ GPU")
        print("   å»ºè­°: LoRA rank=16, batch_size=4")
        print("   å¯é¸: ç”šè‡³å¯ä»¥å˜—è©¦å®Œæ•´å¾®èª¿")

def show_menu():
    """é¡¯ç¤ºé¸å–®"""
    print("\nğŸ“‹ é¸æ“‡åŸ·è¡Œæ¨¡å¼:")
    print("1. ğŸŒ Google Colab ç‰ˆæœ¬ (æ¨è–¦)")
    print("2. ğŸ’» æœ¬åœ°æç¤ºè©å„ªåŒ–è¨“ç·´")
    print("3. ğŸ”§ æœ¬åœ° SD v1.5 å¾®èª¿")
    print("4. ğŸ“Š ç³»çµ±ç‹€æ…‹æª¢æŸ¥")
    print("5. ğŸ“š æŸ¥çœ‹ä½¿ç”¨æŒ‡å—")
    print("0. é€€å‡º")

def launch_colab_guide():
    """é¡¯ç¤º Colab ä½¿ç”¨æŒ‡å—"""
    print("\nğŸŒ Google Colab ä½¿ç”¨æ­¥é©Ÿ:")
    print("=" * 40)
    print("1. é–‹å•Ÿ Google Colab (colab.research.google.com)")
    print("2. ä¸Šå‚³ Day3_Fashion_AI_Colab.ipynb")
    print("3. è¨­ç½® GPU é‹è¡Œæ™‚ (åŸ·è¡Œéšæ®µ â†’ è®Šæ›´åŸ·è¡Œéšæ®µé¡å‹ â†’ GPU)")
    print("4. æŒ‰é †åºåŸ·è¡Œæ‰€æœ‰ Cell")
    print("5. ä¸Šå‚³æ‚¨çš„æ™‚å°šåœ–ç‰‡")
    print("6. ç­‰å¾…è¨“ç·´å®Œæˆä¸¦ä¸‹è¼‰çµæœ")
    
    print("\nğŸ“ éœ€è¦çš„æª”æ¡ˆ:")
    if os.path.exists("Day3_Fashion_AI_Colab.ipynb"):
        print("âœ… Day3_Fashion_AI_Colab.ipynb")
    else:
        print("âŒ Day3_Fashion_AI_Colab.ipynb (è«‹å…ˆå‰µå»º)")
    
    if os.path.exists("Colab_Deployment_Guide.md"):
        print("âœ… Colab_Deployment_Guide.md (è©³ç´°æŒ‡å—)")
    else:
        print("âŒ Colab_Deployment_Guide.md (è«‹å…ˆå‰µå»º)")

def launch_local_prompt():
    """å•Ÿå‹•æœ¬åœ°æç¤ºè©å„ªåŒ–"""
    print("\nğŸ’» å•Ÿå‹•æœ¬åœ°æç¤ºè©å„ªåŒ–è¨“ç·´...")
    
    if os.path.exists("day3_fashion_training.py"):
        print("âœ… æ‰¾åˆ° day3_fashion_training.py")
        os.system("python day3_fashion_training.py")
    else:
        print("âŒ æ‰¾ä¸åˆ° day3_fashion_training.py")

def launch_local_finetuning():
    """å•Ÿå‹•æœ¬åœ°å¾®èª¿"""
    print("\nğŸ”§ å•Ÿå‹•æœ¬åœ° SD v1.5 å¾®èª¿...")
    
    capabilities = check_system_capabilities()
    
    if capabilities["gpu_memory_gb"] < 6:
        print("âš ï¸ è­¦å‘Š: GPU è¨˜æ†¶é«”å¯èƒ½ä¸è¶³")
        print("ğŸŒ å¼·çƒˆå»ºè­°ä½¿ç”¨ Google Colab ç‰ˆæœ¬")
        
        choice = input("æ˜¯å¦ä»è¦ç¹¼çºŒ? (y/N): ").strip().lower()
        if choice not in ['y', 'yes']:
            return
    
    if os.path.exists("day3_real_finetuning.py"):
        print("âœ… æ‰¾åˆ° day3_real_finetuning.py")
        os.system("python day3_real_finetuning.py")
    else:
        print("âŒ æ‰¾ä¸åˆ° day3_real_finetuning.py")

def check_system_status():
    """æª¢æŸ¥ç³»çµ±ç‹€æ…‹"""
    print("\nğŸ“Š ç³»çµ±ç‹€æ…‹æª¢æŸ¥...")
    
    # æª¢æŸ¥æª”æ¡ˆ
    required_files = [
        "day3_fashion_training.py",
        "Day3_Fashion_AI_Colab.ipynb", 
        "Colab_Deployment_Guide.md"
    ]
    
    print("\nğŸ“ æª”æ¡ˆæª¢æŸ¥:")
    for file in required_files:
        if os.path.exists(file):
            print(f"âœ… {file}")
        else:
            print(f"âŒ {file}")
    
    # æª¢æŸ¥ç¡¬é«”
    capabilities = check_system_capabilities()
    
    # æª¢æŸ¥ä¾†æºåœ–ç‰‡
    if os.path.exists("day1_results"):
        image_files = [f for f in os.listdir("day1_results") 
                      if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        print(f"\nğŸ–¼ï¸ ä¾†æºåœ–ç‰‡: {len(image_files)} å¼µ")
    else:
        print("\nğŸ–¼ï¸ ä¾†æºåœ–ç‰‡: day1_results ç›®éŒ„ä¸å­˜åœ¨")

def show_guide():
    """é¡¯ç¤ºä½¿ç”¨æŒ‡å—"""
    print("\nğŸ“š Day 3 Fashion AI Training ä½¿ç”¨æŒ‡å—")
    print("=" * 50)
    
    print("\nğŸ¯ å…©ç¨®è¨“ç·´æ–¹å¼:")
    print("1. æç¤ºè©å„ªåŒ–è¨“ç·´ - å„ªåŒ–ç”Ÿæˆæç¤ºè©ï¼Œä¸ä¿®æ”¹æ¨¡å‹æ¬Šé‡")
    print("2. çœŸæ­£çš„æ¨¡å‹å¾®èª¿ - ä½¿ç”¨ LoRA å¾®èª¿ SD v1.5 æ¨¡å‹æ¬Šé‡")
    
    print("\nğŸŒ Google Colab vs æœ¬åœ°è¨“ç·´:")
    print("Google Colab å„ªå‹¢:")
    print("  âœ… å…è²» 16GB GPU (T4)")
    print("  âœ… è‡ªå‹•é…ç½®å’Œå„ªåŒ–")
    print("  âœ… ç„¡éœ€æœ¬åœ°ç’°å¢ƒè¨­ç½®")
    print("  âœ… ç©©å®šä¸”å¯é ")
    
    print("\næœ¬åœ°è¨“ç·´å„ªå‹¢:")
    print("  âœ… å®Œå…¨æ§åˆ¶è¨“ç·´éç¨‹")
    print("  âœ… ç„¡ç¶²è·¯ä¾è³´")
    print("  âœ… å¯ä»¥é•·æ™‚é–“è¨“ç·´")
    print("  â— éœ€è¦è¶³å¤ çš„ GPU è¨˜æ†¶é«”")
    
    print("\nğŸ’¡ å»ºè­°:")
    print("  - GPU VRAM â‰¤ 4GB: å¿…é ˆä½¿ç”¨ Colab")
    print("  - GPU VRAM 6-8GB: Colab æˆ–æœ¬åœ°æœ€å°é…ç½®") 
    print("  - GPU VRAM â‰¥ 16GB: å¯ä»¥é¸æ“‡ä»»ä½•æ–¹å¼")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ¨ Day 3: Fashion AI Training - æ™ºèƒ½å•Ÿå‹•å™¨")
    print("=" * 55)
    
    # æª¢æ¸¬ç³»çµ±èƒ½åŠ›
    capabilities = check_system_capabilities()
    
    # é¡¯ç¤ºå»ºè­°
    show_recommendations(capabilities)
    
    while True:
        try:
            show_menu()
            choice = input("\nè«‹é¸æ“‡ (0-5): ").strip()
            
            if choice == "0":
                print("ğŸ‘‹ å†è¦‹ï¼")
                break
            elif choice == "1":
                launch_colab_guide()
            elif choice == "2":
                launch_local_prompt()
            elif choice == "3":
                launch_local_finetuning()
            elif choice == "4":
                check_system_status()
            elif choice == "5":
                show_guide()
            else:
                print("âŒ ç„¡æ•ˆé¸æ“‡ï¼Œè«‹é‡æ–°è¼¸å…¥")
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ä½¿ç”¨è€…ä¸­æ–·ï¼Œå†è¦‹ï¼")
            break
        except Exception as e:
            print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")

if __name__ == "__main__":
    main()
