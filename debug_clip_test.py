#!/usr/bin/env python3
"""
ç°¡åŒ–ç‰ˆ CLIP æ¸¬è©¦ - ç”¨æ–¼èª¿è©¦å’Œé©—è­‰
"""

import requests
import json
import base64
import os
from datetime import datetime
from PIL import Image

def check_api_status():
    """æª¢æŸ¥ API ç‹€æ…‹"""
    print("ğŸ” æª¢æŸ¥ WebUI API ç‹€æ…‹...")
    
    try:
        # æª¢æŸ¥åŸºæœ¬é€£æ¥
        response = requests.get("http://localhost:7860/sdapi/v1/options", timeout=10)
        if response.status_code == 200:
            print("âœ… API é€£æ¥æ­£å¸¸")
            
            # æª¢æŸ¥æ¨¡å‹è¼‰å…¥ç‹€æ…‹
            model_response = requests.get("http://localhost:7860/sdapi/v1/sd-models", timeout=10)
            if model_response.status_code == 200:
                models = model_response.json()
                print(f"âœ… ç™¼ç¾ {len(models)} å€‹å¯ç”¨æ¨¡å‹")
                if models:
                    print(f"   ç•¶å‰æ¨¡å‹: {models[0].get('title', 'æœªçŸ¥')}")
                else:
                    print("âš ï¸ æ²’æœ‰å¯ç”¨çš„æ¨¡å‹")
                    return False
            
            return True
        else:
            print(f"âŒ API é€£æ¥å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
            return False
    except requests.exceptions.ConnectionError:
        print("âŒ ç„¡æ³•é€£æ¥åˆ° WebUIï¼Œè«‹ç¢ºèª:")
        print("   1. WebUI å·²å•Ÿå‹•")
        print("   2. API æ¨¡å¼å·²å•Ÿç”¨ (--api)")
        print("   3. ç«¯å£ 7860 å¯ç”¨")
        return False
    except Exception as e:
        print(f"âŒ é€£æ¥æª¢æŸ¥å¤±æ•—: {e}")
        return False

def test_basic_generation():
    """æ¸¬è©¦åŸºæœ¬åœ–åƒç”Ÿæˆ"""
    print("\nğŸ¨ æ¸¬è©¦åŸºæœ¬åœ–åƒç”Ÿæˆ...")
    
    payload = {
        "prompt": "a beautiful woman in elegant dress, high quality",
        "negative_prompt": "low quality, blurry",
        "width": 512,
        "height": 512,
        "steps": 20,
        "cfg_scale": 7.0,
        "sampler_name": "Euler a"
    }
    
    try:
        print("ğŸ“¤ ç™¼é€ç”Ÿæˆè«‹æ±‚...")
        response = requests.post("http://localhost:7860/sdapi/v1/txt2img", 
                               json=payload, timeout=120)
        
        print(f"ğŸ“¥ æ”¶åˆ°å›æ‡‰: {response.status_code}")
        
        if response.status_code == 200:
            result = response.json()
            
            if 'images' in result and result['images']:
                # ä¿å­˜åœ–ç‰‡
                image_data = base64.b64decode(result['images'][0])
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                image_path = f"debug_test_{timestamp}.png"
                
                with open(image_path, "wb") as f:
                    f.write(image_data)
                
                print(f"âœ… åœ–åƒç”ŸæˆæˆåŠŸï¼ä¿å­˜ç‚º: {image_path}")
                
                # æª¢æŸ¥åœ–ç‰‡å¤§å°
                img = Image.open(image_path)
                print(f"   åœ–ç‰‡å°ºå¯¸: {img.size}")
                print(f"   æª”æ¡ˆå¤§å°: {len(image_data)} bytes")
                
                return True
            else:
                print("âŒ å›æ‡‰ä¸­æ²’æœ‰åœ–åƒæ•¸æ“š")
                print(f"å›æ‡‰å…§å®¹: {result}")
                return False
        else:
            print(f"âŒ ç”Ÿæˆå¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
            print(f"éŒ¯èª¤è©³æƒ…: {response.text}")
            return False
            
    except requests.exceptions.Timeout:
        print("âŒ è«‹æ±‚è¶…æ™‚ï¼Œå¯èƒ½æ˜¯:")
        print("   1. æ¨¡å‹è¼‰å…¥ä¸­")
        print("   2. GPU è¨˜æ†¶é«”ä¸è¶³")
        print("   3. ç”Ÿæˆæ™‚é–“éé•·")
        return False
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¤±æ•—: {e}")
        return False

def test_clip_models():
    """æ¸¬è©¦ CLIP æ¨¡å‹è¼‰å…¥"""
    print("\nğŸ” æ¸¬è©¦ CLIP æ¨¡å‹è¼‰å…¥...")
    
    # æ¸¬è©¦æ¨™æº– CLIP
    try:
        from transformers import CLIPProcessor, CLIPModel
        import torch
        
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸ“± ä½¿ç”¨è¨­å‚™: {device}")
        
        print("ğŸ“¥ è¼‰å…¥æ¨™æº– CLIP...")
        model = CLIPModel.from_pretrained(
            "openai/clip-vit-base-patch32",
            torch_dtype=torch.float16 if device == "cuda" else torch.float32,
            low_cpu_mem_usage=True
        )
        processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
        model.to(device)
        
        print("âœ… æ¨™æº– CLIP è¼‰å…¥æˆåŠŸ")
        
        # ç°¡å–®æ¸¬è©¦
        test_labels = ["red dress", "blue shirt", "black pants"]
        
        # å‰µå»ºä¸€å€‹æ¸¬è©¦åœ–ç‰‡ï¼ˆç´”è‰²ï¼‰
        test_img = Image.new('RGB', (224, 224), color='red')
        
        inputs = processor(text=test_labels, images=test_img, return_tensors="pt", padding=True)
        inputs = {k: v.to(device) for k, v in inputs.items()}
        
        with torch.no_grad():
            outputs = model(**inputs)
            probs = outputs.logits_per_image.softmax(dim=1)
        
        top_idx = probs[0].argmax().item()
        print(f"âœ… CLIP æ¸¬è©¦æˆåŠŸï¼Œæœ€é«˜åŒ¹é…: {test_labels[top_idx]} ({probs[0][top_idx]:.3f})")
        
        return True
        
    except Exception as e:
        print(f"âŒ CLIP æ¸¬è©¦å¤±æ•—: {e}")
        return False

def main():
    """ä¸»è¦æ¸¬è©¦æµç¨‹"""
    print("=" * 50)
    print("  ç°¡åŒ–ç‰ˆ CLIP æ¸¬è©¦èˆ‡èª¿è©¦")
    print("=" * 50)
    
    # æª¢æŸ¥ API
    if not check_api_status():
        print("\nâŒ API æª¢æŸ¥å¤±æ•—ï¼Œè«‹å…ˆè§£æ±º WebUI å•é¡Œ")
        return False
    
    # æ¸¬è©¦åœ–åƒç”Ÿæˆ
    if not test_basic_generation():
        print("\nâŒ åŸºæœ¬åœ–åƒç”Ÿæˆå¤±æ•—")
        return False
    
    # æ¸¬è©¦ CLIP
    if not test_clip_models():
        print("\nâŒ CLIP æ¨¡å‹æ¸¬è©¦å¤±æ•—")
        return False
    
    print("\n" + "=" * 50)
    print("âœ… æ‰€æœ‰æ¸¬è©¦é€šéï¼")
    print("ç¾åœ¨å¯ä»¥åŸ·è¡Œå®Œæ•´çš„ day2_enhanced_test.py")
    print("=" * 50)
    
    return True

if __name__ == "__main__":
    main()
    input("\næŒ‰ Enter éµçµæŸ...")
