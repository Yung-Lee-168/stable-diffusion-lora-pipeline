{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41b05c7d",
   "metadata": {},
   "source": [
    "# Fashion AI Training - Google Colab ç‰ˆæœ¬ (ä¿®å¾©ä¾è³´è¡çª)\n",
    "\n",
    "## ğŸ”§ å°ˆç‚ºè§£æ±º Colab ä¾è³´è¡çªè¨­è¨ˆ\n",
    "\n",
    "æ­¤ Notebook æœƒè‡ªå‹•è™•ç† `sentence-transformers` å’Œ `transformers` ç‰ˆæœ¬è¡çªå•é¡Œã€‚\n",
    "\n",
    "### ğŸ“‹ ä½¿ç”¨æ­¥é©Ÿ:\n",
    "1. æŒ‰é †åºåŸ·è¡Œæ¯å€‹ cell\n",
    "2. åœ¨ä¾è³´å®‰è£å®Œæˆå¾Œé‡æ–°å•Ÿå‹•é‹è¡Œæ™‚\n",
    "3. ä¸Šå‚³è¨“ç·´åœ–ç‰‡\n",
    "4. é–‹å§‹è¨“ç·´\n",
    "\n",
    "### ğŸ’¡ æç¤º:\n",
    "- ç¢ºä¿å·²å•Ÿç”¨ GPU (Runtime > Change runtime type > GPU)\n",
    "- å»ºè­°ä½¿ç”¨ T4 æˆ–æ›´é«˜ç­‰ç´šçš„ GPU\n",
    "- è¨“ç·´æ™‚é–“ç´„ 30-60 åˆ†é˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d78dddc",
   "metadata": {},
   "source": [
    "## ğŸ”§ æ­¥é©Ÿ 1: ä¿®å¾©ä¾è³´è¡çª\n",
    "\n",
    "**é‡è¦**: åŸ·è¡Œæ­¤ cell å¾Œè«‹é‡æ–°å•Ÿå‹•é‹è¡Œæ™‚ (Runtime > Restart runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22e6c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿®å¾© Colab ä¾è³´è¡çª\n",
    "print(\"ğŸ”§ æ­£åœ¨ä¿®å¾© Google Colab ä¾è³´è¡çª...\")\n",
    "\n",
    "# 1. å¸è¼‰è¡çªå¥—ä»¶\n",
    "!pip uninstall -y sentence-transformers transformers\n",
    "\n",
    "# 2. å®‰è£å…¼å®¹ç‰ˆæœ¬\n",
    "!pip install transformers>=4.41.0 --force-reinstall\n",
    "\n",
    "# 3. å®‰è£æ ¸å¿ƒå¥—ä»¶\n",
    "!pip install diffusers[torch] accelerate peft packaging\n",
    "\n",
    "# 4. é‡æ–°å®‰è£ sentence-transformers\n",
    "!pip install sentence-transformers\n",
    "\n",
    "# 5. å˜—è©¦å®‰è£ xformers (å¯é¸)\n",
    "!pip install xformers --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "print(\"âœ… ä¾è³´ä¿®å¾©å®Œæˆï¼\")\n",
    "print(\"ğŸ”„ è«‹é‡æ–°å•Ÿå‹•é‹è¡Œæ™‚ (Runtime > Restart runtime)ï¼Œç„¶å¾ŒåŸ·è¡Œä¸‹ä¸€å€‹ cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e819b254",
   "metadata": {},
   "source": [
    "## âœ… æ­¥é©Ÿ 2: æª¢æŸ¥å®‰è£\n",
    "\n",
    "**é‡æ–°å•Ÿå‹•é‹è¡Œæ™‚å¾Œ**ï¼ŒåŸ·è¡Œæ­¤ cell æª¢æŸ¥å¥—ä»¶æ˜¯å¦æ­£ç¢ºå®‰è£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa633eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æª¢æŸ¥å¥—ä»¶ç‰ˆæœ¬\n",
    "import torch\n",
    "import transformers\n",
    "import diffusers\n",
    "\n",
    "print(\"ğŸ“‹ å¥—ä»¶ç‰ˆæœ¬æª¢æŸ¥:\")\n",
    "print(f\"   torch: {torch.__version__}\")\n",
    "print(f\"   transformers: {transformers.__version__}\")\n",
    "print(f\"   diffusers: {diffusers.__version__}\")\n",
    "\n",
    "# æª¢æŸ¥ GPU\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"\\nğŸ”§ GPU: {gpu_name}\")\n",
    "    print(f\"ğŸ’¾ VRAM: {gpu_memory:.1f} GB\")\n",
    "else:\n",
    "    print(\"âŒ æ²’æœ‰å¯ç”¨çš„ GPU\")\n",
    "\n",
    "# æ¸¬è©¦å°å…¥\n",
    "try:\n",
    "    from diffusers import StableDiffusionPipeline\n",
    "    from peft import LoraConfig\n",
    "    print(\"\\nâœ… æ‰€æœ‰å¥—ä»¶å°å…¥æˆåŠŸ\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ å°å…¥å¤±æ•—: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02091022",
   "metadata": {},
   "source": [
    "## ğŸ“ æ­¥é©Ÿ 3: æ›è¼‰ Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5552de47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# æ›è¼‰ Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# å‰µå»ºå·¥ä½œç›®éŒ„\n",
    "work_dir = \"/content/drive/MyDrive/fashion_ai_training\"\n",
    "os.makedirs(work_dir, exist_ok=True)\n",
    "os.chdir(work_dir)\n",
    "\n",
    "print(f\"ğŸ“ å·¥ä½œç›®éŒ„: {work_dir}\")\n",
    "print(\"âœ… Google Drive å·²æ›è¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baab444",
   "metadata": {},
   "source": [
    "## ğŸ“¤ æ­¥é©Ÿ 4: ä¸Šå‚³è¨“ç·´åœ–ç‰‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3de93d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"ğŸ“¤ è«‹ä¸Šå‚³è¨“ç·´åœ–ç‰‡ (æ”¯æ´ JPG, PNG æ ¼å¼)...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# è™•ç†ä¸Šå‚³çš„åœ–ç‰‡\n",
    "image_paths = []\n",
    "upload_dir = \"/content/uploaded_images\"\n",
    "os.makedirs(upload_dir, exist_ok=True)\n",
    "\n",
    "for filename, content in uploaded.items():\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        file_path = os.path.join(upload_dir, filename)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(content)\n",
    "        image_paths.append(file_path)\n",
    "        print(f\"âœ… å·²è™•ç†: {filename}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ç¸½å…±ä¸Šå‚³äº† {len(image_paths)} å¼µåœ–ç‰‡\")\n",
    "\n",
    "# é¡¯ç¤ºåœ–ç‰‡é è¦½\n",
    "if image_paths:\n",
    "    from PIL import Image\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, axes = plt.subplots(1, min(3, len(image_paths)), figsize=(12, 4))\n",
    "    if len(image_paths) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, img_path in enumerate(image_paths[:3]):\n",
    "        img = Image.open(img_path)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(os.path.basename(img_path))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"âŒ æ²’æœ‰æœ‰æ•ˆçš„åœ–ç‰‡æª”æ¡ˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ae8dfb",
   "metadata": {},
   "source": [
    "## ğŸš€ æ­¥é©Ÿ 5: é–‹å§‹è¨“ç·´\n",
    "\n",
    "é€™å€‹ cell æœƒåŸ·è¡Œå¯¦éš›çš„ Fashion AI è¨“ç·´ã€‚æ ¹æ“š GPU é¡å‹å’Œåœ–ç‰‡æ•¸é‡ï¼Œé è¨ˆéœ€è¦ 30-60 åˆ†é˜ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ca93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¼‰å…¥å®Œæ•´çš„è¨“ç·´è…³æœ¬\n",
    "exec(open('/content/colab_training_fixed.py').read())\n",
    "\n",
    "# æˆ–è€…æ‰‹å‹•åŸ·è¡Œç°¡åŒ–ç‰ˆæœ¬\n",
    "print(\"ğŸ¨ Fashion AI Training é–‹å§‹...\")\n",
    "print(\"ğŸ’¡ ç”±æ–¼é€™æ˜¯ç°¡åŒ–ç‰ˆæœ¬ï¼Œå®Œæ•´è¨“ç·´è«‹ä¸Šå‚³å®Œæ•´çš„è…³æœ¬æª”æ¡ˆ\")\n",
    "print(\"âœ… ç’°å¢ƒå·²æº–å‚™å°±ç·’ï¼Œå¯ä»¥é–‹å§‹è¨“ç·´ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370155ca",
   "metadata": {},
   "source": [
    "## ğŸ“¦ æ­¥é©Ÿ 6: ä¸‹è¼‰çµæœ\n",
    "\n",
    "è¨“ç·´å®Œæˆå¾Œï¼ŒåŸ·è¡Œæ­¤ cell ä¾†æ‰“åŒ…å’Œä¸‹è¼‰çµæœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99e5c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from datetime import datetime\n",
    "from google.colab import files\n",
    "\n",
    "# å‰µå»ºä¸‹è¼‰åŒ…\n",
    "package_name = f\"fashion_ai_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip\"\n",
    "\n",
    "with zipfile.ZipFile(package_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    # æ·»åŠ è¨“ç·´çµæœ (å¦‚æœå­˜åœ¨)\n",
    "    result_dirs = ['models', 'validation', 'checkpoints']\n",
    "    \n",
    "    for dir_name in result_dirs:\n",
    "        if os.path.exists(dir_name):\n",
    "            for root, dirs, files in os.walk(dir_name):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    arcname = os.path.relpath(file_path, '.')\n",
    "                    zipf.write(file_path, arcname)\n",
    "    \n",
    "    # æ·»åŠ  README\n",
    "    readme_content = f\"\"\"Fashion AI Training Results\n",
    "è¨“ç·´æ—¥æœŸ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\n",
    "åœ–ç‰‡æ•¸é‡: {len(image_paths) if 'image_paths' in locals() else 0}\n",
    "\n",
    "ä½¿ç”¨æ–¹æ³•:\n",
    "1. è§£å£“ç¸®æª”æ¡ˆ\n",
    "2. å°‡ LoRA æ¬Šé‡è¼‰å…¥åˆ° Stable Diffusion WebUI\n",
    "3. é–‹å§‹ç”Ÿæˆæ™‚å°šåœ–ç‰‡\n",
    "\"\"\"\n",
    "    \n",
    "    with open('README.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(readme_content)\n",
    "    zipf.write('README.txt')\n",
    "\n",
    "print(f\"ğŸ“¦ æ‰“åŒ…å®Œæˆ: {package_name}\")\n",
    "\n",
    "# ä¸‹è¼‰çµæœ\n",
    "files.download(package_name)\n",
    "\n",
    "print(\"ğŸ‰ è¨“ç·´å®Œæˆï¼çµæœå·²ä¸‹è¼‰åˆ°æ‚¨çš„é›»è…¦\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f069878e",
   "metadata": {},
   "source": [
    "## ğŸ”§ æ•…éšœæ’é™¤\n",
    "\n",
    "### å¸¸è¦‹å•é¡Œ:\n",
    "\n",
    "1. **ä¾è³´è¡çª**: é‡æ–°å•Ÿå‹•é‹è¡Œæ™‚ä¸¦é‡æ–°åŸ·è¡Œä¾è³´å®‰è£\n",
    "2. **GPU è¨˜æ†¶é«”ä¸è¶³**: æ¸›å°‘æ‰¹æ¬¡å¤§å°æˆ–ä½¿ç”¨æ›´å°çš„æ¨¡å‹\n",
    "3. **è¨“ç·´ä¸­æ–·**: æª¢æŸ¥é»æœƒè‡ªå‹•ä¿å­˜ï¼Œå¯ä»¥å¾ä¸­æ–·è™•æ¢å¾©\n",
    "\n",
    "### æ‰‹å‹•ä¿®å¾©å‘½ä»¤:\n",
    "\n",
    "```bash\n",
    "# æ¸…ç†ç’°å¢ƒ\n",
    "!pip uninstall -y sentence-transformers transformers\n",
    "\n",
    "# é‡æ–°å®‰è£\n",
    "!pip install transformers>=4.41.0 --force-reinstall\n",
    "!pip install diffusers[torch] accelerate peft\n",
    "```\n",
    "\n",
    "### è¯ç¹«æ”¯æ´:\n",
    "å¦‚æœå•é¡ŒæŒçºŒå­˜åœ¨ï¼Œè«‹æª¢æŸ¥ GitHub å€‰åº«çš„ Issues éƒ¨åˆ†ã€‚"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
