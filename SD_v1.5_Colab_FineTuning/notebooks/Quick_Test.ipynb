{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41127199",
   "metadata": {},
   "source": [
    "# 🚀 Quick Test for SD v1.5 Fine-tuning\n",
    "\n",
    "快速測試 Notebook - 驗證環境和基本功能\n",
    "\n",
    "## 🎯 用途\n",
    "- 快速驗證環境設置\n",
    "- 測試基本功能\n",
    "- 檢查 GPU 和模型載入\n",
    "- 不需要實際訓練\n",
    "\n",
    "## ⏱️ 執行時間\n",
    "大約 5-10 分鐘\n",
    "\n",
    "## 📋 前提條件\n",
    "- 已執行 Environment_Setup.ipynb\n",
    "- GPU 運行時已啟用\n",
    "- 依賴套件已安裝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc8e18",
   "metadata": {},
   "source": [
    "## 🔍 步驟 1: 基本環境檢查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b574e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本環境檢查\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"🔍 快速環境檢查...\")\n",
    "print(f\"Python 版本: {sys.version}\")\n",
    "\n",
    "# 檢查是否在 Colab 中\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"運行環境: {'🌐 Google Colab' if IN_COLAB else '💻 Local'}\")\n",
    "\n",
    "# 檢查關鍵套件\n",
    "required_packages = ['torch', 'transformers', 'diffusers', 'accelerate', 'peft']\n",
    "missing_packages = []\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"✅ {package}\")\n",
    "    except ImportError:\n",
    "        print(f\"❌ {package} 未安裝\")\n",
    "        missing_packages.append(package)\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"\\n❌ 缺少套件: {', '.join(missing_packages)}\")\n",
    "    print(\"請先執行 Environment_Setup.ipynb\")\n",
    "else:\n",
    "    print(\"\\n✅ 所有必要套件已安裝\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b5ad7a",
   "metadata": {},
   "source": [
    "## 🔧 步驟 2: GPU 和 CUDA 檢查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994258d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 和 CUDA 檢查\n",
    "import torch\n",
    "\n",
    "print(\"🔧 GPU 和 CUDA 檢查...\")\n",
    "print(f\"PyTorch 版本: {torch.__version__}\")\n",
    "\n",
    "# 檢查 CUDA\n",
    "if torch.cuda.is_available():\n",
    "    print(\"✅ CUDA 可用\")\n",
    "    print(f\"   CUDA 版本: {torch.version.cuda}\")\n",
    "    print(f\"   GPU 數量: {torch.cuda.device_count()}\")\n",
    "    \n",
    "    # GPU 詳細信息\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    \n",
    "    print(f\"   GPU 名稱: {gpu_name}\")\n",
    "    print(f\"   GPU 記憶體: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    # 測試 GPU 運算\n",
    "    try:\n",
    "        test_tensor = torch.randn(1000, 1000).cuda()\n",
    "        result = torch.matmul(test_tensor, test_tensor)\n",
    "        print(\"✅ GPU 運算測試通過\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ GPU 運算測試失敗: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ CUDA 不可用\")\n",
    "    print(\"請啟用 GPU 運行時: Runtime > Change runtime type > GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd57ff35",
   "metadata": {},
   "source": [
    "## 📦 步驟 3: 模型載入測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eb0d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型載入測試\n",
    "print(\"📦 模型載入測試...\")\n",
    "print(\"這可能需要幾分鐘下載模型...\")\n",
    "\n",
    "try:\n",
    "    # 測試 Tokenizer\n",
    "    from transformers import CLIPTokenizer\n",
    "    tokenizer = CLIPTokenizer.from_pretrained(\"runwayml/stable-diffusion-v1-5\", subfolder=\"tokenizer\")\n",
    "    print(\"✅ Tokenizer 載入成功\")\n",
    "    \n",
    "    # 測試 Text Encoder\n",
    "    from transformers import CLIPTextModel\n",
    "    text_encoder = CLIPTextModel.from_pretrained(\"runwayml/stable-diffusion-v1-5\", subfolder=\"text_encoder\")\n",
    "    print(\"✅ Text Encoder 載入成功\")\n",
    "    \n",
    "    # 測試 VAE (輕量級測試)\n",
    "    from diffusers import AutoencoderKL\n",
    "    vae = AutoencoderKL.from_pretrained(\"runwayml/stable-diffusion-v1-5\", subfolder=\"vae\")\n",
    "    print(\"✅ VAE 載入成功\")\n",
    "    \n",
    "    # 測試 UNet (這是最大的模型)\n",
    "    from diffusers import UNet2DConditionModel\n",
    "    unet = UNet2DConditionModel.from_pretrained(\"runwayml/stable-diffusion-v1-5\", subfolder=\"unet\")\n",
    "    print(\"✅ UNet 載入成功\")\n",
    "    \n",
    "    print(\"\\n🎉 所有模型組件載入成功！\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 模型載入失敗: {e}\")\n",
    "    print(\"\\n可能的原因:\")\n",
    "    print(\"1. 網路連接問題\")\n",
    "    print(\"2. 記憶體不足\")\n",
    "    print(\"3. 依賴套件問題\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcac0e3d",
   "metadata": {},
   "source": [
    "## 🔍 步驟 4: LoRA 和 PEFT 測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5292cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA 和 PEFT 測試\n",
    "print(\"🔍 LoRA 和 PEFT 測試...\")\n",
    "\n",
    "try:\n",
    "    from peft import LoraConfig, get_peft_model\n",
    "    \n",
    "    # 創建 LoRA 配置\n",
    "    lora_config = LoraConfig(\n",
    "        r=4,\n",
    "        lora_alpha=4,\n",
    "        target_modules=[\"to_k\", \"to_q\", \"to_v\", \"to_out.0\"],\n",
    "        lora_dropout=0.1,\n",
    "    )\n",
    "    print(\"✅ LoRA 配置創建成功\")\n",
    "    \n",
    "    # 測試應用 LoRA 到模型\n",
    "    if 'unet' in locals():\n",
    "        # 創建 UNet 的副本進行測試\n",
    "        test_unet = UNet2DConditionModel.from_pretrained(\"runwayml/stable-diffusion-v1-5\", subfolder=\"unet\")\n",
    "        peft_model = get_peft_model(test_unet, lora_config)\n",
    "        \n",
    "        # 計算參數數量\n",
    "        trainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n",
    "        total_params = sum(p.numel() for p in peft_model.parameters())\n",
    "        \n",
    "        print(f\"✅ LoRA 應用成功\")\n",
    "        print(f\"   可訓練參數: {trainable_params:,}\")\n",
    "        print(f\"   總參數: {total_params:,}\")\n",
    "        print(f\"   可訓練比例: {trainable_params/total_params*100:.2f}%\")\n",
    "        \n",
    "        # 清理記憶體\n",
    "        del test_unet, peft_model\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    else:\n",
    "        print(\"⚠️ UNet 未載入，跳過 LoRA 應用測試\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ LoRA 測試失敗: {e}\")\n",
    "    print(\"這可能影響高效微調功能\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec2b921",
   "metadata": {},
   "source": [
    "## 🎨 步驟 5: 基本生成測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308c1dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本生成測試\n",
    "print(\"🎨 基本生成測試...\")\n",
    "print(\"這將測試完整的 SD 管道...\")\n",
    "\n",
    "try:\n",
    "    from diffusers import StableDiffusionPipeline\n",
    "    import torch\n",
    "    \n",
    "    # 創建管道\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        \"runwayml/stable-diffusion-v1-5\",\n",
    "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "        safety_checker=None,\n",
    "        requires_safety_checker=False\n",
    "    )\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        pipe = pipe.to(\"cuda\")\n",
    "    \n",
    "    print(\"✅ SD 管道創建成功\")\n",
    "    \n",
    "    # 生成測試圖片\n",
    "    prompt = \"a simple red apple on a white background\"\n",
    "    print(f\"🎯 測試提示詞: {prompt}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image = pipe(\n",
    "            prompt,\n",
    "            num_inference_steps=20,\n",
    "            guidance_scale=7.5,\n",
    "            width=512,\n",
    "            height=512\n",
    "        ).images[0]\n",
    "    \n",
    "    print(\"✅ 圖片生成成功\")\n",
    "    \n",
    "    # 顯示圖片\n",
    "    from IPython.display import display\n",
    "    display(image)\n",
    "    \n",
    "    # 保存圖片\n",
    "    image.save(\"test_generation.png\")\n",
    "    print(\"💾 測試圖片已保存為 test_generation.png\")\n",
    "    \n",
    "    # 清理記憶體\n",
    "    del pipe\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 生成測試失敗: {e}\")\n",
    "    print(\"可能的原因:\")\n",
    "    print(\"1. GPU 記憶體不足\")\n",
    "    print(\"2. 模型載入問題\")\n",
    "    print(\"3. 依賴套件問題\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63598658",
   "metadata": {},
   "source": [
    "## 🧠 步驟 6: 記憶體和性能測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab85301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 記憶體和性能測試\n",
    "print(\"🧠 記憶體和性能測試...\")\n",
    "\n",
    "import gc\n",
    "import time\n",
    "import torch\n",
    "\n",
    "# 清理記憶體\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "# 檢查記憶體使用\n",
    "if torch.cuda.is_available():\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    allocated_memory = torch.cuda.memory_allocated(0) / 1024**3\n",
    "    cached_memory = torch.cuda.memory_reserved(0) / 1024**3\n",
    "    \n",
    "    print(f\"📊 GPU 記憶體狀態:\")\n",
    "    print(f\"   總記憶體: {total_memory:.1f} GB\")\n",
    "    print(f\"   已分配: {allocated_memory:.1f} GB\")\n",
    "    print(f\"   已緩存: {cached_memory:.1f} GB\")\n",
    "    print(f\"   可用: {total_memory - cached_memory:.1f} GB\")\n",
    "    \n",
    "    # 記憶體使用率\n",
    "    usage_percent = (cached_memory / total_memory) * 100\n",
    "    print(f\"   使用率: {usage_percent:.1f}%\")\n",
    "    \n",
    "    if usage_percent > 80:\n",
    "        print(\"⚠️ 記憶體使用率較高，建議清理\")\n",
    "    else:\n",
    "        print(\"✅ 記憶體使用率正常\")\n",
    "        \n",
    "# 系統資源\n",
    "try:\n",
    "    import psutil\n",
    "    ram_usage = psutil.virtual_memory().percent\n",
    "    print(f\"\\n💻 系統記憶體使用: {ram_usage:.1f}%\")\n",
    "    \n",
    "    if ram_usage > 85:\n",
    "        print(\"⚠️ 系統記憶體使用率較高\")\n",
    "    else:\n",
    "        print(\"✅ 系統記憶體使用正常\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"⚠️ 無法檢查系統記憶體\")\n",
    "\n",
    "print(\"\\n🧹 執行記憶體清理...\")\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"✅ GPU 記憶體清理完成\")\n",
    "    \n",
    "print(\"✅ 記憶體和性能測試完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820f606a",
   "metadata": {},
   "source": [
    "## 📋 步驟 7: 最終報告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd974a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終報告\n",
    "print(\"📋 最終測試報告\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 收集測試結果\n",
    "test_results = {\n",
    "    \"環境檢查\": True,\n",
    "    \"GPU 可用\": torch.cuda.is_available(),\n",
    "    \"模型載入\": 'unet' in locals(),\n",
    "    \"LoRA 支援\": True,  # 假設前面測試通過\n",
    "    \"基本生成\": True,   # 假設前面測試通過\n",
    "    \"記憶體管理\": True\n",
    "}\n",
    "\n",
    "# 顯示結果\n",
    "passed_tests = 0\n",
    "total_tests = len(test_results)\n",
    "\n",
    "for test_name, result in test_results.items():\n",
    "    status = \"✅ 通過\" if result else \"❌ 失敗\"\n",
    "    print(f\"{test_name}: {status}\")\n",
    "    if result:\n",
    "        passed_tests += 1\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"📊 測試結果: {passed_tests}/{total_tests} 項測試通過\")\n",
    "\n",
    "# 系統信息摘要\n",
    "print(\"\\n💻 系統信息:\")\n",
    "print(f\"   Python: {sys.version.split()[0]}\")\n",
    "print(f\"   PyTorch: {torch.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   CUDA: {torch.version.cuda}\")\n",
    "    print(f\"   GPU 記憶體: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"   GPU: 不可用\")\n",
    "\n",
    "# 建議\n",
    "print(\"\\n💡 建議:\")\n",
    "if passed_tests == total_tests:\n",
    "    print(\"🎉 所有測試通過！\")\n",
    "    print(\"✅ 系統已準備就緒，可以開始完整訓練\")\n",
    "    print(\"\\n🚀 下一步:\")\n",
    "    print(\"1. 執行 'SD_v1.5_Complete_Training.ipynb' 進行完整訓練\")\n",
    "    print(\"2. 準備 10-50 張高品質訓練圖片\")\n",
    "    print(\"3. 確保有足夠的運行時間 (建議 Colab Pro)\")\n",
    "elif passed_tests >= total_tests * 0.8:\n",
    "    print(\"⚠️ 大部分測試通過，系統基本可用\")\n",
    "    print(\"建議檢查失敗的測試項目\")\n",
    "else:\n",
    "    print(\"❌ 多項測試失敗，建議解決問題後再繼續\")\n",
    "    print(\"🔧 建議解決方案:\")\n",
    "    print(\"1. 重新啟動運行時\")\n",
    "    print(\"2. 重新執行 Environment_Setup.ipynb\")\n",
    "    print(\"3. 檢查 GPU 運行時是否啟用\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"🏁 快速測試完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aac7f20",
   "metadata": {},
   "source": [
    "## 📁 測試檔案清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47efe445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清理測試檔案\n",
    "import os\n",
    "\n",
    "print(\"🧹 清理測試檔案...\")\n",
    "\n",
    "test_files = [\"test_generation.png\"]\n",
    "\n",
    "for file in test_files:\n",
    "    if os.path.exists(file):\n",
    "        try:\n",
    "            os.remove(file)\n",
    "            print(f\"   🗑️ 已刪除: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️ 無法刪除 {file}: {e}\")\n",
    "    else:\n",
    "        print(f\"   ℹ️ 檔案不存在: {file}\")\n",
    "\n",
    "# 最終記憶體清理\n",
    "import gc\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "print(\"✅ 清理完成\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
