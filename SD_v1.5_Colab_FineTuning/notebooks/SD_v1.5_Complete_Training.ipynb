{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feb1cc73",
   "metadata": {},
   "source": [
    "# ğŸ¨ SD v1.5 Complete Training on Google Colab\n",
    "\n",
    "å®Œæ•´çš„ Stable Diffusion v1.5 å¾®èª¿è¨“ç·´æµç¨‹ï¼Œå°ˆç‚º Google Colab å„ªåŒ–ã€‚\n",
    "\n",
    "## ğŸ“‹ åŠŸèƒ½ç‰¹è‰²\n",
    "- ğŸ”§ è‡ªå‹•ç’°å¢ƒè¨­ç½®èˆ‡ä¾è³´ä¿®å¾©\n",
    "- ğŸ¯ æ”¯æ´ LoRA é«˜æ•ˆå¾®èª¿\n",
    "- ğŸ“Š FashionCLIP ç‰¹å¾µæå–\n",
    "- ğŸ’¾ è‡ªå‹•ä¿å­˜èˆ‡å‚™ä»½\n",
    "- ğŸ“ˆ å¯¦æ™‚è¨“ç·´ç›£æ§\n",
    "- ğŸš€ å¤š GPU é…ç½®å„ªåŒ–\n",
    "\n",
    "## âš ï¸ ä½¿ç”¨å‰é ˆçŸ¥\n",
    "1. ç¢ºä¿å·²å•Ÿç”¨ GPU é‹è¡Œæ™‚ (Runtime > Change runtime type > GPU)\n",
    "2. å»ºè­°ä½¿ç”¨ Colab Pro ä»¥ç²å¾—æ›´å¥½çš„ GPU å’Œæ›´é•·çš„é‹è¡Œæ™‚é–“\n",
    "3. æº–å‚™å¥½è¨“ç·´åœ–ç‰‡ï¼ˆå»ºè­° 10-50 å¼µé«˜å“è³ªåœ–ç‰‡ï¼‰\n",
    "\n",
    "## ğŸ”„ åŸ·è¡Œé †åº\n",
    "è«‹æŒ‰é †åºåŸ·è¡Œä»¥ä¸‹æ‰€æœ‰å–®å…ƒæ ¼ï¼Œä¸è¦è·³éä»»ä½•æ­¥é©Ÿã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cf2268",
   "metadata": {},
   "source": [
    "## ğŸ”§ æ­¥é©Ÿ 1: ç’°å¢ƒæª¢æŸ¥èˆ‡åˆå§‹åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc080dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æª¢æŸ¥é‹è¡Œç’°å¢ƒ\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "print(\"ğŸ” ç’°å¢ƒæª¢æŸ¥ä¸­...\")\n",
    "print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
    "print(f\"ç•¶å‰ç›®éŒ„: {os.getcwd()}\")\n",
    "\n",
    "# æª¢æŸ¥ GPU\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"âœ… GPU å·²å•Ÿç”¨\")\n",
    "        print(result.stdout.split('\\n')[8:10])  # é¡¯ç¤º GPU ä¿¡æ¯\n",
    "    else:\n",
    "        print(\"âŒ GPU æœªå•Ÿç”¨ï¼Œè«‹å•Ÿç”¨ GPU é‹è¡Œæ™‚\")\n",
    "        print(\"æ“ä½œ: Runtime > Change runtime type > Hardware accelerator > GPU\")\n",
    "except:\n",
    "    print(\"âš ï¸ ç„¡æ³•æª¢æŸ¥ GPU ç‹€æ…‹\")\n",
    "\n",
    "# æª¢æŸ¥æ˜¯å¦åœ¨ Colab ä¸­\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"é‹è¡Œç’°å¢ƒ: {'ğŸŒ Google Colab' if IN_COLAB else 'ğŸ’» Local Environment'}\")\n",
    "\n",
    "if not IN_COLAB:\n",
    "    print(\"âš ï¸ æ­¤ Notebook å°ˆç‚º Google Colab è¨­è¨ˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca1afa7",
   "metadata": {},
   "source": [
    "## ğŸ“¦ æ­¥é©Ÿ 2: ä¾è³´å®‰è£èˆ‡ä¿®å¾©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb4477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è‡ªå‹•ä¾è³´ä¿®å¾©è…³æœ¬\n",
    "print(\"ğŸ”§ é–‹å§‹ä¾è³´å®‰è£èˆ‡ä¿®å¾©...\")\n",
    "print(\"é€™å¯èƒ½éœ€è¦ 5-10 åˆ†é˜ï¼Œè«‹è€å¿ƒç­‰å¾…...\")\n",
    "\n",
    "# å¸è¼‰å¯èƒ½è¡çªçš„å¥—ä»¶\n",
    "conflicting_packages = [\n",
    "    \"sentence-transformers\", \n",
    "    \"transformers\", \n",
    "    \"torch\", \n",
    "    \"torchvision\", \n",
    "    \"torchaudio\",\n",
    "    \"fastai\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ—‘ï¸ æ¸…ç†èˆŠç‰ˆæœ¬å¥—ä»¶...\")\n",
    "for package in conflicting_packages:\n",
    "    try:\n",
    "        !pip uninstall -y {package} -q\n",
    "        print(f\"   ğŸ—‘ï¸ {package}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"ğŸ“¦ å®‰è£ PyTorch ç”Ÿæ…‹ç³»çµ±...\")\n",
    "!pip install torch==2.1.0+cu118 torchvision==0.16.0+cu118 torchaudio==2.1.0+cu118 \\\n",
    "    --index-url https://download.pytorch.org/whl/cu118 --force-reinstall -q\n",
    "\n",
    "print(\"ğŸ“¦ å®‰è£ Transformers...\")\n",
    "!pip install \"transformers>=4.41.0,<5.0.0\" --force-reinstall -q\n",
    "\n",
    "print(\"ğŸ“¦ å®‰è£å…¶ä»–ä¾è³´...\")\n",
    "!pip install diffusers[torch] accelerate \"peft>=0.4.0\" packaging \\\n",
    "    matplotlib seaborn numpy pillow scikit-learn -q\n",
    "\n",
    "print(\"ğŸ“¦ å®‰è£ sentence-transformers...\")\n",
    "!pip install sentence-transformers -q\n",
    "\n",
    "print(\"ğŸ“¦ å˜—è©¦å®‰è£ xformersï¼ˆå¯é¸ï¼‰...\")\n",
    "try:\n",
    "    !pip install xformers==0.0.22.post7 --index-url https://download.pytorch.org/whl/cu118 -q\n",
    "    print(\"âœ… xformers å®‰è£æˆåŠŸ\")\n",
    "except:\n",
    "    print(\"âš ï¸ xformers å®‰è£å¤±æ•—ï¼ˆå°‡ä½¿ç”¨æ¨™æº–æ³¨æ„åŠ›æ©Ÿåˆ¶ï¼‰\")\n",
    "\n",
    "print(\"âœ… ä¾è³´å®‰è£å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e783cdea",
   "metadata": {},
   "source": [
    "## ğŸ” æ­¥é©Ÿ 3: é©—è­‰å®‰è£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e772bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é©—è­‰é—œéµå¥—ä»¶å®‰è£\n",
    "print(\"ğŸ” é©—è­‰å®‰è£ç‹€æ…‹...\")\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import transformers\n",
    "    import diffusers\n",
    "    \n",
    "    print(f\"âœ… torch: {torch.__version__}\")\n",
    "    print(f\"âœ… transformers: {transformers.__version__}\")\n",
    "    print(f\"âœ… diffusers: {diffusers.__version__}\")\n",
    "    \n",
    "    # æª¢æŸ¥ CUDA\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"âœ… CUDA å¯ç”¨: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"âœ… CUDA ç‰ˆæœ¬: {torch.version.cuda}\")\n",
    "        print(f\"âœ… GPU è¨˜æ†¶é«”: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    else:\n",
    "        print(\"âŒ CUDA ä¸å¯ç”¨\")\n",
    "    \n",
    "    # æ¸¬è©¦é—œéµå°å…¥\n",
    "    from diffusers import StableDiffusionPipeline\n",
    "    from peft import LoraConfig\n",
    "    print(\"âœ… é—œéµå¥—ä»¶å°å…¥æ¸¬è©¦é€šé\")\n",
    "    \n",
    "    print(\"\\nğŸ‰ æ‰€æœ‰æª¢æŸ¥é€šéï¼Œå¯ä»¥é–‹å§‹è¨“ç·´ï¼\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"âŒ å°å…¥éŒ¯èª¤: {e}\")\n",
    "    print(\"è«‹é‡æ–°å•Ÿå‹•é‹è¡Œæ™‚ä¸¦é‡æ–°åŸ·è¡Œå‰é¢çš„æ­¥é©Ÿ\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ å…¶ä»–éŒ¯èª¤: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dd0c2f",
   "metadata": {},
   "source": [
    "## ğŸ’¾ æ­¥é©Ÿ 4: Google Drive è¨­ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff5ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ›è¼‰ Google Drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "print(\"ğŸ“ æ›è¼‰ Google Drive...\")\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# å‰µå»ºå·¥ä½œç›®éŒ„\n",
    "work_dir = \"/content/drive/MyDrive/SD_v1.5_Training\"\n",
    "os.makedirs(work_dir, exist_ok=True)\n",
    "os.chdir(work_dir)\n",
    "\n",
    "print(f\"ğŸ“‚ å·¥ä½œç›®éŒ„: {work_dir}\")\n",
    "print(f\"ğŸ“ ç•¶å‰ç›®éŒ„: {os.getcwd()}\")\n",
    "\n",
    "# å‰µå»ºå­ç›®éŒ„\n",
    "subdirs = ['models', 'checkpoints', 'validation', 'logs', 'uploaded_images']\n",
    "for subdir in subdirs:\n",
    "    os.makedirs(subdir, exist_ok=True)\n",
    "    print(f\"ğŸ“ å‰µå»ºç›®éŒ„: {subdir}\")\n",
    "\n",
    "print(\"âœ… Google Drive è¨­ç½®å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45911d80",
   "metadata": {},
   "source": [
    "## ğŸ¯ æ­¥é©Ÿ 5: è¼‰å…¥ä¸»è¦è¨“ç·´è…³æœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3f54e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¦‚æœéœ€è¦ï¼Œä¸Šå‚³ä¸»è¦è¨“ç·´è…³æœ¬\n",
    "# é€™è£¡æˆ‘å€‘ç›´æ¥å®šç¾©æ ¸å¿ƒé¡åˆ¥å’Œå‡½æ•¸\n",
    "\n",
    "print(\"ğŸ“¥ è¼‰å…¥è¨“ç·´è…³æœ¬...\")\n",
    "\n",
    "# é€™è£¡å¯ä»¥é¸æ“‡:\n",
    "# 1. ä¸Šå‚³ main_training_script.py æ–‡ä»¶\n",
    "# 2. æˆ–è€…ç›´æ¥åœ¨ä¸‹é¢çš„å–®å…ƒæ ¼ä¸­å®šç¾©æ‰€éœ€çš„é¡åˆ¥\n",
    "\n",
    "# æ–¹æ³• 1: ä¸Šå‚³æ–‡ä»¶\n",
    "from google.colab import files\n",
    "print(\"è«‹ä¸Šå‚³ main_training_script.py æ–‡ä»¶:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if 'main_training_script.py' in uploaded:\n",
    "    print(\"âœ… è¨“ç·´è…³æœ¬ä¸Šå‚³æˆåŠŸ\")\n",
    "    # å°å…¥ä¸»è¦é¡åˆ¥\n",
    "    exec(open('main_training_script.py').read())\n",
    "    print(\"âœ… è¨“ç·´è…³æœ¬è¼‰å…¥å®Œæˆ\")\n",
    "else:\n",
    "    print(\"âŒ æœªæ‰¾åˆ° main_training_script.py\")\n",
    "    print(\"è«‹ç¢ºä¿ä¸Šå‚³äº†æ­£ç¢ºçš„æ–‡ä»¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10658096",
   "metadata": {},
   "source": [
    "## ğŸ“¤ æ­¥é©Ÿ 6: ä¸Šå‚³è¨“ç·´åœ–ç‰‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046641d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸Šå‚³è¨“ç·´åœ–ç‰‡\n",
    "from google.colab import files\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "print(\"ğŸ“¤ ä¸Šå‚³è¨“ç·´åœ–ç‰‡...\")\n",
    "print(\"å»ºè­°ä¸Šå‚³ 10-50 å¼µé«˜å“è³ªåœ–ç‰‡ï¼ˆJPG/PNG æ ¼å¼ï¼‰\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "# è™•ç†ä¸Šå‚³çš„åœ–ç‰‡\n",
    "image_paths = []\n",
    "upload_dir = \"uploaded_images\"\n",
    "\n",
    "for filename, content in uploaded.items():\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        file_path = os.path.join(upload_dir, filename)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(content)\n",
    "        \n",
    "        # é©—è­‰åœ–ç‰‡\n",
    "        try:\n",
    "            img = Image.open(file_path)\n",
    "            img.verify()\n",
    "            image_paths.append(file_path)\n",
    "            print(f\"âœ… {filename} ({img.size})\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ {filename} ç„¡æ•ˆ: {e}\")\n",
    "            os.remove(file_path)\n",
    "    else:\n",
    "        print(f\"âš ï¸ è·³ééåœ–ç‰‡æ–‡ä»¶: {filename}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š æˆåŠŸä¸Šå‚³ {len(image_paths)} å¼µåœ–ç‰‡\")\n",
    "\n",
    "if len(image_paths) == 0:\n",
    "    print(\"âŒ æ²’æœ‰æœ‰æ•ˆçš„åœ–ç‰‡ï¼Œè«‹é‡æ–°ä¸Šå‚³\")\n",
    "else:\n",
    "    print(\"âœ… åœ–ç‰‡ä¸Šå‚³å®Œæˆï¼Œå¯ä»¥é–‹å§‹è¨“ç·´\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daba1f1",
   "metadata": {},
   "source": [
    "## ğŸ”§ æ­¥é©Ÿ 7: è¨“ç·´é…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bc56ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨“ç·´é…ç½®\n",
    "import torch\n",
    "\n",
    "print(\"ğŸ”§ é…ç½®è¨“ç·´åƒæ•¸...\")\n",
    "\n",
    "# æª¢æŸ¥ GPU é¡å‹ä¸¦è‡ªå‹•é…ç½®\n",
    "gpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"\n",
    "gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3 if torch.cuda.is_available() else 0\n",
    "\n",
    "print(f\"ğŸ¯ æª¢æ¸¬åˆ° GPU: {gpu_name}\")\n",
    "print(f\"ğŸ’¾ GPU è¨˜æ†¶é«”: {gpu_memory:.1f} GB\")\n",
    "\n",
    "# æ ¹æ“š GPU è‡ªå‹•é…ç½®\n",
    "if \"T4\" in gpu_name:\n",
    "    config = {\n",
    "        \"train_batch_size\": 1,\n",
    "        \"gradient_accumulation_steps\": 8,\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"num_epochs\": 10,\n",
    "        \"lora_rank\": 4,\n",
    "        \"mixed_precision\": \"fp16\",\n",
    "        \"image_size\": 512\n",
    "    }\n",
    "    print(\"ğŸ“‹ ä½¿ç”¨ T4 å„ªåŒ–é…ç½®\")\n",
    "    \n",
    "elif \"V100\" in gpu_name:\n",
    "    config = {\n",
    "        \"train_batch_size\": 2,\n",
    "        \"gradient_accumulation_steps\": 4,\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"num_epochs\": 15,\n",
    "        \"lora_rank\": 8,\n",
    "        \"mixed_precision\": \"fp16\",\n",
    "        \"image_size\": 512\n",
    "    }\n",
    "    print(\"ğŸ“‹ ä½¿ç”¨ V100 å„ªåŒ–é…ç½®\")\n",
    "    \n",
    "elif \"A100\" in gpu_name:\n",
    "    config = {\n",
    "        \"train_batch_size\": 4,\n",
    "        \"gradient_accumulation_steps\": 2,\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"num_epochs\": 20,\n",
    "        \"lora_rank\": 16,\n",
    "        \"mixed_precision\": \"fp16\",\n",
    "        \"image_size\": 768\n",
    "    }\n",
    "    print(\"ğŸ“‹ ä½¿ç”¨ A100 å„ªåŒ–é…ç½®\")\n",
    "    \n",
    "else:\n",
    "    # é€šç”¨é…ç½®\n",
    "    config = {\n",
    "        \"train_batch_size\": 1,\n",
    "        \"gradient_accumulation_steps\": 4,\n",
    "        \"learning_rate\": 5e-5,\n",
    "        \"num_epochs\": 5,\n",
    "        \"lora_rank\": 4,\n",
    "        \"mixed_precision\": \"fp16\",\n",
    "        \"image_size\": 512\n",
    "    }\n",
    "    print(\"ğŸ“‹ ä½¿ç”¨é€šç”¨é…ç½®\")\n",
    "\n",
    "# é¡¯ç¤ºé…ç½®\n",
    "print(\"\\nğŸ“Š è¨“ç·´é…ç½®:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(\"\\nâœ… é…ç½®å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af08081",
   "metadata": {},
   "source": [
    "## ğŸš€ æ­¥é©Ÿ 8: é–‹å§‹è¨“ç·´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f8bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é–‹å§‹è¨“ç·´\n",
    "print(\"ğŸš€ é–‹å§‹ SD v1.5 å¾®èª¿è¨“ç·´...\")\n",
    "print(\"é€™å¯èƒ½éœ€è¦ 30-60 åˆ†é˜ï¼Œè«‹ä¿æŒ Colab æ´»èºç‹€æ…‹\")\n",
    "\n",
    "try:\n",
    "    # åˆå§‹åŒ–è¨“ç·´å™¨\n",
    "    trainer = FashionSDFineTuner(config)\n",
    "    \n",
    "    # æå–ç‰¹å¾µ\n",
    "    print(\"\\nğŸ” æå–åœ–ç‰‡ç‰¹å¾µ...\")\n",
    "    captions = trainer.extract_features_from_images(image_paths)\n",
    "    \n",
    "    # æº–å‚™æ•¸æ“šé›†\n",
    "    print(\"\\nğŸ“Š æº–å‚™è¨“ç·´æ•¸æ“š...\")\n",
    "    dataloader = trainer.prepare_dataset(image_paths, captions)\n",
    "    \n",
    "    # é–‹å§‹è¨“ç·´\n",
    "    print(\"\\nğŸ¯ é–‹å§‹å¾®èª¿è¨“ç·´...\")\n",
    "    trainer.train(dataloader)\n",
    "    \n",
    "    print(\"\\nğŸ‰ è¨“ç·´å®Œæˆï¼\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ è¨“ç·´å¤±æ•—: {e}\")\n",
    "    print(\"\\nğŸ”§ å»ºè­°è§£æ±ºæ–¹æ¡ˆ:\")\n",
    "    print(\"1. æª¢æŸ¥ GPU è¨˜æ†¶é«”æ˜¯å¦è¶³å¤ \")\n",
    "    print(\"2. æ¸›å°‘ batch_size\")\n",
    "    print(\"3. é‡æ–°å•Ÿå‹•é‹è¡Œæ™‚ä¸¦é‡æ–°åŸ·è¡Œ\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063d18e5",
   "metadata": {},
   "source": [
    "## ğŸ“Š æ­¥é©Ÿ 9: æŸ¥çœ‹è¨“ç·´çµæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcdfb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥çœ‹è¨“ç·´çµæœ\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"ğŸ“Š æŸ¥çœ‹è¨“ç·´çµæœ...\")\n",
    "\n",
    "# æª¢æŸ¥ç”Ÿæˆçš„æª”æ¡ˆ\n",
    "model_dir = \"models/final_model\"\n",
    "validation_dir = \"validation\"\n",
    "logs_dir = \"logs\"\n",
    "\n",
    "print(f\"\\nğŸ“ æ¨¡å‹æª”æ¡ˆ:\")\n",
    "if os.path.exists(model_dir):\n",
    "    for file in os.listdir(model_dir):\n",
    "        size = os.path.getsize(os.path.join(model_dir, file)) / 1024 / 1024\n",
    "        print(f\"   {file} ({size:.1f} MB)\")\n",
    "else:\n",
    "    print(\"   âŒ æœªæ‰¾åˆ°æ¨¡å‹æª”æ¡ˆ\")\n",
    "\n",
    "print(f\"\\nğŸ–¼ï¸ é©—è­‰åœ–ç‰‡:\")\n",
    "if os.path.exists(validation_dir):\n",
    "    validation_images = [f for f in os.listdir(validation_dir) if f.endswith('.png')]\n",
    "    print(f\"   ç”Ÿæˆäº† {len(validation_images)} å¼µé©—è­‰åœ–ç‰‡\")\n",
    "    \n",
    "    # é¡¯ç¤ºæœ€æ–°çš„é©—è­‰åœ–ç‰‡\n",
    "    if validation_images:\n",
    "        latest_image = sorted(validation_images)[-1]\n",
    "        image_path = os.path.join(validation_dir, latest_image)\n",
    "        print(f\"   æœ€æ–°åœ–ç‰‡: {latest_image}\")\n",
    "        display(Image(filename=image_path))\n",
    "else:\n",
    "    print(\"   âŒ æœªæ‰¾åˆ°é©—è­‰åœ–ç‰‡\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ è¨“ç·´åœ–è¡¨:\")\n",
    "if os.path.exists(\"training_progress.png\"):\n",
    "    print(\"   âœ… è¨“ç·´é€²åº¦åœ–è¡¨å·²ç”Ÿæˆ\")\n",
    "    display(Image(filename=\"training_progress.png\"))\n",
    "else:\n",
    "    print(\"   âŒ æœªæ‰¾åˆ°è¨“ç·´åœ–è¡¨\")\n",
    "\n",
    "print(\"\\nâœ… çµæœæŸ¥çœ‹å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cd81fc",
   "metadata": {},
   "source": [
    "## ğŸ“¦ æ­¥é©Ÿ 10: æ‰“åŒ…èˆ‡ä¸‹è¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aa6302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰“åŒ…è¨“ç·´çµæœ\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "from google.colab import files\n",
    "\n",
    "print(\"ğŸ“¦ æ‰“åŒ…è¨“ç·´çµæœ...\")\n",
    "\n",
    "# å‰µå»ºå£“ç¸®æª”æ¡ˆ\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "package_name = f\"sd_v1.5_finetuned_{timestamp}.zip\"\n",
    "\n",
    "with zipfile.ZipFile(package_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    \n",
    "    # æ·»åŠ æ¨¡å‹æª”æ¡ˆ\n",
    "    model_dir = \"models/final_model\"\n",
    "    if os.path.exists(model_dir):\n",
    "        for root, dirs, files in os.walk(model_dir):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(file_path, \"models\")\n",
    "                zipf.write(file_path, f\"model/{arcname}\")\n",
    "        print(\"   âœ… æ¨¡å‹æª”æ¡ˆå·²æ·»åŠ \")\n",
    "    \n",
    "    # æ·»åŠ é©—è­‰åœ–ç‰‡\n",
    "    validation_dir = \"validation\"\n",
    "    if os.path.exists(validation_dir):\n",
    "        for file in os.listdir(validation_dir):\n",
    "            if file.endswith('.png'):\n",
    "                file_path = os.path.join(validation_dir, file)\n",
    "                zipf.write(file_path, f\"validation/{file}\")\n",
    "        print(\"   âœ… é©—è­‰åœ–ç‰‡å·²æ·»åŠ \")\n",
    "    \n",
    "    # æ·»åŠ è¨“ç·´åœ–è¡¨\n",
    "    if os.path.exists(\"training_progress.png\"):\n",
    "        zipf.write(\"training_progress.png\", \"training_progress.png\")\n",
    "        print(\"   âœ… è¨“ç·´åœ–è¡¨å·²æ·»åŠ \")\n",
    "    \n",
    "    # æ·»åŠ é…ç½®æª”æ¡ˆ\n",
    "    config_content = f\"\"\"# SD v1.5 Fine-tuning Configuration\n",
    "# Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "GPU: {gpu_name}\n",
    "Total Images: {len(image_paths)}\n",
    "Training Configuration:\n",
    "\"\"\"\n",
    "    for key, value in config.items():\n",
    "        config_content += f\"  {key}: {value}\\n\"\n",
    "    \n",
    "    zipf.writestr(\"config.txt\", config_content)\n",
    "    print(\"   âœ… é…ç½®æª”æ¡ˆå·²æ·»åŠ \")\n",
    "\n",
    "# æª¢æŸ¥æª”æ¡ˆå¤§å°\n",
    "file_size = os.path.getsize(package_name) / 1024 / 1024\n",
    "print(f\"\\nğŸ“¦ æ‰“åŒ…å®Œæˆ: {package_name} ({file_size:.1f} MB)\")\n",
    "\n",
    "# ä¸‹è¼‰æª”æ¡ˆ\n",
    "print(\"ğŸ“¥ é–‹å§‹ä¸‹è¼‰...\")\n",
    "files.download(package_name)\n",
    "\n",
    "print(\"\\nğŸ‰ æ‰€æœ‰æ­¥é©Ÿå®Œæˆï¼\")\n",
    "print(\"\\nğŸ“‹ è¨“ç·´æ‘˜è¦:\")\n",
    "print(f\"   â€¢ è¨“ç·´åœ–ç‰‡: {len(image_paths)} å¼µ\")\n",
    "print(f\"   â€¢ GPU é¡å‹: {gpu_name}\")\n",
    "print(f\"   â€¢ è¨“ç·´è¼ªæ•¸: {config['num_epochs']}\")\n",
    "print(f\"   â€¢ æ¨¡å‹å·²ä¿å­˜ä¸¦æ‰“åŒ…ä¸‹è¼‰\")\n",
    "print(f\"   â€¢ æª”æ¡ˆå¤§å°: {file_size:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cf4a14",
   "metadata": {},
   "source": [
    "## ğŸ”§ æ•…éšœæ’é™¤\n",
    "\n",
    "### å¸¸è¦‹å•é¡Œ\n",
    "\n",
    "1. **GPU è¨˜æ†¶é«”ä¸è¶³**\n",
    "   - æ¸›å°‘ `train_batch_size` åˆ° 1\n",
    "   - å¢åŠ  `gradient_accumulation_steps`\n",
    "   - ä½¿ç”¨è¼ƒå°çš„ `image_size`\n",
    "\n",
    "2. **ä¾è³´è¡çª**\n",
    "   - é‡æ–°å•Ÿå‹•é‹è¡Œæ™‚\n",
    "   - é‡æ–°åŸ·è¡Œä¾è³´å®‰è£æ­¥é©Ÿ\n",
    "\n",
    "3. **è¨“ç·´ä¸­æ–·**\n",
    "   - æª¢æŸ¥ Colab æœƒè©±æ˜¯å¦éæœŸ\n",
    "   - é‡æ–°é€£æ¥ä¸¦å¾æª¢æŸ¥é»æ¢å¾©\n",
    "\n",
    "4. **ä¸Šå‚³å¤±æ•—**\n",
    "   - æª¢æŸ¥ç¶²è·¯é€£æ¥\n",
    "   - ç¢ºä¿åœ–ç‰‡æ ¼å¼æ­£ç¢º\n",
    "   - é‡æ–°ä¸Šå‚³åœ–ç‰‡\n",
    "\n",
    "### ç²å¾—å¹«åŠ©\n",
    "å¦‚æœé‡åˆ°å…¶ä»–å•é¡Œï¼Œè«‹æŸ¥çœ‹ç›¸é—œæ–‡æª”æˆ–è¯ç¹«æ”¯æ´ã€‚"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
