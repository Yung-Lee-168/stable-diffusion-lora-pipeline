#!/usr/bin/env python3
"""
Fashion Project Quick Start
å¿«é€Ÿé–‹å§‹æ™‚å°šå°ˆæ¡ˆçš„æ¦‚å¿µé©—è­‰
"""

import os
import json
from datetime import datetime

def create_project_structure():
    """å‰µå»ºå°ˆæ¡ˆç›®éŒ„çµæ§‹"""
    
    directories = [
        "fashion_project",
        "fashion_project/data",
        "fashion_project/data/original_images", 
        "fashion_project/data/generated_images",
        "fashion_project/data/features",
        "fashion_project/models",
        "fashion_project/results",
        "fashion_project/scripts",
        "fashion_project/docs"
    ]
    
    for dir_path in directories:
        os.makedirs(dir_path, exist_ok=True)
        print(f"ğŸ“ å‰µå»ºç›®éŒ„: {dir_path}")
    
    return "fashion_project"

def create_sample_config():
    """å‰µå»ºç¤ºä¾‹é…ç½®æª”æ¡ˆ"""
    
    config = {
        "project_info": {
            "name": "Fashion Style Transfer with Stable Diffusion",
            "version": "1.0.0",
            "created_date": datetime.now().isoformat(),
            "description": "ä½¿ç”¨ FashionCLIP åˆ†ææ™‚å°šåœ–ç‰‡ç‰¹å¾µï¼Œè¨“ç·´ SD æ¨¡å‹ç”Ÿæˆé¡ä¼¼é¢¨æ ¼åœ–ç‰‡"
        },
        "data_config": {
            "original_images_dir": "data/original_images",
            "generated_images_dir": "data/generated_images", 
            "features_dir": "data/features",
            "supported_formats": [".jpg", ".jpeg", ".png", ".bmp"],
            "target_image_size": [512, 512]
        },
        "feature_extraction": {
            "model": "FashionCLIP",
            "categories": [
                "gender", "age_group", "top_clothing", "bottom_clothing",
                "style", "color_scheme", "season", "occasion"
            ],
            "confidence_threshold": 0.3
        },
        "sd_generation": {
            "base_model": "v1-5-pruned-emaonly.safetensors",
            "default_params": {
                "width": 512,
                "height": 512,
                "steps": 20,
                "cfg_scale": 7.5,
                "sampler": "Euler"
            }
        },
        "training_config": {
            "method": "LoRA",
            "batch_size": 4,
            "learning_rate": 1e-4,
            "max_train_steps": 1000,
            "validation_split": 0.2
        }
    }
    
    config_file = "fashion_project/config.json"
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    print(f"âš™ï¸ å‰µå»ºé…ç½®æª”æ¡ˆ: {config_file}")
    return config_file

def create_readme():
    """å‰µå»ºèªªæ˜æ–‡ä»¶"""
    
    readme_content = """# Fashion Style Transfer Project

## å°ˆæ¡ˆæ¦‚è¿°
ä½¿ç”¨ FashionCLIP åˆ†ææ™‚å°šé›œèªŒåœ–ç‰‡ç‰¹å¾µï¼Œè¨“ç·´ Stable Diffusion æ¨¡å‹ç”Ÿæˆç›¸ä¼¼é¢¨æ ¼çš„æœè£åœ–ç‰‡ã€‚

## å°ˆæ¡ˆçµæ§‹
```
fashion_project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ original_images/     # åŸå§‹æ™‚å°šé›œèªŒåœ–ç‰‡
â”‚   â”œâ”€â”€ generated_images/    # SD ç”Ÿæˆçš„åœ–ç‰‡
â”‚   â””â”€â”€ features/           # æå–çš„ç‰¹å¾µè³‡æ–™
â”œâ”€â”€ models/                 # è¨“ç·´å¥½çš„æ¨¡å‹
â”œâ”€â”€ results/               # å¯¦é©—çµæœå’Œè©•ä¼°
â”œâ”€â”€ scripts/              # åŸ·è¡Œè…³æœ¬
â”œâ”€â”€ docs/                # æ–‡æª”
â””â”€â”€ config.json          # é…ç½®æª”æ¡ˆ
```

## ä½¿ç”¨æ­¥é©Ÿ

### 1. è³‡æ–™æº–å‚™
```bash
# å°‡æ™‚å°šé›œèªŒåœ–ç‰‡æ”¾å…¥ data/original_images/
cp your_fashion_images/* data/original_images/
```

### 2. ç‰¹å¾µæå–
```bash
python fashion_feature_extractor.py
```

### 3. ç”Ÿæˆè¨“ç·´è³‡æ–™
```bash
python fashion_sd_trainer.py
```

### 4. æ¨¡å‹è¨“ç·´ (æœªä¾†å¯¦ä½œ)
```bash
python train_fashion_lora.py
```

## æŠ€è¡“æ¶æ§‹

1. **ç‰¹å¾µæå–**: FashionCLIP â†’ æœè£ç‰¹å¾µå‘é‡
2. **æç¤ºè©ç”Ÿæˆ**: ç‰¹å¾µ â†’ SD æç¤ºè©
3. **åœ–ç‰‡ç”Ÿæˆ**: SD API â†’ ç”Ÿæˆåœ–ç‰‡
4. **å“è³ªè©•ä¼°**: åŸå§‹åœ– vs ç”Ÿæˆåœ–
5. **æ¨¡å‹å¾®èª¿**: LoRA/Dreambooth

## ä¾è³´å¥—ä»¶
- torch
- transformers
- clip-by-openai
- Pillow
- requests
- numpy
- pandas

## å®‰è£
```bash
pip install torch transformers clip-by-openai pillow requests numpy pandas
```

## ä½¿ç”¨ç¯„ä¾‹

```python
from fashion_feature_extractor import FashionFeatureExtractor

# æå–ç‰¹å¾µ
extractor = FashionFeatureExtractor()
features = extractor.extract_features_from_image("image.jpg")

# ç”Ÿæˆåœ–ç‰‡
from fashion_sd_trainer import FashionSDTrainer
trainer = FashionSDTrainer()
result = trainer.generate_from_features(features)
```

## è©•ä¼°æŒ‡æ¨™
- è¦–è¦ºç›¸ä¼¼åº¦ (CLIP Score)
- ç‰¹å¾µä¸€è‡´æ€§
- é¢¨æ ¼ä¿æŒåº¦
- ç”Ÿæˆå“è³ª (FID)

## æœªä¾†æ”¹é€²
- [ ] æ›´ç²¾ç¢ºçš„ç‰¹å¾µæå–
- [ ] å¤šæ¨¡å‹ensemble
- [ ] å¯¦æ™‚ç”Ÿæˆå„ªåŒ–
- [ ] ç”¨æˆ¶ä»‹é¢é–‹ç™¼
"""
    
    readme_file = "fashion_project/README.md"
    with open(readme_file, 'w', encoding='utf-8') as f:
        f.write(readme_content)
    
    print(f"ğŸ“– å‰µå»ºèªªæ˜æ–‡ä»¶: {readme_file}")
    return readme_file

def create_sample_script():
    """å‰µå»ºç¤ºä¾‹åŸ·è¡Œè…³æœ¬"""
    
    script_content = '''#!/usr/bin/env python3
"""
Fashion Project Demo Script
æ™‚å°šå°ˆæ¡ˆç¤ºä¾‹è…³æœ¬
"""

import os
import sys

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def demo_workflow():
    """ç¤ºç¯„å®Œæ•´å·¥ä½œæµç¨‹"""
    
    print("ğŸ¨ Fashion Style Transfer Demo")
    print("=" * 50)
    
    # 1. æª¢æŸ¥è³‡æ–™
    original_dir = "data/original_images"
    if not os.listdir(original_dir):
        print(f"âš ï¸ è«‹å°‡æ™‚å°šåœ–ç‰‡æ”¾å…¥ {original_dir}/")
        return
    
    # 2. ç‰¹å¾µæå–
    print("\\nğŸ“Š Step 1: ç‰¹å¾µæå–")
    try:
        from fashion_feature_extractor import FashionFeatureExtractor
        extractor = FashionFeatureExtractor()
        features = extractor.process_fashion_magazine_dataset(original_dir)
        print("âœ… ç‰¹å¾µæå–å®Œæˆ")
    except Exception as e:
        print(f"âŒ ç‰¹å¾µæå–å¤±æ•—: {e}")
        return
    
    # 3. åœ–ç‰‡ç”Ÿæˆ
    print("\\nğŸ¨ Step 2: åœ–ç‰‡ç”Ÿæˆ")
    try:
        from fashion_sd_trainer import FashionSDTrainer
        trainer = FashionSDTrainer()
        generated = trainer.generate_training_images(max_samples=5)
        print("âœ… åœ–ç‰‡ç”Ÿæˆå®Œæˆ")
    except Exception as e:
        print(f"âŒ åœ–ç‰‡ç”Ÿæˆå¤±æ•—: {e}")
        return
    
    # 4. è©•ä¼°
    print("\\nğŸ“ˆ Step 3: å“è³ªè©•ä¼°")
    try:
        evaluation = trainer.evaluate_generation_quality()
        print("âœ… è©•ä¼°å®Œæˆ")
    except Exception as e:
        print(f"âŒ è©•ä¼°å¤±æ•—: {e}")
    
    print("\\nğŸ‰ Demo å®Œæˆ!")

if __name__ == "__main__":
    demo_workflow()
'''
    
    script_file = "fashion_project/scripts/demo.py"
    with open(script_file, 'w', encoding='utf-8') as f:
        f.write(script_content)
    
    print(f"ğŸš€ å‰µå»ºç¤ºä¾‹è…³æœ¬: {script_file}")
    return script_file

def main():
    """ä¸»å‡½æ•¸ - å¿«é€Ÿé–‹å§‹"""
    
    print("ğŸš€ Fashion Project Quick Start")
    print("=" * 50)
    
    # å‰µå»ºå°ˆæ¡ˆçµæ§‹
    project_dir = create_project_structure()
    
    # å‰µå»ºé…ç½®æª”æ¡ˆ
    config_file = create_sample_config()
    
    # å‰µå»ºèªªæ˜æ–‡ä»¶
    readme_file = create_readme()
    
    # å‰µå»ºç¤ºä¾‹è…³æœ¬
    script_file = create_sample_script()
    
    print("\nğŸ‰ å°ˆæ¡ˆåˆå§‹åŒ–å®Œæˆ!")
    print(f"ğŸ“ å°ˆæ¡ˆç›®éŒ„: {project_dir}")
    print(f"\næ¥ä¸‹ä¾†çš„æ­¥é©Ÿ:")
    print(f"1. å°‡æ™‚å°šé›œèªŒåœ–ç‰‡æ”¾å…¥ {project_dir}/data/original_images/")
    print(f"2. å®‰è£ä¾è³´: pip install torch transformers clip-by-openai")
    print(f"3. åŸ·è¡Œç¤ºä¾‹: python {script_file}")
    print(f"4. æŸ¥çœ‹èªªæ˜: {readme_file}")

if __name__ == "__main__":
    main()
